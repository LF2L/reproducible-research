Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Document Type,Publication Stage,Access Type,Source,EID
"Fladie I.A., Adewumi T.M., Vo N.H., Tritz D.J., Vassar M.B.","57211914778;57213172193;57212881930;57200158801;23029184400;","An Evaluation of Nephrology Literature for Transparency and Reproducibility Indicators: Cross-Sectional Review",2020,"Kidney International Reports",,,,"","",,1,"10.1016/j.ekir.2019.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077643272&doi=10.1016%2fj.ekir.2019.11.001&partnerID=40&md5=c7b52d9d8adccb41afaf48af458bb685","Department of Psychiatry and Behavioral Sciences, Oklahoma State University Center for Health Sciences, Tulsa, OK, United States; Kansas City University of Medicine and Biosciences, Joplin, MO, United States","Fladie, I.A., Department of Psychiatry and Behavioral Sciences, Oklahoma State University Center for Health Sciences, Tulsa, OK, United States; Adewumi, T.M., Department of Psychiatry and Behavioral Sciences, Oklahoma State University Center for Health Sciences, Tulsa, OK, United States; Vo, N.H., Kansas City University of Medicine and Biosciences, Joplin, MO, United States; Tritz, D.J., Department of Psychiatry and Behavioral Sciences, Oklahoma State University Center for Health Sciences, Tulsa, OK, United States; Vassar, M.B., Department of Psychiatry and Behavioral Sciences, Oklahoma State University Center for Health Sciences, Tulsa, OK, United States","Introduction: Reproducibility is critical to diagnostic accuracy and treatment implementation. Concurrent with clinical reproducibility, research reproducibility establishes whether the use of identical study materials and methodologies in replication efforts permits researchers to arrive at similar results and conclusions. In this study, we address this gap by evaluating nephrology literature for common indicators of transparent and reproducible research. Methods: We searched the National Library of Medicine catalog to identify 36 MEDLINE-indexed, English-language nephrology journals. We randomly sampled 300 publications published between January 1, 2014, and December 31, 2018. Results: Our search yielded 28,835 publications, of which we randomly sampled 300 publications. Of the 300 publications, 152 (50.7%) were publicly available, whereas 143 (47.7%) were restricted through paywall and 5 (1.7%) were inaccessible. Of the remaining 295 publications, 123 were excluded because they lack empirical data necessary for reproducibility. Of the 172 publications with empirical data, 43 (25%) reported data availability statements and 4 (2.3%) analysis scripts. Of the 71 publications analyzed for preregistration and protocol availability, 0 (0.0%) provided links to a protocol and 8 (11.3%) were preregistered. Conclusion: Our study found that reproducible and transparent research practices are infrequently used by the nephrology research community. Greater efforts should be made by both funders and journals. In doing so, an open science culture may eventually become the norm rather than the exception. © 2019 International Society of Nephrology","data availability; evidence-based science; reproducibility; transparency","article; diagnostic test accuracy study; English (language); human; human experiment; Medline; nephrology; reproducibility; systematic review",Article,"Article in Press",Open Access,Scopus,2-s2.0-85077643272
"Emmert-Streib F., Dehmer M., Yli-Harja O.","15057742200;13404645900;55880982100;","Ensuring Quality Standards and Reproducible Research for Data Analysis Services in Oncology: A Cooperative Service Model",2019,"Frontiers in Cell and Developmental Biology","7",, 349,"","",,,"10.3389/fcell.2019.00349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077340569&doi=10.3389%2ffcell.2019.00349&partnerID=40&md5=ac43e7872e2fdd0bc2696edad3e942dd","Predictive Society, Data Analytics Lab, Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland; Institute of Biosciences and Medical Technology, Tampere, Finland; Steyr School of Management, University of Applied Sciences Upper Austria, Steyr, Austria; Department of Mechatronics and Biomedical Computer Science, UMIT, Hall in Tyrol, Austria; College of Artificial Intelligence, Nankai University, Tianjin, China; Institute for Systems Biology, Seattle, WA, United States","Emmert-Streib, F., Predictive Society, Data Analytics Lab, Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland, Institute of Biosciences and Medical Technology, Tampere, Finland; Dehmer, M., Steyr School of Management, University of Applied Sciences Upper Austria, Steyr, Austria, Department of Mechatronics and Biomedical Computer Science, UMIT, Hall in Tyrol, Austria, College of Artificial Intelligence, Nankai University, Tianjin, China; Yli-Harja, O., Institute of Biosciences and Medical Technology, Tampere, Finland, Institute for Systems Biology, Seattle, WA, United States","Modern molecular high-throughput devices, e.g., next-generation sequencing, have transformed medical research. Resulting data sets are usually high-dimensional on a genomic-scale providing multi-factorial information from intertwined molecular and cellular activities of genes and their products. This genomics-revolution installed precision medicine offering breathtaking opportunities for patient's diagnosis and treatment. However, due to the speed of these developments the quality standards of the involved data analyses are lacking behind, as exemplified by the infamous Duke Saga. In this paper, we argue in favor of a two-stage cooperative serve model that couples data generation and data analysis in the most beneficial way from the perspective of a patient to ensure data analysis quality standards including reproducible research. © Copyright © 2019 Emmert-Streib, Dehmer and Yli-Harja.","biostatistics; computational biology; data science; genomics; oncology; precision medicine; reproducible research","adult; article; biostatistics; cancer model; controlled study; data analysis; data science; genomics; human; personalized medicine; velocity",Article,"Final",Open Access,Scopus,2-s2.0-85077340569
"Pfister N., Bauer S., Peters J.","57194283500;56410381900;55705328700;","Learning stable and predictive structures in kinetic systems",2019,"Proceedings of the National Academy of Sciences of the United States of America","116","51",,"25405","25411",,,"10.1073/pnas.1905688116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076678324&doi=10.1073%2fpnas.1905688116&partnerID=40&md5=464d1349c2920dcfc6b2473122e7e533","aSeminar for Statistics, Eidgenössische Technische Hochschule Zürich, Zürich, 8092, Switzerland; Empirical Inference, Max-Planck-Institute for Intelligent Systems, Tübingen, 72076, Germany; Department of Mathematical Sciences, University of Copenhagen, Copenhagen, 2100, Denmark","Pfister, N., aSeminar for Statistics, Eidgenössische Technische Hochschule Zürich, Zürich, 8092, Switzerland; Bauer, S., Empirical Inference, Max-Planck-Institute for Intelligent Systems, Tübingen, 72076, Germany; Peters, J., Department of Mathematical Sciences, University of Copenhagen, Copenhagen, 2100, Denmark","Learning kinetic systems from data is one of the core challenges in many fields. Identifying stable models is essential for the generalization capabilities of data-driven inference. We introduce a computationally efficient framework, called CausalKinetiX, that identifies structure from discrete time, noisy observations, generated from heterogeneous experiments. The algorithm assumes the existence of an underlying, invariant kinetic model, a key criterion for reproducible research. Results on both simulated and real-world examples suggest that learning the structure of kinetic systems benefits from a causal perspective. The identified variables and models allow for a concise description of the dynamics across multiple experimental settings and can be used for prediction in unseen experiments. We observe significant improvements compared to well-established approaches focusing solely on predictive performance, especially for out-of-sample generalization. © 2019 National Academy of Sciences. All rights reserved.","Causal inference; Invariance; Kinetic systems; Stability; Structure learning","article; controlled study; kinetics; learning; prediction; simulation",Article,"Final",,Scopus,2-s2.0-85076678324
"Roche D.G., Bennett J.R., Provencher J., Rytwinski T., Haddaway N.R., Cooke S.J.","25623797000;57206712889;26534824300;22956744700;54997981700;24320083600;","Environmental sciences benefit from robust evidence irrespective of speed",2019,"Science of the Total Environment","696",, 134000,"","",,,"10.1016/j.scitotenv.2019.134000","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071076623&doi=10.1016%2fj.scitotenv.2019.134000&partnerID=40&md5=af09267072afda6d405d84e257070515","Canadian Centre for Evidence-Based Conservation, Department of Biology and Institute of Environmental and Interdisciplinary Sciences, Carleton University, Ottawa, ON, Canada; Canadian Wildlife Service, Environment and Climate Change Canada, Gatineau, QC, Canada; Stockholm Environment Institute, Stockholm, Sweden; Africa Centre for Evidence, University of Johannesburg, Johannesburg, South Africa","Roche, D.G., Canadian Centre for Evidence-Based Conservation, Department of Biology and Institute of Environmental and Interdisciplinary Sciences, Carleton University, Ottawa, ON, Canada; Bennett, J.R., Canadian Centre for Evidence-Based Conservation, Department of Biology and Institute of Environmental and Interdisciplinary Sciences, Carleton University, Ottawa, ON, Canada; Provencher, J., Canadian Wildlife Service, Environment and Climate Change Canada, Gatineau, QC, Canada; Rytwinski, T., Canadian Centre for Evidence-Based Conservation, Department of Biology and Institute of Environmental and Interdisciplinary Sciences, Carleton University, Ottawa, ON, Canada; Haddaway, N.R., Stockholm Environment Institute, Stockholm, Sweden, Africa Centre for Evidence, University of Johannesburg, Johannesburg, South Africa; Cooke, S.J., Canadian Centre for Evidence-Based Conservation, Department of Biology and Institute of Environmental and Interdisciplinary Sciences, Carleton University, Ottawa, ON, Canada","Discussions around the “slow science movement” abound in environmental sciences, yet they are generally counterproductive. Researchers must focus on producing robust and transparent knowledge, regardless of speed. Slow versus fast science is irrelevant - what we need is reproducible research to support evidence-based decision making and tackle urgent and costly environmental problems. © 2019","Conservation; Open science; Policy; Reproducibility; Slow science movement","decision making; human; note; reproducibility; scientist; velocity; article",Note,"Final",,Scopus,2-s2.0-85071076623
"Sullivan I.","57208347491;","Reproducibility as a Value-Add",2019,"Journal of biomolecular techniques : JBT","30",,,"S59","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077457800&partnerID=40&md5=38db951142a00e9b5f16128187ee192f","Center for Open Science","Sullivan, I., Center for Open Science","Researchers face increasing expectations to incorporate reproducible research practices in their work. The shifting landscape of data mandates, author submission guidelines, community checklists, global IDs for reagents or shared protocols, and other new practices can be daunting for researchers to engage with, especially when so many of these practices are tied to the work done at shared research facilities where they are not the domain experts. We discuss an approach that presents greater consultation with and documentation of the work of shared research facilities in resulting publications as a valuable service that can be provided to authors to help them address these new reproducibility expectations for their work. Using papers from the Center for Open Science's ""Reproducibility Project: Cancer Biology"" project as models, we discuss potential workflows and tools to support this increasingly deep collaboration with researchers as well as related marketing and framing suggestions to help persuade researchers of the value of this approach. © Association of Biomolecular Resource Facilities.",,"article; cancer model; human; marketing; reproducibility; workflow",Article,"Final",,Scopus,2-s2.0-85077457800
"Smith A.J., Lilley E.","55740299400;6701712712;","The role of the three Rs in improving the planning and reproducibility of animal experiments",2019,"Animals","9","11", 975,"","",,,"10.3390/ani9110975","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075249612&doi=10.3390%2fani9110975&partnerID=40&md5=ae4a560da4144fd40810370a7f1b6006","Norecopa, c/o Norwegian Veterinary Institute, P.O. Box 750 SentrumOslo  0106, Norway; Science Group, Research Animals Department, RSPCA, Wilberforce Way, Southwater, West Sussex, RH13 9RS, United Kingdom","Smith, A.J., Norecopa, c/o Norwegian Veterinary Institute, P.O. Box 750 SentrumOslo  0106, Norway; Lilley, E., Science Group, Research Animals Department, RSPCA, Wilberforce Way, Southwater, West Sussex, RH13 9RS, United Kingdom","Training in the design of animal experiments focuses all too often on those aspects which can be approached mathematically, such as the number of animals needed to deliver a robust result, allocation of group size, and techniques such as randomization, blocking and statistical analysis. Important as they are, these are only a small part of the process of planning animal experiments. Additional key elements include refinements of housing, husbandry and procedures, health and safety, and attention at all stages to animal welfare. Advances in technology and laboratory animal science have led to improvements in care and husbandry, better provision of anesthetics and analgesics, refined methods of drug administration, greater competence in welfare assessment and application of humane endpoints. These improvements require continual dialogue between scientists, facility managers and technical staff, a practice that is a key feature of what has become known as the culture of care. This embodies a commitment to improving animal welfare, scientific quality, staff care and transparency for all stakeholders. Attention to both the physical and mental health of all those directly or indirectly involved in animal research is now an important part of the process of planning and conducting animal experiments. Efforts during the last 30 years to increase the internal and external validity of animal experiments have tended to concentrate on the production of guidelines to improve the quality of reporting animal experiments, rather than for planning them. Recently, comprehensive guidelines for planning animal studies have been published, to redress this imbalance. These will be described in this paper. Endorsement of this overarching influence of the Three R concept, by all the stakeholders, will not only reduce animal numbers and improve animal welfare, but also lead to more reliable and reproducible research which should improve translation of pre-clinical studies into tangible clinical benefit. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","Planning; PREPARE; Reporting; Reproducibility; Three Rs",,Article,"Final",Open Access,Scopus,2-s2.0-85075249612
"Salecker J., Sciaini M., Meyer K.M., Wiegand K.","57190606039;57203861336;55224410000;7003673415;","The nlrx r package: A next-generation framework for reproducible NetLogo model analyses",2019,"Methods in Ecology and Evolution","10","11",,"1854","1863",,1,"10.1111/2041-210X.13286","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072703601&doi=10.1111%2f2041-210X.13286&partnerID=40&md5=31833f9a383a1c0c52985c00d6b1ee90","Department of Ecosystem Modelling, University of Göttingen, Göttingen, Germany; Centre of Biodiversity and Sustainable Land Use (CBL), University of Goettingen, Göttingen, Germany","Salecker, J., Department of Ecosystem Modelling, University of Göttingen, Göttingen, Germany; Sciaini, M., Department of Ecosystem Modelling, University of Göttingen, Göttingen, Germany; Meyer, K.M., Department of Ecosystem Modelling, University of Göttingen, Göttingen, Germany; Wiegand, K., Department of Ecosystem Modelling, University of Göttingen, Göttingen, Germany, Centre of Biodiversity and Sustainable Land Use (CBL), University of Goettingen, Göttingen, Germany","Agent-based models find wide application in all fields of science where large-scale patterns emerge from properties of individuals. Due to increasing capacities of computing resources it was possible to improve the level of detail and structural realism of next-generation models in recent years. However, this is at the expense of increased model complexity, which requires more efficient tools for model exploration, analysis and documentation that enable reproducibility, repeatability and parallelization. NetLogo is a widely used environment for agent-based model development, but it does not provide sufficient built-in tools for extensive model exploration, such as sensitivity analyses. One tool for controlling NetLogo externally is the r-package RNetLogo. However, this package is not suited for efficient, reproducible research as it has stability and resource allocation issues, is not straightforward to be setup and used on high performance computing clusters and does not provide utilities, such as storing and exchanging metadata, in an easy way. We present the r-package nlrx, which overcomes stability and resource allocation issues by running NetLogo simulations via dynamically created XML experiment files. Class objects make setting up experiments more convenient and helper functions provide many parameter exploration approaches, such as Latin Hypercube designs, Sobol sensitivity analyses or optimization approaches. Output is automatically collected in user-friendly formats and can be post-processed with provided utility functions. nlrx enables reproducibility by storing all relevant information and simulation output of experiments in one r object which can conveniently be archived and shared. We provide a detailed description of the nlrx package functions and the overall workflow. We also present a use case scenario using a NetLogo model, for which we performed a sensitivity analysis and a genetic algorithm optimization. The nlrx package is the first framework for documentation and application of reproducible NetLogo simulation model analysis. © 2019 The Authors. Methods in Ecology and Evolution published by John Wiley & Sons Ltd on behalf of British Ecological Society","agent-based modelling; algorithm optimization; individual-based modelling; model analysis; NetLogo; r package; reproducible workflow; sensitivity analysis",,Article,"Final",Open Access,Scopus,2-s2.0-85072703601
"Blischak J.D., Carbonetto P., Stephens M.","56375187500;22333789900;7201574987;","Creating and sharing reproducible research code the workflow way [version 1; peer review: 3 approved]",2019,"F1000Research","8",, 1749,"","",,,"10.12688/f1000research.20843.1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074958520&doi=10.12688%2ff1000research.20843.1&partnerID=40&md5=94c0f15c64cfa2eeefb81263a10d69db","Department of Human Genetics, University of Chicago, Chicago, IL  60637, United States; Research Computing Center, University of Chicago, Chicago, IL  60637, United States; Department of Statistics, University of Chicago, Chicago, IL  60637, United States","Blischak, J.D., Department of Human Genetics, University of Chicago, Chicago, IL  60637, United States; Carbonetto, P., Department of Human Genetics, University of Chicago, Chicago, IL  60637, United States, Research Computing Center, University of Chicago, Chicago, IL  60637, United States; Stephens, M., Department of Human Genetics, University of Chicago, Chicago, IL  60637, United States, Department of Statistics, University of Chicago, Chicago, IL  60637, United States","Making scientific analyses reproducible, well documented, and easily shareable is crucial to maximizing their impact and ensuring that others can build on them. However, accomplishing these goals is not easy, requiring careful attention to organization, workflow, and familiarity with tools that are not a regular part of every scientist's toolbox. We have developed an R package, workflowr, to help all scientists, regardless of background, overcome these challenges. Workflowr aims to instill a particular “workflow”-a sequence of steps to be repeated and integrated into research practice-that helps make projects more reproducible and accessible.This workflow integrates four key elements: (1) version control (via Git); (2) literate programming (via R Markdown); (3) automatic checks and safeguards that improve code reproducibility; and (4) sharing code and results via a browsable website. These features exploit powerful existing tools, whose mastery would take considerable study. However, the workflowr interface is simple enough that novice users can quickly enjoy its many benefits. By simply following the workflowr “workflow”, R users can create projects whose results, figures, and development history are easily accessible on a static website-thereby conveniently shareable with collaborators by sending them a URL-and accompanied by source code and reproducibility safeguards. The workflowr R package is open source and available on CRAN, with full documentation and source code available at https://github.com/jdblischak/workflowr. © 2019 Blischak JD et al.","Interactive programming; Literate programming; Open science; R; Reproducibility; Version control; Workflow","article; documentation; peer review; reproducibility; workflow",Article,"Final",Open Access,Scopus,2-s2.0-85074958520
"Stanstrup J., Broeckling C.D., Helmus R., Hoffmann N., Mathé E., Naake T., Nicolotti L., Peters K., Rainer J., Salek R.M., Schulze T., Schymanski E.L., Stravs M.A., Thévenot E.A., Treutler H., Weber R.J.M., Willighagen E., Witting M., Neumann S.","36145328800;6505889306;55805582900;35336657500;12243332100;56584620000;57212704767;26634251800;36763469000;16302215200;23470791500;24068144000;55257865500;7801407724;55453435200;25626911200;6507481906;55578910900;18038199000;","The metaRbolomics toolbox in bioconductor and beyond",2019,"Metabolites","9","10", 200,"","",,1,"10.3390/metabo9100200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073434016&doi=10.3390%2fmetabo9100200&partnerID=40&md5=eab4b6831d79e5b35a78b3ae11792181","University of Copenhagen, Rolighedsvej 30, Frederiksberg C, 1958, Denmark; Proteomics and Metabolomics Facility, Colorado State University, Fort Collins, CO  80523, United States; Institute for Biodiversity and Ecosystem Dynamics, University of Amsterdam, Amsterdam, 1098 XH, Netherlands; Leibniz-Institut für Analytische Wissenschaften-ISAS-e.V, Otto-Hahn-Straße 6b, Dortmund, 44227, Germany; Department of Biomedical Informatics, College of Medicine, The Ohio State University, Columbus, OH  43210, United States; Max Planck Institute of Molecular Plant Physiology, Potsdam-Golm, 14476, Germany; The Australian Wine Research Institute, Metabolomics Australia, PO Box 197, Adelaide, SA 5064, Australia; Leibniz Institute of Plant Biochemistry (IPB Halle), Bioinformatics and Scientific Data, Halle, 06120, Germany; Institute for Biomedicine, Eurac Research, Affiliated Institute of the University of Lübeck, Bolzano, 39100, Italy; The International Agency for Research on Cancer, 150 cours Albert Thomas, CEDEX 08, Lyon, 69372, France; Department of Effect-Directed Analysis, Helmholtz Centre for Environmental Research-UFZ, Permoserstraße 15, Leipzig, 04318, Germany; Luxembourg Centre for Systems Biomedicine, University of Luxembourg, 6 avenue du Swing, Belvaux, L-4367, Luxembourg; Eawag, Swiss Federal Institute of Aquatic Science and Technology, Überlandstrasse 133, Dubendorf, 8600, Switzerland; CEA, LIST, Laboratory for Data Sciences and Decision, MetaboHUB, Gif-Sur-Yvette, F-91191, France; Phenome Centre Birmingham and School of Biosciences, University of Birmingham, Edgbaston, Birmingham, B15 2TT, United Kingdom; Department of Bioinformatics-BiGCaT, NUTRIM, Maastricht University, Maastricht, 6229 ER, Netherlands; Research Unit Analytical BioGeoChemistry, Helmholtz Zentrum München, Neuherberg, 85764, Germany; Technische Universität München, Weihenstephan, 85354, Germany; German Centre for Integrative Biodiversity Research (iDiv), Halle-Jena-Leipzig Deutscher, Platz, Leipzig  04103, Germany","Stanstrup, J., University of Copenhagen, Rolighedsvej 30, Frederiksberg C, 1958, Denmark; Broeckling, C.D., Proteomics and Metabolomics Facility, Colorado State University, Fort Collins, CO  80523, United States; Helmus, R., Institute for Biodiversity and Ecosystem Dynamics, University of Amsterdam, Amsterdam, 1098 XH, Netherlands; Hoffmann, N., Leibniz-Institut für Analytische Wissenschaften-ISAS-e.V, Otto-Hahn-Straße 6b, Dortmund, 44227, Germany; Mathé, E., Department of Biomedical Informatics, College of Medicine, The Ohio State University, Columbus, OH  43210, United States; Naake, T., Max Planck Institute of Molecular Plant Physiology, Potsdam-Golm, 14476, Germany; Nicolotti, L., The Australian Wine Research Institute, Metabolomics Australia, PO Box 197, Adelaide, SA 5064, Australia; Peters, K., Leibniz Institute of Plant Biochemistry (IPB Halle), Bioinformatics and Scientific Data, Halle, 06120, Germany; Rainer, J., Institute for Biomedicine, Eurac Research, Affiliated Institute of the University of Lübeck, Bolzano, 39100, Italy; Salek, R.M., The International Agency for Research on Cancer, 150 cours Albert Thomas, CEDEX 08, Lyon, 69372, France; Schulze, T., Department of Effect-Directed Analysis, Helmholtz Centre for Environmental Research-UFZ, Permoserstraße 15, Leipzig, 04318, Germany; Schymanski, E.L., Luxembourg Centre for Systems Biomedicine, University of Luxembourg, 6 avenue du Swing, Belvaux, L-4367, Luxembourg; Stravs, M.A., Eawag, Swiss Federal Institute of Aquatic Science and Technology, Überlandstrasse 133, Dubendorf, 8600, Switzerland; Thévenot, E.A., CEA, LIST, Laboratory for Data Sciences and Decision, MetaboHUB, Gif-Sur-Yvette, F-91191, France; Treutler, H., Leibniz Institute of Plant Biochemistry (IPB Halle), Bioinformatics and Scientific Data, Halle, 06120, Germany; Weber, R.J.M., Phenome Centre Birmingham and School of Biosciences, University of Birmingham, Edgbaston, Birmingham, B15 2TT, United Kingdom; Willighagen, E., Department of Bioinformatics-BiGCaT, NUTRIM, Maastricht University, Maastricht, 6229 ER, Netherlands; Witting, M., Research Unit Analytical BioGeoChemistry, Helmholtz Zentrum München, Neuherberg, 85764, Germany, Technische Universität München, Weihenstephan, 85354, Germany; Neumann, S., Leibniz Institute of Plant Biochemistry (IPB Halle), Bioinformatics and Scientific Data, Halle, 06120, Germany, German Centre for Integrative Biodiversity Research (iDiv), Halle-Jena-Leipzig Deutscher, Platz, Leipzig  04103, Germany","Metabolomics aims to measure and characterise the complex composition of metabolites in a biological system. Metabolomics studies involve sophisticated analytical techniques such as mass spectrometry and nuclear magnetic resonance spectroscopy, and generate large amounts of high-dimensional and complex experimental data. Open source processing and analysis tools are of major interest in light of innovative, open and reproducible science. The scientific community has developed a wide range of open source software, providing freely available advanced processing and analysis approaches. The programming and statistics environment R has emerged as one of the most popular environments to process and analyse Metabolomics datasets. A major benefit of such an environment is the possibility of connecting different tools into more complex workflows. Combining reusable data processing R scripts with the experimental data thus allows for open, reproducible research. This review provides an extensive overview of existing packages in R for different steps in a typical computational metabolomics workflow, including data processing, biostatistics, metabolite annotation and identification, and biochemical network and pathway analysis. Multifunctional workflows, possible user interfaces and integration into workflow management systems are also reviewed. In total, this review summarises more than two hundred metabolomics specific packages primarily available on CRAN, Bioconductor and GitHub. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","Bioconductor; Compound identification; CRAN; Data integration; Feature selection; Lipidomics; Mass spectrometry; Metabolite networks; Metabolomics; NMR spectroscopy; R; Signal processing; Statistical data analysis","analytic method; biostatistics; computer language; data processing; human; mass spectrometry; metabolomics; nonhuman; nuclear magnetic resonance spectroscopy; Review; workflow",Review,"Final",Open Access,Scopus,2-s2.0-85073434016
"Adhikari B.M., Jahanshad N., Shukla D., Turner J., Grotegerd D., Dannlowski U., Kugel H., Engelen J., Dietsche B., Krug A., Kircher T., Fieremans E., Veraart J., Novikov D.S., Boedhoe P.S.W., van der Werf Y.D., van den Heuvel O.A., Ipser J., Uhlmann A., Stein D.J., Dickie E., Voineskos A.N., Malhotra A.K., Pizzagalli F., Calhoun V.D., Waller L., Veer I.M., Walter H., Buchanan R.W., Glahn D.C., Hong L.E., Thompson P.M., Kochunov P.","35725098200;8517650500;56988740400;7404250345;37101507600;13806470600;26643516600;57201653630;55224682400;24166628400;55724907000;23008075900;36199096900;7102213414;57189300122;6603160309;6603278935;15047989200;56030860100;55769747571;23033654500;6504704378;7201832955;54788271300;7003595227;57193790216;25931182000;7201499004;7202409082;6603114543;57200164603;7403220237;55894435200;","A resting state fMRI analysis pipeline for pooling inference across diverse cohorts: an ENIGMA rs-fMRI protocol",2019,"Brain Imaging and Behavior","13","5",,"1453","1467",,5,"10.1007/s11682-018-9941-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053437315&doi=10.1007%2fs11682-018-9941-x&partnerID=40&md5=e360915bdc8b63fb7fa0ef857fdd66f1","Maryland Psychiatric Research Center, Department of Psychiatry, University of Maryland School of Medicine, Baltimore, MD, United States; Imaging Genetics Center, Keck School of Medicine of USC, Marina del Rey, Los Angeles, CA, United States; Department of Psychology, Georgia State University, Atlanta, GA, United States; Department of Psychiatry, University of Münster, Münster, Germany; Department of Clinical Radiology, University of Münster, Münster, Germany; Department of Psychiatry and Psychotherapy, Philipps-University Marburg, Marburg, Germany; Center for Biomedical Imaging, Department of Radiology, New York University School of Medicine, New York, NY, United States; Department of Psychiatry, Department of Anatomy & Neurosciences, VU University Medical Center, Amsterdam, Netherlands; Department of Psychiatry and Mental Health, University of Cape Town, Cape Town, South Africa; Centre for Addiction and Mental Health, Toronto, ON, Canada; Centre for Addiction and Mental Health, Campbell Family Mental Health Research Institute, Toronto, ON, Canada; Department of Psychiatry, University of Toronto, Toronto, ON, Canada; Department of Psychiatry, The Zucker Hillside Hospital, Glen Oaks, New York, NY, United States; The Mind Research Network & The University of New Mexico, Albuquerque, NM, United States; Department of Psychiatry and Psychotherapy, Charité Universitätsmedizin Berlin, Campus Matte, Berlin, Germany; Department of Psychiatry, Yale University, School of Medicine, New Haven, CT, United States","Adhikari, B.M., Maryland Psychiatric Research Center, Department of Psychiatry, University of Maryland School of Medicine, Baltimore, MD, United States; Jahanshad, N., Imaging Genetics Center, Keck School of Medicine of USC, Marina del Rey, Los Angeles, CA, United States; Shukla, D., Maryland Psychiatric Research Center, Department of Psychiatry, University of Maryland School of Medicine, Baltimore, MD, United States; Turner, J., Department of Psychology, Georgia State University, Atlanta, GA, United States; Grotegerd, D., Department of Psychiatry, University of Münster, Münster, Germany; Dannlowski, U., Department of Psychiatry, University of Münster, Münster, Germany; Kugel, H., Department of Clinical Radiology, University of Münster, Münster, Germany; Engelen, J., Department of Psychiatry and Psychotherapy, Philipps-University Marburg, Marburg, Germany; Dietsche, B., Department of Psychiatry and Psychotherapy, Philipps-University Marburg, Marburg, Germany; Krug, A., Department of Psychiatry and Psychotherapy, Philipps-University Marburg, Marburg, Germany; Kircher, T., Department of Psychiatry and Psychotherapy, Philipps-University Marburg, Marburg, Germany; Fieremans, E., Center for Biomedical Imaging, Department of Radiology, New York University School of Medicine, New York, NY, United States; Veraart, J., Center for Biomedical Imaging, Department of Radiology, New York University School of Medicine, New York, NY, United States; Novikov, D.S., Center for Biomedical Imaging, Department of Radiology, New York University School of Medicine, New York, NY, United States; Boedhoe, P.S.W., Department of Psychiatry, Department of Anatomy & Neurosciences, VU University Medical Center, Amsterdam, Netherlands; van der Werf, Y.D., Department of Psychiatry, Department of Anatomy & Neurosciences, VU University Medical Center, Amsterdam, Netherlands; van den Heuvel, O.A., Department of Psychiatry, Department of Anatomy & Neurosciences, VU University Medical Center, Amsterdam, Netherlands; Ipser, J., Department of Psychiatry and Mental Health, University of Cape Town, Cape Town, South Africa; Uhlmann, A., Department of Psychiatry and Mental Health, University of Cape Town, Cape Town, South Africa; Stein, D.J., Department of Psychiatry and Mental Health, University of Cape Town, Cape Town, South Africa; Dickie, E., Centre for Addiction and Mental Health, Toronto, ON, Canada; Voineskos, A.N., Centre for Addiction and Mental Health, Campbell Family Mental Health Research Institute, Toronto, ON, Canada, Department of Psychiatry, University of Toronto, Toronto, ON, Canada; Malhotra, A.K., Department of Psychiatry, The Zucker Hillside Hospital, Glen Oaks, New York, NY, United States; Pizzagalli, F., Imaging Genetics Center, Keck School of Medicine of USC, Marina del Rey, Los Angeles, CA, United States; Calhoun, V.D., The Mind Research Network & The University of New Mexico, Albuquerque, NM, United States; Waller, L., Department of Psychiatry and Psychotherapy, Charité Universitätsmedizin Berlin, Campus Matte, Berlin, Germany; Veer, I.M., Department of Psychiatry and Psychotherapy, Charité Universitätsmedizin Berlin, Campus Matte, Berlin, Germany; Walter, H., Department of Psychiatry and Psychotherapy, Charité Universitätsmedizin Berlin, Campus Matte, Berlin, Germany; Buchanan, R.W., Maryland Psychiatric Research Center, Department of Psychiatry, University of Maryland School of Medicine, Baltimore, MD, United States; Glahn, D.C., Department of Psychiatry, Yale University, School of Medicine, New Haven, CT, United States; Hong, L.E., Maryland Psychiatric Research Center, Department of Psychiatry, University of Maryland School of Medicine, Baltimore, MD, United States; Thompson, P.M., Imaging Genetics Center, Keck School of Medicine of USC, Marina del Rey, Los Angeles, CA, United States; Kochunov, P., Maryland Psychiatric Research Center, Department of Psychiatry, University of Maryland School of Medicine, Baltimore, MD, United States","Large-scale consortium efforts such as Enhancing NeuroImaging Genetics through Meta-Analysis (ENIGMA) and other collaborative efforts show that combining statistical data from multiple independent studies can boost statistical power and achieve more accurate estimates of effect sizes, contributing to more reliable and reproducible research. A meta- analysis would pool effects from studies conducted in a similar manner, yet to date, no such harmonized protocol exists for resting state fMRI (rsfMRI) data. Here, we propose an initial pipeline for multi-site rsfMRI analysis to allow research groups around the world to analyze scans in a harmonized way, and to perform coordinated statistical tests. The challenge lies in the fact that resting state fMRI measurements collected by researchers over the last decade vary widely, with variable quality and differing spatial or temporal signal-to-noise ratio (tSNR). An effective harmonization must provide optimal measures for all quality data. Here we used rsfMRI data from twenty-two independent studies with approximately fifty corresponding T1-weighted and rsfMRI datasets each, to (A) review and aggregate the state of existing rsfMRI data, (B) demonstrate utility of principal component analysis (PCA)-based denoising and (C) develop a deformable ENIGMA EPI template based on the representative anatomy that incorporates spatial distortion patterns from various protocols and populations. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","ENIGMA EPI template; Large multi-site studies; Processing pipelines","anatomy; article; controlled study; effect size; functional magnetic resonance imaging; genetics; human; meta analysis; neuroimaging; pipeline; principal component analysis; rest; scientist; signal noise ratio",Article,"Final",,Scopus,2-s2.0-85053437315
"Konkol M., Kray C.","57193205857;8399247700;","In-depth examination of spatiotemporal figures in open reproducible research",2019,"Cartography and Geographic Information Science","46","5",,"412","427",,1,"10.1080/15230406.2018.1512421","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055341581&doi=10.1080%2f15230406.2018.1512421&partnerID=40&md5=c43868ad9d096785c7c58422d2668600","Institute for Geoinformatics, University of Münster, Münster, Germany","Konkol, M., Institute for Geoinformatics, University of Münster, Münster, Germany; Kray, C., Institute for Geoinformatics, University of Münster, Münster, Germany","Figures such as maps and time series are essential means to visualize spatiotemporal results in scientific papers. Being able to recompute them using the underlying source code and data is thus a core aspect in reproducible research. However, many scientists see the preparation of code and data for publication as an additional burden without immediate benefits. In this work, we investigate advantages and new capabilities of reproducible research papers. Our key contributions are (i) the extension of a geoscientist’s workflow while examining papers including reproducible figures such as maps and (ii) the prototypical implementation of the workflow as a web application. The workflow is based on current practices of geoscientists and encapsulates benefits of reproducible figures. It is informed by ideas and needs identified by geoscientists in a survey, interviews, and a focus group. Based on their statements, we first extend the traditional workflow steps Discovery and Inspection by additional capabilities and propose two new steps: Manipulation of the content of a spatiotemporal figure and Substitution of the underlying code and data. The extended workflow and its implementation might facilitate in-depth examination and reusability of geoscientific results. © 2018, © 2018 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","computational research; interactive figures; Open reproducible research; open science; spatiotemporal analysis","Reusability; Computational researches; interactive figures; Open science; Reproducible research; Spatiotemporal analysis; Codes (symbols); mapping method; research work; spatiotemporal analysis; visualization",Article,"Final",Open Access,Scopus,2-s2.0-85055341581
"Kray C., Pebesma E., Konkol M., Nüst D.","8399247700;6603459366;57193205857;49361950400;","Reproducible research in geoinformatics: Concepts, challenges and benefits",2019,"Leibniz International Proceedings in Informatics, LIPIcs","142",, 8,"","",,,"10.4230/LIPIcs.COSIT.2019.8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072642053&doi=10.4230%2fLIPIcs.COSIT.2019.8&partnerID=40&md5=5862a3f4dff0359409542d7330b90023","Institute for Geoinformatics (ifgi), University of Münster, Germany","Kray, C., Institute for Geoinformatics (ifgi), University of Münster, Germany; Pebesma, E., Institute for Geoinformatics (ifgi), University of Münster, Germany; Konkol, M., Institute for Geoinformatics (ifgi), University of Münster, Germany; Nüst, D., Institute for Geoinformatics (ifgi), University of Münster, Germany","Geoinformatics deals with spatial and temporal information and its analysis. Research in this field often follows established practices of first developing computational solutions for specific spatiotemporal problems and then publishing the results and insights in a (static) paper, e.g. as a PDF. Not every detail can be included in such a paper, and particularly, the complete set of computational steps are frequently left out. While this approach conveys key knowledge to other researchers it makes it difficult to effectively re-use and reproduce the reported results. In this vision paper, we propose an alternative approach to carry out and report research in Geoinformatics. It is based on (computational) reproducibility, promises to make re-use and reproduction more effective, and creates new opportunities for further research. We report on experiences with executable research compendia (ERCs) as alternatives to classic publications in Geoinformatics, and we discuss how ERCs combined with a supporting research infrastructure can transform how we do research in Geoinformatics. We point out which challenges this idea entails and what new research opportunities emerge, in particular for the COSIT community. © 2019 Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing. All rights reserved.","Computational; Geoinformatics; GI Science; Reproducibility; Spatial and temporal information; Spatial data science; Vision paper","Cell proliferation; Information theory; Paper; Computational; Geo-informatics; Reproducibilities; Spatial data; Temporal information; Computation theory",Conference Paper,"Final",,Scopus,2-s2.0-85072642053
"Boulesteix A.-L., Janitza S., Hornung R., Probst P., Busen H., Hapfelmeier A.","8702716900;55574644200;56943075200;57194659012;57210891671;35798264200;","Making complex prediction rules applicable for readers: Current practice in random forest literature and recommendations",2019,"Biometrical Journal","61","5",,"1314","1328",,2,"10.1002/bimj.201700243","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052448458&doi=10.1002%2fbimj.201700243&partnerID=40&md5=442876a066b15f3b900f2c87e7293717","Institute for Medical Information Processing, Biometry and Epidemiology, LMU Munich, Munich, Germany; Institute for Medical Informatics, Statistics and Epidemiology, TUM Munich, Munich, Germany","Boulesteix, A.-L., Institute for Medical Information Processing, Biometry and Epidemiology, LMU Munich, Munich, Germany; Janitza, S., Institute for Medical Information Processing, Biometry and Epidemiology, LMU Munich, Munich, Germany; Hornung, R., Institute for Medical Information Processing, Biometry and Epidemiology, LMU Munich, Munich, Germany; Probst, P., Institute for Medical Information Processing, Biometry and Epidemiology, LMU Munich, Munich, Germany; Busen, H., Institute for Medical Information Processing, Biometry and Epidemiology, LMU Munich, Munich, Germany; Hapfelmeier, A., Institute for Medical Informatics, Statistics and Epidemiology, TUM Munich, Munich, Germany","Ideally, prediction rules should be published in such a way that readers may apply them, for example, to make predictions for their own data. While this is straightforward for simple prediction rules, such as those based on the logistic regression model, this is much more difficult for complex prediction rules derived by machine learning tools. We conducted a survey of articles reporting prediction rules that were constructed using the random forest algorithm and published in PLOS ONE in 2014–2015 in the field “medical and health sciences”, with the aim of identifying issues related to their applicability. Making a prediction rule reproducible is a possible way to ensure that it is applicable; thus reproducibility is also examined in our survey. The presented prediction rules were applicable in only 2 of 30 identified papers, while for further eight prediction rules it was possible to obtain the necessary information by contacting the authors. Various problems, such as nonresponse of the authors, hampered the applicability of prediction rules in the other cases. Based on our experiences from this illustrative survey, we formulate a set of recommendations for authors who aim to make complex prediction rules applicable for readers. All data including the description of the considered studies and analysis codes are available as supplementary materials. © 2018 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","logistic regression; machine learning; prediction rule; reproducibility; reproducible research","algorithm; article; human; human experiment; prediction; random forest; reading; reproducibility",Article,"Final",,Scopus,2-s2.0-85052448458
"Knudtson K.L., Carnahan R.H., Hegstad-Davies R.L., Fisher N.C., Hicks B., Lopez P.A., Meyn S.M., Mische S.M., Weis-Garcia F., White L.D., Sol-Church K.","6603152838;7003616850;6701806859;57212542368;57210905802;57212499190;55780183100;57188693520;57203922419;57212906432;6602918031;","Survey on scientific shared resource rigor and reproducibility",2019,"Journal of Biomolecular Techniques","30","3",,"36","44",,,"10.7171/jbt.19-3003-001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071788504&doi=10.7171%2fjbt.19-3003-001&partnerID=40&md5=759ce68632470aaefb018cf9b9e07594","University of Iowa, Iowa City, IA  52242, United States; Vanderbilt University Medical Center, Nashville, TN  37232, United States; University of Minnesota, Minneapolis, MN  55455, United States; University of North Carolina at Chapel Hill, Chapel Hill, NC  27599, United States; Cancer Genomics Research Laboratory, Frederick National Laboratory for Cancer Research, Frederick, MD  20877, United States; New York University (NYU), Langone Medical Center, New York, NY  10016, United States; Memorial Sloan Kettering Cancer Center, New York, NY  10065, United States; Baylor College Medicine, Houston, TX  77030, United States; University of Virginia, School of Medicine, Pinn Hall, Room 1076, Charlottesville, VA  22908, United States","Knudtson, K.L., University of Iowa, Iowa City, IA  52242, United States; Carnahan, R.H., Vanderbilt University Medical Center, Nashville, TN  37232, United States; Hegstad-Davies, R.L., University of Minnesota, Minneapolis, MN  55455, United States; Fisher, N.C., University of North Carolina at Chapel Hill, Chapel Hill, NC  27599, United States; Hicks, B., Cancer Genomics Research Laboratory, Frederick National Laboratory for Cancer Research, Frederick, MD  20877, United States; Lopez, P.A., New York University (NYU), Langone Medical Center, New York, NY  10016, United States; Meyn, S.M., Vanderbilt University Medical Center, Nashville, TN  37232, United States; Mische, S.M., New York University (NYU), Langone Medical Center, New York, NY  10016, United States; Weis-Garcia, F., Memorial Sloan Kettering Cancer Center, New York, NY  10065, United States; White, L.D., Baylor College Medicine, Houston, TX  77030, United States; Sol-Church, K., University of Virginia, School of Medicine, Pinn Hall, Room 1076, Charlottesville, VA  22908, United States","Shared scientific resources, also known as core facilities, support a significant portion of the research conducted at biomolecular research institutions. The Association of Biomolecular Resource Facilities (ABRF) established the Committee on Core Rigor and Reproducibility (CCoRRe) to further its mission of integrating advanced technologies, education, and communication in the operations of shared scientific resources in support of reproducible research. In order to first assess the needs of the scientific shared resource community, the CCoRRe solicited feedback from ABRF members via a survey. The purpose of the survey was to gain information on how U.S. National Institutes of Health (NIH) initiatives on advancing scientific rigor and reproducibility influenced current services and new technology development. In addition, the survey aimed to identify the challenges and opportunities related to implementation of new reporting requirements and to identify new practices and resources needed to ensure rigorous research. The results revealed a surprising unfamiliarity with the NIH guidelines. Many of the perceived challenges to the effective implementation of best practices (i.e., those designed to ensure rigor and reproducibility) were similarly noted as a challenge to effective provision of support services in a core setting. Further, most cores routinely use best practices and offer services that support rigor and reproducibility. These services include access to well-maintained instrumentation and training on experimental design and data analysis as well as data management. Feedback from this survey will enable the ABRF to build better educational resources and share critical best-practice guidelines. These resources will become important tools to the core community and the researchers they serve to impact rigor and transparency across the range of science and technology. © 2019 ABRF.","Core; Reproducibility; Rigor; Shared resource; Transparency","Article; consultation; core laboratory; cost effectiveness analysis; data analysis; experimental design; feedback system; graduate student; human; information processing; laboratory information system; medical documentation; medical education; medical research; medical technology; mentoring; multiple choice test; national health organization; organizational policy; practice guideline; quality control; reproducibility; scientific literature; standardization; United States",Article,"Final",Open Access,Scopus,2-s2.0-85071788504
"Roy Y., Banville H., Albuquerque I., Gramfort A., Falk T.H., Faubert J.","57204590374;57128487100;57201293695;23388890700;7004897891;7003902219;","Deep learning-based electroencephalography analysis: A systematic review",2019,"Journal of Neural Engineering","16","5", 051001,"","",,6,"10.1088/1741-2552/ab260c","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071350928&doi=10.1088%2f1741-2552%2fab260c&partnerID=40&md5=5e42da93beaa3ff35ba574a336f8d738","Faubert Lab, Université de Montréal, Montréal, Canada; Inria, Université Paris-Saclay, Paris, France; InteraXon Inc., Toronto, Canada; MuSAE Lab, INRS-EMT, Université du Québec, Montréal, Canada","Roy, Y., Faubert Lab, Université de Montréal, Montréal, Canada; Banville, H., Inria, Université Paris-Saclay, Paris, France, InteraXon Inc., Toronto, Canada; Albuquerque, I., MuSAE Lab, INRS-EMT, Université du Québec, Montréal, Canada; Gramfort, A., Inria, Université Paris-Saclay, Paris, France; Falk, T.H., MuSAE Lab, INRS-EMT, Université du Québec, Montréal, Canada; Faubert, J., Faubert Lab, Université de Montréal, Montréal, Canada","Context. Electroencephalography (EEG) is a complex signal and can require several years of training, as well as advanced signal processing and feature extraction methodologies to be correctly interpreted. Recently, deep learning (DL) has shown great promise in helping make sense of EEG signals due to its capacity to learn good feature representations from raw data. Whether DL truly presents advantages as compared to more traditional EEG processing approaches, however, remains an open question. Objective. In this work, we review 154 papers that apply DL to EEG, published between January 2010 and July 2018, and spanning different application domains such as epilepsy, sleep, brain-computer interfacing, and cognitive and affective monitoring. We extract trends and highlight interesting approaches from this large body of literature in order to inform future research and formulate recommendations. Methods. Major databases spanning the fields of science and engineering were queried to identify relevant studies published in scientific journals, conferences, and electronic preprint repositories. Various data items were extracted for each study pertaining to (1) the data, (2) the preprocessing methodology, (3) the DL design choices, (4) the results, and (5) the reproducibility of the experiments. These items were then analyzed one by one to uncover trends. Results. Our analysis reveals that the amount of EEG data used across studies varies from less than ten minutes to thousands of hours, while the number of samples seen during training by a network varies from a few dozens to several millions, depending on how epochs are extracted. Interestingly, we saw that more than half the studies used publicly available data and that there has also been a clear shift from intra-subject to inter-subject approaches over the last few years.across all relevant studies. More importantly, however, we noticed studies often suffer from poor reproducibility: a majority of papers would be hard or impossible to reproduce given the unavailability of their data and code. Significance. To help the community progress and share work more effectively, we provide a list of recommendations for future studies and emphasize the need for more reproducible research. We also make our summary table of DL and EEG papers available and invite authors of published work to contribute to it directly. A planned follow-up to this work will be an online public benchmarking portal listing reproducible results. © 2019 IOP Publishing Ltd.",,"Biomedical signal processing; Data mining; Electroencephalography; Electrophysiology; Engineering research; Advanced signal processing; Brain-computer interfacing; Feature representation; Processing approach; Reproducibilities; Reproducible research; Science and engineering; Scientific journals; Deep learning; benchmarking; bibliographic database; brain computer interface; computer vision; convolutional neural network; deep belief network; deep learning; deep neural network; electroencephalography; epilepsy; feature extraction; follow up; human; long term memory; meta analysis; priority journal; recurrent neural network; Review; short term memory; signal processing; sleep; systematic review",Review,"Final",Open Access,Scopus,2-s2.0-85071350928
"Godlove D.","57213102935;","Singularity",2019,"ACM International Conference Proceeding Series",,, 3332192,"","",,,"10.1145/3332186.3332192","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071018163&doi=10.1145%2f3332186.3332192&partnerID=40&md5=99b9e5dfa8ba6233c3d3fdf4d50c9fdc","Sylabs Inc., Albany, CA, United States","Godlove, D., Sylabs Inc., Albany, CA, United States","Container technology makes it easy to create highly portable and reproducible research environments. The Singularity container platform has a unique security model allowing untrusted users to run untrusted containers safely on multi-tenant systems. Singularity has a special file format (called the Singularity Image Format or SIF) for packaging and distributing containers. This format allows for novel features like cryptographic signing and verification of containers, extreme portability, and guaranteed reproducibility. The Singularity runtime supports both integration as well as isolation, making it easy to read and write data to the host system, leverage hardware like GPUs and high-speed interconnects, and integrate with batch schedulers like Slurm, PBS, LSF, UGE, etc. This emphasis on integration is part of the overall development philosophy: Singularity is intended to be a simple, secure, feature-rich container solution. Sylabs Inc. has developed SingularityPRO, a professionally curated and supported version of the open source offering as well as the Singularity Container Services, an end-to-end cloud hosted solution for creating and distributing trusted containers. Most top HPC centers use Singularity in production, and enterprise users are rapidly adopting this solution as well. © 2019 Copyright is held by the owner/author(s). Publication rights licensed to ACM.","Cloud native; Kubernetes; Linux containers; Reproducible science","Computer operating systems; Learning systems; Program processors; Batch schedulers; High-speed interconnects; Highly-portable; Kubernetes; Reproducibilities; Reproducible research; Reproducible science; Runtime support; Containers",Conference Paper,"Final",,Scopus,2-s2.0-85071018163
"Slater L.J., Thirel G., Harrigan S., Delaigue O., Hurley A., Khouakhi A., Prosdocimi I., Vitolo C., Smith K.","14030760900;26533302300;55073248000;55650039500;57197787935;25959184500;36629151900;56414898900;57210363448;","Using R in hydrology: A review of recent developments and future directions",2019,"Hydrology and Earth System Sciences","23","7",,"2939","2963",,,"10.5194/hess-23-2939-2019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068931142&doi=10.5194%2fhess-23-2939-2019&partnerID=40&md5=f55bbd8dca137eaeba3510a8dc615041","School of Geography and the Environment, University of Oxford, Oxford, OX1 3QY, United Kingdom; HYCAR Research Unit, IRSTEA, 1 Rue Pierre-Gilles de Gennes, Antony, 92160, France; Forecast Department, European Centre for Medium-Range Weather Forecasts (ECMWF), Shinfield Park, Reading, RG2 9AX, United Kingdom; School of Geography, Earth and Environmental Sciences, University of Birmingham, Birmingham, B15 2TT, United Kingdom; School of Architecture, Building and Civil Engineering, Loughborough University, Loughborough, LE11 3TU, United Kingdom; Department of Environmental Sciences, Informatics and Statistics, Ca' Foscari University of Venice, Venice, 30172, Italy; Centre for Ecology and Hydrology, Maclean Building, Crowmarsh Gifford, Wallingford, OX10 8BB, United Kingdom","Slater, L.J., School of Geography and the Environment, University of Oxford, Oxford, OX1 3QY, United Kingdom; Thirel, G., HYCAR Research Unit, IRSTEA, 1 Rue Pierre-Gilles de Gennes, Antony, 92160, France; Harrigan, S., Forecast Department, European Centre for Medium-Range Weather Forecasts (ECMWF), Shinfield Park, Reading, RG2 9AX, United Kingdom; Delaigue, O., HYCAR Research Unit, IRSTEA, 1 Rue Pierre-Gilles de Gennes, Antony, 92160, France; Hurley, A., School of Geography, Earth and Environmental Sciences, University of Birmingham, Birmingham, B15 2TT, United Kingdom; Khouakhi, A., School of Architecture, Building and Civil Engineering, Loughborough University, Loughborough, LE11 3TU, United Kingdom; Prosdocimi, I., Department of Environmental Sciences, Informatics and Statistics, Ca' Foscari University of Venice, Venice, 30172, Italy; Vitolo, C., Forecast Department, European Centre for Medium-Range Weather Forecasts (ECMWF), Shinfield Park, Reading, RG2 9AX, United Kingdom; Smith, K., Centre for Ecology and Hydrology, Maclean Building, Crowmarsh Gifford, Wallingford, OX10 8BB, United Kingdom","The open-source programming language R has gained a central place in the hydrological sciences over the last decade, driven by the availability of diverse hydro-meteorological data archives and the development of open-source computational tools. The growth of R's usage in hydrology is reflected in the number of newly published hydrological packages, the strengthening of online user communities, and the popularity of training courses and events. In this paper, we explore the benefits and advantages of R's usage in hydrology, such as the democratization of data science and numerical literacy, the enhancement of reproducible research and open science, the access to statistical tools, the ease of connecting R to and from other languages, and the support provided by a growing community. This paper provides an overview of a typical hydrological workflow based on reproducible principles and packages for retrieval of hydro-meteorological data, spatial analysis, hydrological modelling, statistics, and the design of static and dynamic visualizations and documents. We discuss some of the challenges that arise when using R in hydrology and useful tools to overcome them, including the use of hydrological libraries, documentation, and vignettes (long-form guides that illustrate how to use packages); the role of integrated development environments (IDEs); and the challenges of big data and parallel computing in hydrology. Lastly, this paper provides a roadmap for R's future within hydrology, with R packages as a driver of progress in the hydrological sciences, application programming interfaces (APIs) providing new avenues for data acquisition and provision, enhanced teaching of hydrology in R, and the continued growth of the community via short courses and events. © Author(s) 2019.",,"Application programming interfaces (API); Curricula; Data acquisition; Meteorology; Open access; Open source software; Statistical mechanics; Computational tools; Dynamic visualization; Hydrological modelling; Integrated development environment; Meteorological data; Open-source programming; Reproducible research; Statistical tools; Hydrology; data acquisition; democratization; future prospect; hydrological modeling; hydrology; hydrometeorology; linear programing; parallel computing; research method; visualization; Apis",Review,"Final",Open Access,Scopus,2-s2.0-85068931142
"Page N., Langford M., Higgs G.","55789599400;7006486730;7006202570;","Measuring Spatial Accessibility to Services within Indices of Multiple Deprivation: Implications of Applying an Enhanced two-Step Floating Catchment Area (E2SFCA) Approach",2019,"Applied Spatial Analysis and Policy","12","2",,"321","348",,,"10.1007/s12061-017-9246-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039550132&doi=10.1007%2fs12061-017-9246-2&partnerID=40&md5=cc46eb8d539f0015500c4d1b2f487cf4","Wales Institute of Social and Economic Research, Data and Methods (WISERD) and GIS Research Centre, Faculty of Computing, Engineering and Science, University of South Wales, Pontypridd, CF37 IDL, United Kingdom","Page, N., Wales Institute of Social and Economic Research, Data and Methods (WISERD) and GIS Research Centre, Faculty of Computing, Engineering and Science, University of South Wales, Pontypridd, CF37 IDL, United Kingdom; Langford, M., Wales Institute of Social and Economic Research, Data and Methods (WISERD) and GIS Research Centre, Faculty of Computing, Engineering and Science, University of South Wales, Pontypridd, CF37 IDL, United Kingdom; Higgs, G., Wales Institute of Social and Economic Research, Data and Methods (WISERD) and GIS Research Centre, Faculty of Computing, Engineering and Science, University of South Wales, Pontypridd, CF37 IDL, United Kingdom","Approaches to calculating spatial accessibility within existing indices of multiple deprivation (IMD) methodologies are based on ‘traditional’ accessibility metrics and tend not to adopt more recent methodological enhancements. In particular, the last decade has seen a relatively large body of studies that have applied floating catchment area (FCA) methods that account for both service supply and potential demand interactions, mediated by the impact of distance, in a wide range of application areas. In this paper, we investigate potential implications of incorporating an FCA-based approach to measuring spatial accessibility within an existing IMD framework. Using the Welsh Index of Multiple Deprivation (WIMD) as a case study, FCA-derived accessibility scores were substituted for the existing approach used to calculate accessibility and a revised index was computed. The published methodologies used to construct the other ‘domains’ within the WIMD were followed and the implications for the overall deprivation measure were assessed. Statistical and visualisation tools revealed implications for both the access and overall IMD rankings, with sparsely populated (predominantly rural) areas tending to receive higher accessibility scores from FCA-based approaches than more densely populated (predominantly urban) areas. These areas in turn showed the greatest decline in ranking on the WIMD calculations following the application of FCA approaches. Potential reasons for such trends are posited before we conclude by drawing attention to the implications of adopting FCA-based approaches to calculate IMDs particularly for those policies designed to distribute funds or allocate resources to areas of need. © 2017, Springer Science+Business Media B.V., part of Springer Nature.","Accessibility; Indices of multiple deprivation; Reproducible research; Two-step floating catchment area","accessibility; detection method; measurement method; methodology; resource allocation; spatial analysis; urban area",Article,"Final",,Scopus,2-s2.0-85039550132
"Sullivan I., DeHaven A., Mellor D.","57213407142;57201200401;36721992500;","Open and Reproducible Research on Open Science Framework",2019,"Current Protocols in Essential Laboratory Techniques","18","1", e32,"","",,2,"10.1002/cpet.32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064569839&doi=10.1002%2fcpet.32&partnerID=40&md5=638caeb0e715b4cfca37b61d3c75444e","Center for Open Science, Charlottesville, VA, United States","Sullivan, I., Center for Open Science, Charlottesville, VA, United States; DeHaven, A., Center for Open Science, Charlottesville, VA, United States; Mellor, D., Center for Open Science, Charlottesville, VA, United States","By implementing more transparent research practices, authors have the opportunity to stand out and showcase work that is more reproducible, easier to build upon, and more credible. Scientists gain by making work easier to share and maintain within their own laboratories, and the scientific community gains by making underlying data or research materials more available for confirmation or making new discoveries. The following protocol gives authors step-by-step instructions for using the free and open source Open Science Framework (OSF) to create a data management plan, preregister their study, use version control, share data and other research materials, or post a preprint for quick and easy dissemination. © 2019 by John Wiley & Sons, Inc. © 2019 John Wiley & Sons, Inc.","data management; open data; open science; preregistration; reproducible research","article; human; publication; scientist",Article,"Final",Open Access,Scopus,2-s2.0-85064569839
"Muenchow J., Schäfer S., Krüger E.","54416073200;57195284960;57209328578;","Reviewing qualitative GIS research—Toward a wider usage of open-source GIS and reproducible research practices",2019,"Geography Compass","13","6", e12441,"","",,,"10.1111/gec3.12441","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067387953&doi=10.1111%2fgec3.12441&partnerID=40&md5=ebc8dbf49b298822aabf0b1e0405544f","Institute of Geography, Friedrich Schiller University Jena, Germany","Muenchow, J., Institute of Geography, Friedrich Schiller University Jena, Germany; Schäfer, S., Institute of Geography, Friedrich Schiller University Jena, Germany; Krüger, E., Institute of Geography, Friedrich Schiller University Jena, Germany","Geographic Information Systems (GIS) have become an indispensable tool in all fields dealing with geographic data in academia as well as the public and private sector. After some initial reservations, human geography and other social sciences have also embraced GIS technologies especially by extending and adjusting the available data models for qualitative data. The result was coined qualitative GIS. Given the diversity and fragmentation of the research in which qualitative GIS have been applied, a comprehensive literature review is overdue. Therefore, we retrieved all articles that dealt with qualitative GIS from the ISI Web of Science. From the resulting 380 relevant manuscripts, we extracted study-specific information and analyzed it by means of descriptive statistics, text mining, detrended correspondence analysis (DCA), and k-means clustering. Our results reveal four major thematic domains within which qualitative GIS research takes place, namely, “conceptual contributions to qualitative GIS,” “theory and empiricism of public participation GIS,” “health, youth, and the urban environment,” and “ecosystem services, landscapes, and tourism”. Some of these trends are popular in specific regions (e.g., “ecosystem services, landscapes, and tourism” research in Australia). Furthermore, we found that a large body of studies lacks clear information on the used software packages and that the share of free open-source GIS software is negligible. Overall, we would encourage more transparency, a wider use of open-source software, and interdisciplinary collaboration to even further advance and promote qualitative GIS research. To put our recommendations into practice, we made the data used in this manuscript and the corresponding analysis publicly accessible (https://github.com/jannes-m/qual_gis). To further facilitate the replication of our results, we exclusively used open-source software, namely, R, leaflet, and PostgreSQL. These and other open-source software packages, for example, Python and QGIS, might have the potential to fundamentally change the way to conduct qualitative GIS research. This is equally true for methods borrowed from other fields such as ordinations, cluster algorithms, and interactive web mapping, which might be promising tools in human geography and the social sciences. © 2019 The Author(s) Geography Compass © 2019 John Wiley & Sons Ltd","interdisciplinary collaboration; open-source software; qualitative GIS; reproducible research; synthesis; text mining","algorithm; data mining; GIS; interdisciplinary approach; literature review; qualitative analysis; software; Australia",Article,"Final",,Scopus,2-s2.0-85067387953
"Barker M., Olabarriaga S.D., Wilkins-Diehr N., Gesing S., Katz D.S., Shahand S., Henwood S., Glatard T., Jeffery K., Corrie B., Treloar A., Glaves H., Wyborn L., Hong N.P.C., Costa A.","57192395945;55918790000;6506826243;35408907000;49661664400;35148552700;55859810500;16177066500;14830351800;6602493336;22939397700;53864956800;6701353685;56708168900;22834392900;","The global impact of science gateways, virtual research environments and virtual laboratories",2019,"Future Generation Computer Systems","95",,,"240","248",,7,"10.1016/j.future.2018.12.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059853566&doi=10.1016%2fj.future.2018.12.026&partnerID=40&md5=19c7b74376123a16aaf5caf7a084517a","National eResearch Collaboration Tools and Resources and James Cook University, Australia; Amsterdam Medical Centers – Location AMC, University of Amsterdam, Netherlands; San Diego Supercomputer Center, University of California San Diego, United States; Department of Computer Science and Engineering/Center for Research Computing, University of Notre Dame, United States; National Center for Supercomputing Applications, Department of Computer Science, Department of Electrical and Computer Engineering, School of Information Sciences, University of Illinois at Urbana-Champaign, United States; ServiceNow and Academic Medical Center – University of Amsterdam, Netherlands; CANARIE, Canada; Department of Computer Science and Software Engineering, Concordia University, Canada; VRE4EIC and ERCIM, United Kingdom; Simon Fraser University, Canada; New Zealand eScience Infrastructure, New Zealand; Australian National Data Service, Australia; British Geological Survey, United Kingdom; National Computational Infrastructure Facility and The Research School of Earth Sciences, Australian National University, Australia; University of Edinburgh, United Kingdom; INAF, Italy","Barker, M., National eResearch Collaboration Tools and Resources and James Cook University, Australia; Olabarriaga, S.D., Amsterdam Medical Centers – Location AMC, University of Amsterdam, Netherlands; Wilkins-Diehr, N., San Diego Supercomputer Center, University of California San Diego, United States; Gesing, S., Department of Computer Science and Engineering/Center for Research Computing, University of Notre Dame, United States; Katz, D.S., National Center for Supercomputing Applications, Department of Computer Science, Department of Electrical and Computer Engineering, School of Information Sciences, University of Illinois at Urbana-Champaign, United States; Shahand, S., ServiceNow and Academic Medical Center – University of Amsterdam, Netherlands; Henwood, S., CANARIE, Canada; Glatard, T., Department of Computer Science and Software Engineering, Concordia University, Canada; Jeffery, K., VRE4EIC and ERCIM, United Kingdom; Corrie, B., Simon Fraser University, Canada, New Zealand eScience Infrastructure, New Zealand; Treloar, A., Australian National Data Service, Australia; Glaves, H., British Geological Survey, United Kingdom; Wyborn, L., National Computational Infrastructure Facility and The Research School of Earth Sciences, Australian National University, Australia; Hong, N.P.C., University of Edinburgh, United Kingdom; Costa, A., INAF, Italy","Science gateways, virtual laboratories and virtual research environments are all terms used to refer to community-developed digital environments that are designed to meet a set of needs for a research community. Specifically, they refer to integrated access to research community resources including software, data, collaboration tools, workflows, instrumentation and high-performance computing, usually via Web and mobile applications. Science gateways, virtual laboratories and virtual research environments are enabling significant contributions to many research domains, facilitating more efficient, open, reproducible research in bold new ways. This paper explores the global impact achieved by the sum effects of these programs in increasing research impact, demonstrates their value in the broader digital landscape and discusses future opportunities. This is evidenced through examination of national and international programs in this field. © 2019 Elsevier B.V.","Cyberinfrastructure; e-infrastructure; Open science; Science gateways; Virtual laboratories; Virtual research environments","Application programs; Cyber infrastructures; E-infrastructures; Open science; Science gateway; Virtual laboratories; Virtual research environment; Laboratories",Article,"Final",,Scopus,2-s2.0-85059853566
"Konkol M., Kray C., Suleiman J.","57193205857;8399247700;57209507230;","Creating interactive scientific publications using bindings",2019,"Proceedings of the ACM on Human-Computer Interaction","3","EICS", 16,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067944699&partnerID=40&md5=3de1001f7f44704d35f8de2154019e11","University of Münster, Institute for Geoinformatics, Heisenbergstrasse 2, NRW, Münster, 48149, Germany","Konkol, M., University of Münster, Institute for Geoinformatics, Heisenbergstrasse 2, NRW, Münster, 48149, Germany; Kray, C., University of Münster, Institute for Geoinformatics, Heisenbergstrasse 2, NRW, Münster, 48149, Germany; Suleiman, J., University of Münster, Institute for Geoinformatics, Heisenbergstrasse 2, NRW, Münster, 48149, Germany","Many scientific publications report on computational results based on code and data, but even when code and data are published, the main text is usually provided in a separate, traditional format such as PDF. Since code, data, and text are not linked on a deep level, it is difficult for readers and reviewers to understand and retrace how the authors achieved a specific result that is reported in the main text, e.g. a figure, table, or number. In addition, to make use of new the opportunities afforded by data and code availability, such as re-running analyses with changed parameters, considerable effort is required. In order to overcome this issue and to enable more interactive publications that support scientists in more deeply exploring the reported results, we present the concept, implementation, and initial evaluation of bindings. A binding describes which data subsets, code lines, and parameters produce a specific result that is reported in the main text (e.g. as a figure, table, or number). Based on a prototypical implementation of these bindings, we propose a toolkit for authors to easily create interactive figures by connecting specific UI widgets (e.g. a slider) to parameters. In addition to inspecting code and data, readers can then manipulate the parameter and see how the results change. We evaluated the approach by applying it to a set of existing articles. The results provide initial evidence that the concept is feasible and applicable to many papers with moderate effort. © 2019 Copyright held by the owner/author(s).","Interactive papers; Open science; Reproducible research; Research compendia","Publishing; Computational results; Data subsets; Interactive paper; Main texts; Open science; Prototypical implementation; Reproducible research; Scientific publications; Codes (symbols)",Article,"Final",,Scopus,2-s2.0-85067944699
"Cruz S.M.S.D., Nascimento J.A.P.D.","23476751900;57206937989;","Towards integration of data-driven agronomic experiments with data provenance",2019,"Computers and Electronics in Agriculture","161",,,"14","28",,,"10.1016/j.compag.2019.01.044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062153231&doi=10.1016%2fj.compag.2019.01.044&partnerID=40&md5=deaf94d01b2e513e0a57576ebf29988a","Federal Rural University of Rio de Janeiro (UFRRJ), Department of Computer Sciences, BR-465, Km 7 – Room 80 – P1, CEP. 23.897-000, SeropédicaRJ, Brazil; Brazilian Agricultural Research Corporation (Embrapa), BR-465, Km 7 – Bairro Ecologia, CEP: 23891-000, SeropédicaRJ, Brazil","Cruz, S.M.S.D., Federal Rural University of Rio de Janeiro (UFRRJ), Department of Computer Sciences, BR-465, Km 7 – Room 80 – P1, CEP. 23.897-000, SeropédicaRJ, Brazil; Nascimento, J.A.P.D., Brazilian Agricultural Research Corporation (Embrapa), BR-465, Km 7 – Bairro Ecologia, CEP: 23891-000, SeropédicaRJ, Brazil","With improvements in computing and communications, the amount of scientific data in agriculture has been exploding. Thus, researchers must rely on computational simulations to model the data-driven in silico agronomic experiments, the in silico experiments are those that are completely executed by using computer models. Reproducibility, transparency, independent verification are major features of Science. However, even agricultural research of exemplary quality may have irreproducible empirical findings because of random or systematic error. Funding agencies, researchers, and reviewers are demanding improved processes and the use of open data to increase reproducibility of those experiments. Currently, there are no scientific criteria to evaluate the integration of data-driven agronomic experiments with data provenance. We propose RFlow, a framework that aid researchers to manage, share, and enact the scientific in silico experiments of research projects that use reusable R scripts. The framework uses open data standards and transparently captures provenance of the agronomic experiments. RFlow is non-intrusive, can be connected to workflow systems and does not require researchers to change their working way. Our computational experiments show that the framework can collect provenance metadata and enrich a scientific project. This study shows how RFlow can serve as the primary integration platform for statistical systems, like R, with implications for other data and compute-intensive agronomic projects. As a proof of concept, we show the concrete effectiveness and expressive power of the RFlow which was evaluated through a set of data-driven agronomic in silico experiments and provenance SQL queries that exemplifies what kind of information was gathered. © 2019 Elsevier B.V.","Agriculture; Data analysis; Provenance; Reproducible research; Scientific workflows; Scripts","Agriculture; Agronomy; Data reduction; Integration; Open Data; Agricultural research; Computational experiment; Computational simulation; Integration platform; Provenance; Reproducible research; Scientific workflows; Scripts; Data integration; agricultural research; agriculture; agronomy; computer simulation; data assimilation; experimental study; metadata; project management; statistical analysis",Article,"Final",,Scopus,2-s2.0-85062153231
"Feger S.S., Dallmeier-Tiessen S., Woźniak P.W., Schmidt A.","56893703100;55496905200;55879280600;57204719065;","Gamification in science: A study of requirements in the context of reproducible research",2019,"Conference on Human Factors in Computing Systems - Proceedings",,,,"","",,1,"10.1145/3290605.3300690","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067308884&doi=10.1145%2f3290605.3300690&partnerID=40&md5=fa0ae976be8fa5243fcd797df975c0a6","LMU Munich, Munich, Germany; CERN, Geneva, Switzerland; Utrecht University, Utrecht, Netherlands","Feger, S.S., LMU Munich, Munich, Germany, CERN, Geneva, Switzerland; Dallmeier-Tiessen, S., CERN, Geneva, Switzerland; Woźniak, P.W., Utrecht University, Utrecht, Netherlands; Schmidt, A., LMU Munich, Munich, Germany","The need for data preservation and reproducible research is widely recognized in the scientific community. Yet, researchers often struggle to find the motivation to contribute to data repositories and to use tools that foster reproducibility. In this paper, we explore possible uses of gamification to support reproducible practices in High Energy Physics. To understand how gamification can be effective in research tools, we participated in a workshop and performed interviews with data analysts. We then designed two interactive prototypes of a research preservation service that use contrasting gamification strategies. The evaluation of the prototypes showed that gamification needs to address core scientific challenges, in particular the fair reflection of quality and individual contribution. Through thematic analysis, we identified four themes which describe perceptions and requirements of gamification in research: Contribution, Metrics, Applications and Scientific practice. Based on these, we discuss design implications for gamification in science. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.","Game design elements; Gamification; Research reproducibility; Science","Design; High energy physics; Human computer interaction; Human engineering; Data preservations; Design implications; Game design; Gamification; Reproducibilities; Reproducible research; Science; Scientific community; Quality control",Conference Paper,"Final",,Scopus,2-s2.0-85067308884
"Feger S.S., Dallmeier-Tiessen S., Schmidt A., Woźniak P.W.","56893703100;55496905200;57204719065;55879280600;","Designing for reproducibility: A qualitative study of challenges and opportunities in high energy physics",2019,"Conference on Human Factors in Computing Systems - Proceedings",,,,"","",,1,"10.1145/3290605.3300685","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067302955&doi=10.1145%2f3290605.3300685&partnerID=40&md5=e79048848ab10fe1710fdd9eb9c58c99","LMU Munich, Munich, Germany; CERN, Geneva, Switzerland; Utrecht University, Utrecht, Netherlands","Feger, S.S., LMU Munich, Munich, Germany, CERN, Geneva, Switzerland; Dallmeier-Tiessen, S., CERN, Geneva, Switzerland; Schmidt, A., LMU Munich, Munich, Germany; Woźniak, P.W., Utrecht University, Utrecht, Netherlands","Reproducibility should be a cornerstone of scientific research and is a growing concern among the scientific community and the public. Understanding how to design services and tools that support documentation, preservation and sharing is required to maximize the positive impact of scientific research. We conducted a study of user attitudes towards systems that support data preservation in High Energy Physics, one of science’s most data-intensive branches. We report on our interview study with 12 experimental physicists, studying requirements and opportunities in designing for research preservation and reproducibility. Our findings suggest that we need to design for motivation and benefits in order to stimulate contributions and to address the observed scalability challenge. Therefore, researchers’ attitudes towards communication, uncertainty, collaboration and automation need to be reflected in design. Based on our findings, we present a systematic view of user needs and constraints that define the design space of systems supporting reproducible practices. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.","Design requirements; Interview study; Reproducible research; Secondary usage forms","Human computer interaction; Human engineering; Data preservations; Interview study; Qualitative study; Reproducibilities; Reproducible research; Scientific community; Scientific researches; Support documentation; High energy physics",Conference Paper,"Final",,Scopus,2-s2.0-85067302955
"De C. Wang P., Soares V.S., De Souza J.M., Esteves M.G.P., Schots N.C.L., Duarte F.R.","57210809833;57210797010;7103050923;8209508400;56454375700;55953911800;","A crowd science framework to support the construction of a gold standard corpus for plagiarism detection",2019,"Proceedings of the 2019 IEEE 23rd International Conference on Computer Supported Cooperative Work in Design, CSCWD 2019",,, 8791853,"440","445",,,"10.1109/CSCWD.2019.8791853","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071424175&doi=10.1109%2fCSCWD.2019.8791853&partnerID=40&md5=f0e45c0fe06f9ba92920165d32bb2ef5","IM/UFRRJ, Computer Science School, Federal Rural University of Rio de Janeiro, Brazil; PESC/COPPE/UFRJ, Graduate School of Engineering, Federal University of Rio de Janeiro, Brazil","De C. Wang, P., IM/UFRRJ, Computer Science School, Federal Rural University of Rio de Janeiro, Brazil; Soares, V.S., IM/UFRRJ, Computer Science School, Federal Rural University of Rio de Janeiro, Brazil; De Souza, J.M., PESC/COPPE/UFRJ, Graduate School of Engineering, Federal University of Rio de Janeiro, Brazil; Esteves, M.G.P., PESC/COPPE/UFRJ, Graduate School of Engineering, Federal University of Rio de Janeiro, Brazil; Schots, N.C.L., IM/UFRRJ, Computer Science School, Federal Rural University of Rio de Janeiro, Brazil; Duarte, F.R., IM/UFRRJ, Computer Science School, Federal Rural University of Rio de Janeiro, Brazil","The construction of a Gold Standard Corpus for Plagiarism Detection (GSCPD) is a challenging task for reproducible research in computer science, given that there is a trade off between the time expended by the experts and the size, quality, and reliability of a GSCPD. In such a challenging scenario, this paper describes a framework to support the construction of a GSCPD in any language. Aiming for reproducibility and scalability, the framework involves a data acquisition process and a Crowd Science project that employs human processing power to identify plagiarism in pairs of textual data extracted via the data acquisition process. This papers also presents the application of this framework in Portuguese language and the preliminary results of a feasibility study about the use of a tool that composes the framework. © 2019 IEEE.","Crowd Science; Crowdsourcing; Gold standard corpus; Plagiarism detection","Crowdsourcing; Data acquisition; Economic and social effects; Interactive computer systems; Acquisition process; Crowd Science; Feasibility studies; Gold standards; Plagiarism detection; Portuguese languages; Reproducibilities; Reproducible research; Intellectual property",Conference Paper,"Final",,Scopus,2-s2.0-85071424175
"Li J.","24481536100;","A critical review of spatial predictive modeling process in environmental sciences with reproducible examples in R",2019,"Applied Sciences (Switzerland)","9","10", 2048,"","",,1,"10.3390/app9102048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066498398&doi=10.3390%2fapp9102048&partnerID=40&md5=d9048ca7a849074ad20368fde35ca34d","National Earth and Marine Observations Branch, Environmental Geoscience Division, Geoscience Australia, Canberra, ACT  2601, Australia","Li, J., National Earth and Marine Observations Branch, Environmental Geoscience Division, Geoscience Australia, Canberra, ACT  2601, Australia","Spatial predictive methods are increasingly being used to generate predictions across various disciplines in environmental sciences. Accuracy of the predictions is critical as they form the basis for environmental management and conservation. Therefore, improving the accuracy by selecting an appropriate method and then developing the most accurate predictive model(s) is essential. However, it is challenging to select an appropriate method and find the most accurate predictive model for a given dataset due to many aspects and multiple factors involved in the modeling process. Many previous studies considered only a portion of these aspects and factors, often leading to sub-optimal or even misleading predictive models. This study evaluates a spatial predictive modeling process, and identifies nine major components for spatial predictive modeling. Each of these nine components is then reviewed, and guidelines for selecting and applying relevant components and developing accurate predictive models are provided. Finally, reproducible examples using spm, an R package, are provided to demonstrate how to select and develop predictive models using machine learning, geostatistics, and their hybrid methods according to predictive accuracy for spatial predictive modeling; reproducible examples are also provided to generate and visualize spatial predictions in environmental sciences. © 2019 by the authors.","Feature selection; Model assessment; Model validation; Predictive accuracy; Reproducible research; Spatial predictions; Spatial predictive models; Variable selection",,Review,"Final",Open Access,Scopus,2-s2.0-85066498398
"Baumer B.S.","54580607300;","A Grammar for Reproducible and Painless Extract-Transform-Load Operations on Medium Data",2019,"Journal of Computational and Graphical Statistics","28","2",,"256","264",,,"10.1080/10618600.2018.1512867","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055674459&doi=10.1080%2f10618600.2018.1512867&partnerID=40&md5=98ad2fe5f130295751adae91de3f0ed2","Program in Statistical and Data Sciences, Smith College, Northampton, MA, United States","Baumer, B.S., Program in Statistical and Data Sciences, Smith College, Northampton, MA, United States","Many interesting datasets available on the Internet are of a medium size—too big to fit into a personal computer’s memory, but not so large that they would not fit comfortably on its hard disk. In the coming years, datasets of this magnitude will inform vital research in a wide array of application domains. However, due to a variety of constraints they are cumbersome to ingest, wrangle, analyze, and share in a reproducible fashion. These obstructions hamper thorough peer-review and thus disrupt the forward progress of science. We propose a predictable and pipeable framework for R (the state-of-the-art statistical computing environment) that leverages SQL (the venerable database architecture and query language) to make reproducible research on medium data a painless reality. Supplementary material for this article is available online. © 2018, © 2018 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.","Data wrangling; Databases; Reproducibility; Statistical computing",,Article,"Final",,Scopus,2-s2.0-85055674459
"Goodman S.N.","35404606500;","Why is Getting Rid of P-Values So Hard? Musings on Science and Statistics",2019,"American Statistician","73","sup1",,"26","30",,6,"10.1080/00031305.2018.1558111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063213423&doi=10.1080%2f00031305.2018.1558111&partnerID=40&md5=908f69c9821308dcc9ddb846724b5073","Departments of Medicine and Health Research and Policy, Stanford University, Stanford, CA, United States","Goodman, S.N., Departments of Medicine and Health Research and Policy, Stanford University, Stanford, CA, United States","The current concerns about reproducibility have focused attention on proper use of statistics across the sciences. This gives statisticians an extraordinary opportunity to change what are widely regarded as statistical practices detrimental to the cause of good science. However, how that should be done is enormously complex, made more difficult by the balkanization of research methods and statistical traditions across scientific subdisciplines. Working within those sciences while also allying with science reform movements—operating simultaneously on the micro and macro levels—are the key to making lasting change in applied science. © 2019, © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","P-values; Reproducible research; Scientific inference; Statistical inference",,Article,"Final",Open Access,Scopus,2-s2.0-85063213423
"Sayre F., Riegelman A.","57200305866;57200303430;","Replicable services for reproducible research: A model for academic libraries",2019,"College and Research Libraries","80","2",,"195","",,,"10.5860/crl.80.2.260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064207888&doi=10.5860%2fcrl.80.2.260&partnerID=40&md5=8ccc55b02f145e822e0a7402e48b1d7f","University of Minnesota Twin Cities, United States","Sayre, F., University of Minnesota Twin Cities, United States; Riegelman, A., University of Minnesota Twin Cities, United States","Over the past decade, evidence from disciplines ranging from biology to economics has suggested that many scientific studies may not be reproducible. This has led to declarations in both the scientific and lay press that science is experiencing a “reproducibility crisis” and that this crisis has consequences for the extent to which students, faculty, and the public at large can trust research. Faculty build on these results with their own research, and students and the public use these results for everything from patient care to public policy. To build a model for how academic libraries can support reproducible research, the authors conducted a review of major guidelines from funders, publishers, and professional societies. Specific recommendations were extracted from guidelines and compared with existing academic library services and librarian expertise. The authors believe this review shows that many of the recommendations for improving reproducibility are core areas of academic librarianship, including data management, scholarly communication, and methodological support for systematic reviews and data-intensive research. By increasing our knowledge of disciplinary, journal, funder, and society perspectives on reproducibility, and reframing existing librarian expertise and services, academic librarians will be well positioned to be leaders in supporting reproducible research. © 2019, Association of College and Research Libraries. All rights reserved.",,,Article,"Final",Open Access,Scopus,2-s2.0-85064207888
"Roettger T.B., Winter B., Baayen H.","56026435300;55368947400;6602286653;","Emergent data analysis in phonetic sciences: Towards pluralism and reproducibility",2019,"Journal of Phonetics","73",,,"1","7",,,"10.1016/j.wocn.2018.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059154802&doi=10.1016%2fj.wocn.2018.12.001&partnerID=40&md5=734386efc4f1ac1dc53512f253c13455","Northwestern University, Department of Linguistics, United States; University of Birmingham, Department of English Language and Applied Linguistics, United Kingdom; University of Tübingen, Department of Linguistics, Germany","Roettger, T.B., Northwestern University, Department of Linguistics, United States; Winter, B., University of Birmingham, Department of English Language and Applied Linguistics, United Kingdom; Baayen, H., University of Tübingen, Department of Linguistics, Germany","This special issue introduces a series of papers that make available new methods to the phonetic and linguistic community and reflect upon existing data analysis practices. In our introduction, we highlight three themes that we consider pressing issues in data analysis and that run across the contributions to this special issue: the difference between exploratory and confirmatory analyses, different approaches to statistical inference, and the analysis of multidimensional multivariate speech data. Moreover, we provide a call for considering the importance of open and reproducible research practices, such as publishing one's data and analysis code. Rather than being dogmatic about particular statistical methods, the pluralism of analysis approaches in linguistics should excite debate and discussion, to which this special issue is an invitation. In addition, the co-existence of multiple ways of analyzing the same data (each with its own advantages and disadvantages and different analysis goals) makes it all the more important for researchers to make their research process open and accessible to other researchers. © 2018","Bayesian modeling; Data analysis; Null hypothesis significance testing; Open science; Reproducibility; Statistics","article; data analysis; exploratory research; human; human experiment; linguistics; null hypothesis; publishing; reproducibility; scientist; speech; statistical analysis; statistics",Article,"Final",,Scopus,2-s2.0-85059154802
"Guerrera D., Maffia A., Burkhart H.","56446965900;56446973500;7005750160;","Reproducible stencil compiler benchmarks using PROVA!",2019,"Future Generation Computer Systems","92",,,"933","946",,1,"10.1016/j.future.2018.05.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047269453&doi=10.1016%2fj.future.2018.05.023&partnerID=40&md5=c263c34dd03c0c5f61e8eb32f9a8aeb6","University of Basel, Basel, Switzerland","Guerrera, D., University of Basel, Basel, Switzerland; Maffia, A., University of Basel, Basel, Switzerland; Burkhart, H., University of Basel, Basel, Switzerland","The stencil pattern represents a vast variety of applications, ranging from geophysics to medical science. In application codes, the stencil kernel is often the part where most of the time is spent, thus forcing an efficient parallel implementation of it. On the other side, we know that stencil computations are often memory-bound, which requires sophisticated parallelization techniques to get scalable solutions. In this paper, we present the results of stencil benchmark experiments run on different systems using the PROVA! tool we are currently implementing. PROVA! aims for reproducible performance experiments and makes collaborative stencil benchmarking feasible through web repositories and interfaces. © 2018 Elsevier B.V.","HPC; Performance engineering; Reproducibility; Reproducible research; Roofline; Stencil","Hardware; Software engineering; Performance engineering; Reproducibilities; Reproducible research; Roofline; Stencil; Benchmarking",Article,"Final",,Scopus,2-s2.0-85047269453
"Ramirez-Lopez L., Wadoux A.M.J.C., Franceschini M.H.D., Terra F.S., Marques K.P.P., Sayão V.M., Demattê J.A.M.","57201570755;57148356400;57194593962;55376018200;57191979021;57189301012;6603846580;","Robust soil mapping at the farm scale with vis–NIR spectroscopy",2019,"European Journal of Soil Science","70","2",,"378","393",,2,"10.1111/ejss.12752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059473772&doi=10.1111%2fejss.12752&partnerID=40&md5=d2f29161e327ca7a35fed1584da82b97","NIR Data Analytics, BUCHI, Labortechnik AG, Meierseggstrasse 40, Flawil, 9230, Switzerland; Soil Geography and Landscape Group, Wageningen University & Research, PO Box 47, Wageningen, 6700 AA, Netherlands; Laboratory of Geo-Information Science and Remote Sensing, Wageningen University & Research, PO Box 47, Wageningen, 6700 AA, Netherlands; Center of Technological Development, Federal University of Pelotas, Campus Porto, R. Gomes Carneiro 01, Bairro Centro, Pelotas, RS 96610-010, Brazil; Department of Soil Science, “Luiz de Queiroz” College of Agriculture, University of São Paulo (ESALQ/USP), Avenida Pádua Dias, 11, CP 9, Piracicaba, SP  13418-900, Brazil","Ramirez-Lopez, L., NIR Data Analytics, BUCHI, Labortechnik AG, Meierseggstrasse 40, Flawil, 9230, Switzerland; Wadoux, A.M.J.C., Soil Geography and Landscape Group, Wageningen University & Research, PO Box 47, Wageningen, 6700 AA, Netherlands; Franceschini, M.H.D., Laboratory of Geo-Information Science and Remote Sensing, Wageningen University & Research, PO Box 47, Wageningen, 6700 AA, Netherlands; Terra, F.S., Center of Technological Development, Federal University of Pelotas, Campus Porto, R. Gomes Carneiro 01, Bairro Centro, Pelotas, RS 96610-010, Brazil; Marques, K.P.P., Department of Soil Science, “Luiz de Queiroz” College of Agriculture, University of São Paulo (ESALQ/USP), Avenida Pádua Dias, 11, CP 9, Piracicaba, SP  13418-900, Brazil; Sayão, V.M., Department of Soil Science, “Luiz de Queiroz” College of Agriculture, University of São Paulo (ESALQ/USP), Avenida Pádua Dias, 11, CP 9, Piracicaba, SP  13418-900, Brazil; Demattê, J.A.M., Department of Soil Science, “Luiz de Queiroz” College of Agriculture, University of São Paulo (ESALQ/USP), Avenida Pádua Dias, 11, CP 9, Piracicaba, SP  13418-900, Brazil","Sustainable agriculture practices are often hampered by the prohibitive costs associated with the generation of fine-resolution soil maps. Recently, several papers have been published highlighting how visible and near infrared (vis–NIR) reflectance spectroscopy may offer an alternative to address this problem by increasing the density of soil sampling and by reducing the number of conventional laboratory analyses needed. However, for farm-scale soil mapping, previous studies rarely focused on sample optimization for the calibration of vis–NIR models or on robust modelling of the spatial variation of soil properties predicted by vis–NIR spectroscopy. In the present study, we used soil vis–NIR spectroscopy models optimized in terms of both number of calibration samples and accuracy for high-resolution robust farm-scale soil mapping and addressed some of the most common pitfalls identified in previous research. We collected 910 samples from 458 locations at two depths (A, 0–0.20 m; B, 0.80–1.0 m) in the state of São Paulo, Brazil. All soil samples were analysed by conventional methods and scanned in the vis–NIR spectral range. With the vis–NIR spectra only, we inferred statistically the optimal set size and the best samples with which to calibrate vis–NIR models. The calibrated vis–NIR models were validated and used to predict soil properties for the rest of the samples. The prediction error of the spectroscopic model was propagated through the spatial analysis, in which robust block kriging was used to predict particle-size fractions and exchangeable calcium content for each depth. The results indicated that statistical selection of the calibration samples based on vis–NIR spectra considerably decreased the need for conventional chemical analysis for a given level of mapping accuracy. The methods tested in this research were developed and implemented using open-source software. All codes and data are provided for reproducible research purposes. Highlights: Vis–NIR spectroscopy enables an increase in sampling density with little additional cost. Guided selection of vis–NIR calibration samples reduced the need for conventional soil analysis. Error of spectroscopic model prediction was propagated by spatial analysis. Maps from the vis–NIR augmented dataset were almost as accurate as those from conventional soil analysis. © 2018 The Authors. European Journal of Soil Science published by John Wiley & Sons Ltd on behalf of British Society of Soil Science.",,"calibration; detection method; laboratory method; mapping method; numerical model; sampling; soil analysis; soil property; spatial analysis; spatial variation; spectroscopy; Brazil; Sao Paulo [Brazil]",Article,"Final",Open Access,Scopus,2-s2.0-85059473772
"Konkol M., Kray C., Pfeiffer M.","57193205857;8399247700;36096250000;","Computational reproducibility in geoscientific papers: Insights from a series of studies with geoscientists and a reproduction study",2019,"International Journal of Geographical Information Science","33","2",,"408","429",,3,"10.1080/13658816.2018.1508687","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051984579&doi=10.1080%2f13658816.2018.1508687&partnerID=40&md5=fcf3fd936b8732ccf291e77450803f7f","Institute for Geoinformatics, University of Münster, Münster, Germany","Konkol, M., Institute for Geoinformatics, University of Münster, Münster, Germany; Kray, C., Institute for Geoinformatics, University of Münster, Münster, Germany; Pfeiffer, M., Institute for Geoinformatics, University of Münster, Münster, Germany","Reproducibility is a cornerstone of science and thus for geographic research as well. However, studies in other disciplines such as biology have shown that published work is rarely reproducible. To assess the state of reproducibility, specifically computational reproducibility (i.e. rerunning the analysis of a paper using the original code), in geographic research, we asked geoscientists about this topic using three methods: a survey (n = 146), interviews (n = 9), and a focus group (n = 5). We asked participants about their understanding of open reproducible research (ORR), how much it is practiced, and what obstacles hinder ORR. We found that participants had different understandings of ORR and that there are several obstacles for authors and readers (e.g. effort, lack of openness). Then, in order to complement the subjective feedback from the participants, we tried to reproduce the results of papers that use spatial statistics to address problems in the geosciences. We selected 41 open access papers from Copernicus and Journal of Statistical Software and executed the R code. In doing so, we identified several technical issues and specific issues with the reproduced figures depicting the results. Based on these findings, we propose guidelines for authors to overcome the issues around reproducibility in the computational geosciences. © 2018, © 2018 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","computational research; Open reproducible research; spatial statistics","Earth science; geographical research; GIS; software; spatial data",Article,"Final",Open Access,Scopus,2-s2.0-85051984579
"Poldrack R.A.","7004739390;","The Costs of Reproducibility",2019,"Neuron","101","1",,"11","14",,5,"10.1016/j.neuron.2018.11.030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058433671&doi=10.1016%2fj.neuron.2018.11.030&partnerID=40&md5=2d0add566823aa534fb3d9a73eee2cd2","Department of Psychology, Stanford University, Stanford, CA, United States","Poldrack, R.A., Department of Psychology, Stanford University, Stanford, CA, United States","Improving the reproducibility of neuroscience research is of great concern, especially to early-career researchers (ECRs). Here I outline the potential costs for ECRs in adopting practices to improve reproducibility. I highlight the ways in which ECRs can achieve their career goals while doing better science and the need for established researchers to support them in these efforts. © 2018 Elsevier Inc.In this NeuroView, Poldrack discusses the concerns of early-career researchers about the potential costs of adopting reproducible research practices and outlines the responsibility of established researchers to help advance the careers of those doing better science. © 2018 Elsevier Inc.",,"article; career; human; neuroscience; reproducibility; scientist; economics; medical research; personnel; reproducibility; standards; Biomedical Research; Humans; Neurosciences; Reproducibility of Results; Research Personnel",Short Survey,"Final",Open Access,Scopus,2-s2.0-85058433671
"Colom M., Kerautret B., Krähenbühl A.","55549886000;8688299900;55200867800;","An Overview of Platforms for Reproducible Research and Augmented Publications",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11455 LNCS",,,"25","39",,,"10.1007/978-3-030-23987-9_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068964733&doi=10.1007%2f978-3-030-23987-9_2&partnerID=40&md5=7c671113634978d40d873d29d295604c","Centre de mathématiques et de leurs applications, CNRS, ENS Paris-Saclay, Université Paris-Saclay, Cachan Cedex, 94235, France; LIRIS, Université de Lyon 2, Lyon, France; ICube, UMR 7357, Université de Strasbourg, Strasbourg, France","Colom, M., Centre de mathématiques et de leurs applications, CNRS, ENS Paris-Saclay, Université Paris-Saclay, Cachan Cedex, 94235, France; Kerautret, B., LIRIS, Université de Lyon 2, Lyon, France; Krähenbühl, A., ICube, UMR 7357, Université de Strasbourg, Strasbourg, France","There exist several dissemination repositories, computation platforms, and online tools that might be used to implement Reproducible Research. In this paper, we discuss the strengths and weaknesses, or better, the adequacy of each of them for this purpose. Specifically, we present aspects such as the freely availability of contents for the scientific community, the languages which are accepted, or how the platform solves the problem of dependency to specific library versions. We discuss if articles and codes are peer-reviewed or if they are simply spread through a dissemination platform, and if changes are allowed after publication. The most popular platforms and tools are presented with the perspective to highlight new ways for scientific communication. © Springer Nature Switzerland AG 2019.",,"Artificial intelligence; Computer science; Computers; On-line tools; Popular platform; Reproducible research; Scientific communication; Scientific community; Pattern recognition",Conference Paper,"Final",,Scopus,2-s2.0-85068964733
[No author name available],[No author id available],"2nd International Workshop on Reproducible Research in Pattern Recognition, RRPR 2018",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11455 LNCS",,,"","",156,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068967711&partnerID=40&md5=ccaf19c6e2b6baee08d56e04ec31d729",,"","The proceedings contain 14 papers. The special focus in this conference is on Reproducible Research in Pattern Recognition. The topics include: Some Comments on Variational Bayes Block Sparse Modeling with Correlated Entries; an Image Processing Library in Modern C++: Getting Simplicity and Efficiency with Generic Programming; new Definition of Quality-Scale Robustness for Image Processing Algorithms, with Generalized Uncertainty Modeling, Applied to Denoising and Segmentation; reScience C: A Journal for Reproducible Replications in Computational Science; an Overview of Platforms for Reproducible Research and Augmented Publications; a Root-to-Leaf Algorithm Computing the Tree of Shapes of an Image; discrete Regular Polygons for Digital Shape Rigid Motion via Polygonization; non-deterministic Behavior of Ranking-Based Metrics When Evaluating Embeddings; CNN Implementation for Semantic Heads Segmentation Using Top-View Depth Data in Crowded Environment; Connected Components Labeling on DRAGs: Implementation and Reproducibility Notes; MATLAB Implementation Details of a Scalable Spectral Clustering Algorithm with the Cosine Similarity; On the Implementation of ALFA – Agglomerative Late Fusion Algorithm for Object Detection.",,,Conference Review,"Final",,Scopus,2-s2.0-85068967711
"Button K.S., Chambers C.D., Lawrence N., Munafò M.R.","37107323800;7101706206;55983493400;7004859481;","Grassroots Training for Reproducible Science: A Consortium-Based Approach to the Empirical Dissertation",2019,"Psychology Learning and Teaching",,,,"","",,,"10.1177/1475725719857659","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068343094&doi=10.1177%2f1475725719857659&partnerID=40&md5=eb84cc35cfc8050cf3e491a03a87b2bd","Department of Psychology, University of Bath, United Kingdom; Cardiff University Brain Research Imaging Centre, School of Psychology, Cardiff University, United Kingdom; Department of Psychology, University of Exeter, United Kingdom; MRC Integrative Epidemiology Unit, University of Bristol, United Kingdom; UK Centre for Tobacco and Alcohol Studies, School of Experimental Psychology, University of Bristol, United Kingdom","Button, K.S., Department of Psychology, University of Bath, United Kingdom; Chambers, C.D., Cardiff University Brain Research Imaging Centre, School of Psychology, Cardiff University, United Kingdom; Lawrence, N., Department of Psychology, University of Exeter, United Kingdom; Munafò, M.R., MRC Integrative Epidemiology Unit, University of Bristol, United Kingdom, UK Centre for Tobacco and Alcohol Studies, School of Experimental Psychology, University of Bristol, United Kingdom","There is a widely acknowledged need to improve the reliability and efficiency of scientific research to increase the credibility of the published scientific literature and accelerate discovery. Widespread improvement requires a cultural shift in both thinking and practice, and better education will be instrumental to achieve this. Here we argue that education in reproducible science should start at the grassroots. We present our model of consortium-based student projects to train undergraduates in reproducible team science. We discuss how with careful design we have aligned collaboration with the current conventions for individual student assessment. We reflect on our experiences of several years running the GW4 Undergraduate Psychology Consortium offering insights we hope will be of practical use to others wishing to adopt a similar approach. We consider the pedagogical benefits of our approach in equipping students with 21st-century skills. Finally, we reflect on the need to shift incentives to reward to team science in global research and how this applies to the reward structures of student assessment. © The Author(s) 2019.","collaboration; empirical dissertation; open science; pre-registration; Reproducibility; reproducible research; student projects; team science",,Article,"Article in Press",,Scopus,2-s2.0-85068343094
"Strand J.F., Brown V.A.","49962336000;57196353690;","Publishing open, reproducible research with undergraduates",2019,"Frontiers in Psychology","10","MAR", 564,"","",,1,"10.3389/fpsyg.2019.00564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065127833&doi=10.3389%2ffpsyg.2019.00564&partnerID=40&md5=d25ae772b3fda11150a68c52d2722435","Department of Psychology, Carleton College, Northfield, MN, United States; Department of Psychological and Brain Sciences, Washington University in St. Louis, St. Louis, MO, United States","Strand, J.F., Department of Psychology, Carleton College, Northfield, MN, United States; Brown, V.A., Department of Psychological and Brain Sciences, Washington University in St. Louis, St. Louis, MO, United States","In response to growing concern in psychology and other sciences about low rates of replicability of published findings (Open Science Collaboration, 2015), there has been a movement toward conducting open and transparent research (see Chambers, 2017). This has led to changes in statistical reporting guidelines in journals (Appelbaum et al., 2018), new professional societies (e.g., Society for the Improvement of Psychological Science), frameworks for posting materials, data, code, and manuscripts (e.g., Open Science Framework, PsyArXiv), initiatives for sharing data and collaborating (e.g., Psych Science Accelerator, Study Swap), and educational resources for teaching through replication (e.g., Collaborative Replications and Education Project). This ""credibility revolution"" (Vazire, 2018) provides many opportunities for researchers. However, given the recency of the changes and the rapid pace of advancements (see Houtkoop et al., 2018), it may be overwhelming for faculty to know whether and how to begin incorporating open science practices into research with undergraduates. In this paper, we will not attempt to catalog the entirety of the open science movement (see recommended resources below for more information), but will instead highlight why adopting open science practices may be particularly beneficial to conducting and publishing research with undergraduates. The first author is a faculty member at Carleton College (a small, undergraduate-only liberal arts college) and the second is a former undergraduate research assistant (URA) and lab manager in Dr. Strand's lab, now pursuing a PhD at Washington University in St. Louis. We argue that open science practices have tremendous benefits for undergraduate students, both in creating publishable results and in preparing students to be critical consumers of science. © 2019 Strand and Brown.","Open science; Pre-registration; Replicability; Training; Undergraduate",,Note,"Final",Open Access,Scopus,2-s2.0-85065127833
"McIntosh L.D., Juehne A.","56996909000;56997363000;","Automating the pre-review of research",2019,"Information Services and Use","39","3",,"227","232",,,"10.3233/ISU-190048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077459048&doi=10.3233%2fISU-190048&partnerID=40&md5=5a344cc3f31114695c480894b6463259","Ripeta, 911 Washington Ave, St. Louis, MO  63101, United States","McIntosh, L.D., Ripeta, 911 Washington Ave, St. Louis, MO  63101, United States; Juehne, A., Ripeta, 911 Washington Ave, St. Louis, MO  63101, United States","This paper gives an overview of Ripeta, an organization whose mission is to assess, design, and disseminate practices and measures to improve the reproducibility of science with minimal burden on scientists, starting with the biomedical sciences. Ripeta focuses on assessing the quality of the reporting and robustness of the scientific method rather than on the quality of the science. Their long-term goal includes developing a suite of tools across the broader spectrum of sciences to understand and measure the key standards and limitations for scientific reproducibility across the research lifecycle and enable an automated approach to their assessment and dissemination. For consumers of scientific research who want an easier way to evaluate the science, Ripeta offers research reports-similar to credit reports-to quickly assess the rigor of publications. Unlike the current burden of extensive due diligence and sifting through lengthy scientific publications, Ripeta extracts the key components for reproducible research from the manuscripts and intuitively present them to you. © 2019 IOS Press and the authors. All rights reserved.","experimental conditions; reproducibility of science; research replication; ripeta; scientific reporting practices","Life cycle; Automated approach; Experimental conditions; Reproducibilities; Reproducible research; ripeta; Scientific publications; scientific reporting practices; Scientific researches; Facsimile",Article,"Final",Open Access,Scopus,2-s2.0-85077459048
"Li F., Zhou Y., Cai T.","57211778223;56035831500;24281176800;","Trails of Data: Three Cases for Collecting Web Information for Social Science Research",2019,"Social Science Computer Review",,,,"","",,,"10.1177/0894439319886019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075010416&doi=10.1177%2f0894439319886019&partnerID=40&md5=68f79f0d16c42ca5f62a36a7da905247","University of Macau, China","Li, F., University of Macau, China; Zhou, Y., University of Macau, China; Cai, T., University of Macau, China","As the availability of online data grows rapidly, researchers are confronted with a pressing question: How should social scientists collect Internet data for research? This study focuses on one of the most commonly used data collection techniques: web scraping. Going beyond canned approaches by leveraging a general framework of data communication, this study illustrates how online information can be systematically queried and fetched for reproducible research. To generalize our approaches, we additionally explore the variations in site security and architecture that analysts may encounter during the scraping process before they are given access to the desired data. The approaches we introduce do not rely on any proprietary software and can be easily implemented on any computing platform with programming languages such as Python or R. The methodological discussion in this study is meant to be applicable to current web-based research efforts. We include three examples with complete Python implementation. We also present an integrated workflow that enables researchers to produce analytical data sets that are traceable and thus verifiable for analysis or replication. Lastly, options related to the validity and efficiency of data are discussed, and we highlight the ongoing debate surrounding the ethics of online data collection, ultimately advocating for the fair use of online data. © The Author(s) 2019.","APIs; data collection; headless browser; Python; reproducible research; web scraping",,Article,"Article in Press",Open Access,Scopus,2-s2.0-85075010416
"McDermott M.B.A., Wang S., Marinsek N., Ranganath R., Ghassemi M., Foschini L.","57205550617;57210730050;57210640616;34875603200;56305414400;56705765600;","Reproducibility in machine learning for health",2019,"RML@ICLR 2019 Workshop - Reproducibility in Machine Learning",,,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071324959&partnerID=40&md5=4a0f4a155e8463e6f206d3233cfcd355","Massachusetts Institute of Technology, United States; University of Toronto, Canada; Evidation Health, Inc., United States; New York University, United States","McDermott, M.B.A., Massachusetts Institute of Technology, United States; Wang, S., University of Toronto, Canada; Marinsek, N., Evidation Health, Inc., United States; Ranganath, R., New York University, United States; Ghassemi, M., University of Toronto, Canada; Foschini, L., Evidation Health, Inc., United States","Machine learning algorithms designed to characterize, monitor, and intervene on human health (ML4H) are expected to perform safely and reliably when operating at scale, potentially outside strict human supervision. This requirement warrants a stricter attention to issues of reproducibility than other fields of machine learning. In this work, we conduct a systematic evaluation of over 100 recently published ML4H research papers along several dimensions related to reproducibility. We find that the field of ML4H compares poorly to more established machine learning fields, particularly concerning data and code accessibility. Finally, drawing from success in other fields of science, we propose recommendations to data providers, academic publishers, and the ML4H research community in order to promote reproducible research moving forward. © RML@ICLR 2019 Workshop - Reproducibility in Machine Learning. All Rights Reserved.",,"Learning algorithms; Human health; Human supervision; Reproducibilities; Reproducible research; Research communities; Research papers; Systematic evaluation; Machine learning",Conference Paper,"Final",,Scopus,2-s2.0-85071324959
"Pividori M., Im H.K., Schwartz R.","56129306100;12139007100;57210994820;","Ukbrest: Efficient and streamlined data access for reproducible research in large biobanks",2019,"Bioinformatics","35","11", bty925,"1971","1973",,1,"10.1093/bioinformatics/bty925","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065814807&doi=10.1093%2fbioinformatics%2fbty925&partnerID=40&md5=ce2e1e3e259239f83dc72aed7a95b6f6","Department of Medicine, Section of Genetic Medicine, University of Chicago, Chicago, IL, United States; Center for Translational Data Science, University of Chicago, Chicago, IL, United States","Pividori, M., Department of Medicine, Section of Genetic Medicine, University of Chicago, Chicago, IL, United States, Center for Translational Data Science, University of Chicago, Chicago, IL, United States; Im, H.K., Department of Medicine, Section of Genetic Medicine, University of Chicago, Chicago, IL, United States, Center for Translational Data Science, University of Chicago, Chicago, IL, United States; Schwartz, R., Department of Medicine, Section of Genetic Medicine, University of Chicago, Chicago, IL, United States","Large biobanks, such as UK Biobank with half a million participants, are changing the scale and availability of genotypic and phenotypic data for researchers to ask fundamental questions about the biology of health and disease. The breadth of the UK Biobank data is enabling discoveries at an unprecedented pace. However, this size and complexity pose new challenges to investigators who need to keep the accruing data up to date, comply with potential consent changes, and efficiently and reproducibly extract subsets of the data to answer specific scientific questions. Here we propose a tool called ukbREST designed for the UK Biobank study (easily extensible to other biobanks), which allows authorized users to efficiently retrieve phenotypic and genetic data. It exposes a REST API that makes data highly accessible inside a private and secure network, allowing the data specification in a human readable text format easily shareable with other researchers. These characteristics make ukbREST an important tool to make biobank's valuable data more readily accessible to the research community and facilitate reproducibility of the analysis, a key aspect of science. Availability and implementation: It is implemented in Python using the Flask-RESTful framework for the API, and it is under the MIT license. It works with PostgreSQL and a Docker image is available for easy deployment. The source code and documentation is available in Github: https://github.com/hakyimlab/ukbrest. © 2018 The Author(s). Published by Oxford University Press.",,,Article,"Final",Open Access,Scopus,2-s2.0-85065814807
"DuPre E., Hanke M., Poline J.-B.","56385473800;35859076500;7003479971;","Nature abhors a paywall: How open science can realize the potential of naturalistic stimuli",2019,"NeuroImage",,, 116330,"","",,,"10.1016/j.neuroimage.2019.116330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075388991&doi=10.1016%2fj.neuroimage.2019.116330&partnerID=40&md5=415c1e7a90c30c6464031a124816913c","Montreal Neurological Institute, McGill University, Canada; Institute of Neuroscience and Medicine, Brain & Behaviour (INM-7), Research Centre Jülich, Jülich, Germany; Institute of Systems Neuroscience, Medical Faculty, Heinrich Heine University Düsseldorf, Düsseldorf, Germany","DuPre, E., Montreal Neurological Institute, McGill University, Canada; Hanke, M., Institute of Neuroscience and Medicine, Brain & Behaviour (INM-7), Research Centre Jülich, Jülich, Germany, Institute of Systems Neuroscience, Medical Faculty, Heinrich Heine University Düsseldorf, Düsseldorf, Germany; Poline, J.-B., Montreal Neurological Institute, McGill University, Canada","Naturalistic stimuli show significant potential to inform behavioral, cognitive, and clinical neuroscience. To date, this impact is still limited by the relative inaccessibility of both generated neuroimaging data as well as the supporting naturalistic stimuli. In this perspective, we highlight currently available naturalistic datasets and technical solutions such as DataLad that continue to advance our ability to share this data. We also review scientific and sociological challenges in selecting naturalistic stimuli for reproducible research. Overall, we encourage researchers to share their naturalistic datasets to the full extent possible under local copyright law. © 2019 Elsevier Inc.","Data sharing; Naturalistic stimuli; Open science",,Article,"Article in Press",,Scopus,2-s2.0-85075388991
"Drummond C.","7102876506;","Is the drive for reproducible science having a detrimental effect on what is published?",2019,"Learned Publishing","32","1",,"63","69",,1,"10.1002/leap.1224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060535634&doi=10.1002%2fleap.1224&partnerID=40&md5=3b9a08887fff464fcb2c16e46834217a","Digital Technologies Research Centre, National Research Council, Ottawa, ON, Canada","Drummond, C., Digital Technologies Research Centre, National Research Council, Ottawa, ON, Canada","This paper is a critique of the part played by the reproducible research movement within the scientific community. In particular, it raises concerns about the strong influence the movement is having on which papers are published. The primary effect is through changes to the peer review process. These not only require that the data and software used to generate the reported results be part of the review but also that the novelty criterion should be deprecated. This paper questions a central tenet of the movement, the idea of a single, well-defined, and iterative scientific method. Philosophers, historians of science, and scientists alike have argued extensively against the idea of a single method. Some going as far as to suggest that there are as many methods as scientists. I am convinced that there are broad, high-level ideas that bind scientists together. Yet, anything more sharply delineated that could reasonably be entitled a scientific method is not logically or historically justified. If this criticism is accepted, then changes to the peer review process are not warranted. Furthermore, I would contend that the influence the reproducible research movement is having on the publishing of papers, and elsewhere, should be considerably curtailed. © 2019 Her Majesty the Queen in Right of Canada. Learned Publishing © 2019 ALPSP.",,,Article,"Final",Open Access,Scopus,2-s2.0-85060535634
"Niekler A., Bleier A., Kahmann C., Posch L., Wiedemann G., Erdogan K., Heyer G., Strohmaier M.","55369209200;55505591300;57191658366;55872869300;55822538800;57195633920;13908384700;57205900668;","ILCM - A virtual research infrastructure for large-scale qualitative data",2019,"LREC 2018 - 11th International Conference on Language Resources and Evaluation",,,,"1313","1319",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059910222&partnerID=40&md5=9e4880ca68ae9f0f1f27d4f1424e12d3","Faculty of Mathematics and Computer Science, University Leipzig, Augustusplatz 10, Leipzig, 04109, Germany; Department of Computational Social Science, GESIS, Leibniz Institute for the Social Sciences, Unter Sachsenhausen 6-8, Cologne, 50667, Germany; Institute of Interactive Systems and Data Science, Graz University of Technology, Inffeldgasse 16c, Graz, 8010, Austria; HumTec Institute, RWTH Aachen University, Theaterplatz 14, Aachen, 52062, Germany","Niekler, A., Faculty of Mathematics and Computer Science, University Leipzig, Augustusplatz 10, Leipzig, 04109, Germany; Bleier, A., Department of Computational Social Science, GESIS, Leibniz Institute for the Social Sciences, Unter Sachsenhausen 6-8, Cologne, 50667, Germany; Kahmann, C., Faculty of Mathematics and Computer Science, University Leipzig, Augustusplatz 10, Leipzig, 04109, Germany; Posch, L., Department of Computational Social Science, GESIS, Leibniz Institute for the Social Sciences, Unter Sachsenhausen 6-8, Cologne, 50667, Germany, Institute of Interactive Systems and Data Science, Graz University of Technology, Inffeldgasse 16c, Graz, 8010, Austria; Wiedemann, G., Faculty of Mathematics and Computer Science, University Leipzig, Augustusplatz 10, Leipzig, 04109, Germany; Erdogan, K., Department of Computational Social Science, GESIS, Leibniz Institute for the Social Sciences, Unter Sachsenhausen 6-8, Cologne, 50667, Germany; Heyer, G., Faculty of Mathematics and Computer Science, University Leipzig, Augustusplatz 10, Leipzig, 04109, Germany; Strohmaier, M., Department of Computational Social Science, GESIS, Leibniz Institute for the Social Sciences, Unter Sachsenhausen 6-8, Cologne, 50667, Germany, HumTec Institute, RWTH Aachen University, Theaterplatz 14, Aachen, 52062, Germany","The iLCM project pursues the development of an integrated research environment for the analysis of structured and unstructured data in a “Software as a Service” architecture (SaaS). The research environment addresses requirements for the quantitative evaluation of large amounts of qualitative data with text mining methods as well as requirements for the reproducibility of data-driven research designs in the social sciences. For this, the iLCM research environment comprises two central components. First, the Leipzig Corpus Miner (LCM), a decentralized SaaS application for the analysis of large amounts of news texts developed in a previous Digital Humanities project. Second, the text mining tools implemented in the LCM are extended by an “Open Research Computing” (ORC) environment for executable script documents, so-called “notebooks”. This novel integration allows to combine generic, high-performance methods to process large amounts of unstructured text data and with individual program scripts to address specific research requirements in computational social science and digital humanities. ilcm.informatik.uni-leipzig.de. © LREC 2018 - 11th International Conference on Language Resources and Evaluation. All rights reserved.","Computational social science; Digital humanities; Infrastructure; Reproducible research; Text mining","Behavioral research; Data mining; Petroleum reservoir evaluation; Computational social science; Digital humanities; Infrastructure; Reproducible research; Text mining; Software as a service (SaaS)",Conference Paper,"Final",,Scopus,2-s2.0-85059910222
"Olendorf R.K.","57209021319;","Toward a more open, trusted, and efficient research environment",2019,"BioResources","14","3",,"5016","5017",,,"10.15376/biores.14.3.5016-5017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066337921&doi=10.15376%2fbiores.14.3.5016-5017&partnerID=40&md5=e7a354c1e9b656f6dc16e7eefc4431c8","University Libraries, North Carolina State University, Campus Box 7114, 2800 Faucette Drive, Raleigh, NC  27695, United States","Olendorf, R.K., University Libraries, North Carolina State University, Campus Box 7114, 2800 Faucette Drive, Raleigh, NC  27695, United States","Open science is becoming increasingly popular. Both funders and publishers require data be made public. The goal is to make research easier to validate, more trusted, and to hasten the speed of discovery. However, due to lack of training, lack of resources and lack of time, researchers often fail to make much of the content they generate public, and they also fail to adequately document and organize it. Here I make an argument that researchers should try to make all their research content public. I briefly describe best practices that should both result in a better product and be less burdensome on the researcher. I also argue that if done properly, opening up their research can have multiple benefits for the research and their career. © 2019, North Carolina State University.","Open data; Open science; Reproducible research",,Editorial,"Final",,Scopus,2-s2.0-85066337921
"Krieger N.I., Perzynski A.T., Dalton J.E.","57210465297;36979453700;23488241300;","Facilitating reproducible project management and manuscript development in team science: The projects R package",2019,"PLoS ONE","14","7", e0212390,"","",,,"10.1371/journal.pone.0212390","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070790953&doi=10.1371%2fjournal.pone.0212390&partnerID=40&md5=ceb1fc4bb3b1c0a1edb8e1c8f1ed9cbf","Department of Quantitative Health Sciences, Lerner Research Institute, Cleveland Clinic, Cleveland, OH, United States; Center for Healthcare Research and Policy, Case Western Reserve University at MetroHealth, Cleveland, OH, United States; Cleveland Clinic Lerner College of Medicine, Case Western Reserve University, Cleveland, OH, United States","Krieger, N.I., Department of Quantitative Health Sciences, Lerner Research Institute, Cleveland Clinic, Cleveland, OH, United States; Perzynski, A.T., Center for Healthcare Research and Policy, Case Western Reserve University at MetroHealth, Cleveland, OH, United States; Dalton, J.E., Department of Quantitative Health Sciences, Lerner Research Institute, Cleveland Clinic, Cleveland, OH, United States, Cleveland Clinic Lerner College of Medicine, Case Western Reserve University, Cleveland, OH, United States","The contemporary scientific community places a growing emphasis on the reproducibility of research. The projects R package is a free, open-source package created in the interest of facilitating reproducible research workflows. It adds to existing software tools for reproducible research and introduces several practical features that are helpful for scientists and their collaborative research teams. For each individual project, it supplies a framework for storing raw and cleaned study data sets, and it provides script templates for protocol creation, data cleaning, data analysis and manuscript development. Internal databases of project and author information are generated and displayed, and manuscript title pages containing author lists and their affiliations are automatically generated from the internal database. File management tools allow teams to organize multiple projects. When used on a shared file system, multiple researchers can harmoniously contribute to the same project in a less punctuated manner, reducing the frequency of misunderstandings and the need for status updates. © 2019 Krieger et al.",,"article; cleaning; data analysis; human; publication; reproducibility; scientist; software; workflow",Article,"Final",Open Access,Scopus,2-s2.0-85070790953
"Anderson J.M., Niemann A., Johnson A.L., Cook C., Tritz D., Vassar M.","57209416031;57212221999;57203734299;57200159277;57200158801;23029184400;","Transparent, reproducible, and open science practices of published literature in dermatology journals: Cross-sectional analysis",2019,"Journal of Medical Internet Research","21","11", e16078,"","",,,"10.2196/16078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076237386&doi=10.2196%2f16078&partnerID=40&md5=ede97d402dd850772226cf51a8cd344b","Oklahoma State University Center for Health Sciences, 1111 W 17th St, Tulsa, OK  74107, United States; Kansas City University of Medicine and Biosciences, Kansas City, MO, United States","Anderson, J.M., Oklahoma State University Center for Health Sciences, 1111 W 17th St, Tulsa, OK  74107, United States; Niemann, A., Kansas City University of Medicine and Biosciences, Kansas City, MO, United States; Johnson, A.L., Oklahoma State University Center for Health Sciences, 1111 W 17th St, Tulsa, OK  74107, United States; Cook, C., Oklahoma State University Center for Health Sciences, 1111 W 17th St, Tulsa, OK  74107, United States; Tritz, D., Oklahoma State University Center for Health Sciences, 1111 W 17th St, Tulsa, OK  74107, United States; Vassar, M., Oklahoma State University Center for Health Sciences, 1111 W 17th St, Tulsa, OK  74107, United States","Background: Reproducible research is a foundational component for scientific advancements, yet little is known regarding the extent of reproducible research within the dermatology literature. Objective: This study aimed to determine the quality and transparency of the literature in dermatology journals by evaluating for the presence of 8 indicators of reproducible and transparent research practices. Methods: By implementing a cross-sectional study design, we conducted an advanced search of publications in dermatology journals from the National Library of Medicine catalog. Our search included articles published between January 1, 2014, and December 31, 2018. After generating a list of eligible dermatology publications, we then searched for full text PDF versions by using Open Access Button, Google Scholar, and PubMed. Publications were analyzed for 8 indicators of reproducibility and transparency—availability of materials, data, analysis scripts, protocol, preregistration, conflict of interest statement, funding statement, and open access—using a pilot-tested Google Form. Results: After exclusion, 127 studies with empirical data were included in our analysis. Certain indicators were more poorly reported than others. We found that most publications (113, 88.9%) did not provide unmodified, raw data used to make computations, 124 (97.6%) failed to make the complete protocol available, and 126 (99.2%) did not include step-by-step analysis scripts. Conclusions: Our sample of studies published in dermatology journals do not appear to include sufficient detail to be accurately and successfully reproduced in their entirety. Solutions to increase the quality, reproducibility, and transparency of dermatology research are warranted. More robust reporting of key methodological details, open data sharing, and stricter standards journals impose on authors regarding disclosure of study materials might help to better the climate of reproducible research in dermatology. © J Michael Anderson, Andrew Niemann, Austin L Johnson, Courtney Cook, Daniel Tritz, Matt Vassar.","Data sharing; Dermatology; Publishing, open access; Reproducibility of findings","article; climate; conflict of interest; cross-sectional study; data analysis; dermatology; funding; human; Medline; publishing; reproducibility",Article,"Final",Open Access,Scopus,2-s2.0-85076237386
"Russell S., Bennett T.D., Ghosh D.","57202535381;7202878300;57201786914;","Software engineering principles to improve quality and performance of R software",2019,"PeerJ Computer Science","2019","2", e175,"","",,,"10.7717/peerj-cs.175","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074154637&doi=10.7717%2fpeerj-cs.175&partnerID=40&md5=9141457628e74a753a3381904fbe9e9a","University of Colorado Data Science to Patient Value, University of Colorado Anschutz Medical Campus, Aurora, CO, United States; Pediatric Critical Care, University of Colorado School of Medicine, Aurora, CO, United States; Department of Biostatistics and Informatics, Colorado School of Public Health, Aurora, CO, United States","Russell, S., University of Colorado Data Science to Patient Value, University of Colorado Anschutz Medical Campus, Aurora, CO, United States; Bennett, T.D., University of Colorado Data Science to Patient Value, University of Colorado Anschutz Medical Campus, Aurora, CO, United States, Pediatric Critical Care, University of Colorado School of Medicine, Aurora, CO, United States; Ghosh, D., University of Colorado Data Science to Patient Value, University of Colorado Anschutz Medical Campus, Aurora, CO, United States, Department of Biostatistics and Informatics, Colorado School of Public Health, Aurora, CO, United States","Today's computational researchers are expected to be highly proficient in using software to solve a wide range of problems ranging from processing large datasets to developing personalized treatment strategies from a growing range of options. Researchers are well versed in their own field, but may lack formal training and appropriate mentorship in software engineering principles. Two major themes not covered in most university coursework nor current literature are software testing and software optimization. Through a survey of all currently available Comprehensive R Archive Network packages, we show that reproducible and replicable software tests are frequently not available and that many packages do not appear to employ software performance and optimization tools and techniques. Through use of examples from an existing R package, we demonstrate powerful testing and optimization techniques that can improve the quality of any researcher's software. © 2019 Russell et al.","Case study; Data science; Optimization; Profiling; R language; Reproducible research; Software engineering; Statistical computing; Unit testing","Data Science; Large dataset; Optimization; Software engineering; Profiling; R languages; Reproducible research; Statistical computing; Unit testing; Software testing",Article,"Final",Open Access,Scopus,2-s2.0-85074154637
"Malmström L.","6602744452;","Computational proteomics with Jupyter and Python",2019,"Methods in Molecular Biology","1977",,,"237","248",,,"10.1007/978-1-4939-9232-4_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064766930&doi=10.1007%2f978-1-4939-9232-4_15&partnerID=40&md5=4ce3aaecb2b9471b067db08590ed6ff1","Institute for Computational Science, University of Zurich, Zurich, Switzerland; S3IT, University of Zurich, Zurich, Switzerland; Division of Infection Medicine, Department of Clinical Sciences, Lund University, Lund, Sweden","Malmström, L., Institute for Computational Science, University of Zurich, Zurich, Switzerland, S3IT, University of Zurich, Zurich, Switzerland, Division of Infection Medicine, Department of Clinical Sciences, Lund University, Lund, Sweden","Proteomics based on mass spectrometry produces complex data in large quantities. The need for flexible computational pipelines, in the context of big data, in proteomics and other areas of science, has prompted the development of computational platforms and libraries that facilitate data analysis and data processing. In this respect, Python appears to be one of the winners among programming languages in terms of popularity and development. This chapter shows how to perform basic tasks using Python and dedicated libraries in a Jupyter framework: from basic search result summarizations to the creation of MS1 chromatograms. © Springer Science+Business Media, LLC, part of Springer Nature 2019.","Jupyter; JupyterHub; Proteomics; Python; R; Reproducible research","big data; chromatography; computer language; data analysis; library; mass spectrometry; pipeline; proteomics; biology; procedures; protein database; reproducibility; software; standards; Computational Biology; Databases, Protein; Proteomics; Reproducibility of Results; Software",Book Chapter,"Final",,Scopus,2-s2.0-85064766930
"Stanford N.J., Scharm M., Dobson P.D., Golebiewski M., Hucka M., Kothamachu V.B., Nickerson D., Owen S., Pahle J., Wittig U., Waltemath D., Goble C., Mendes P., Snoep J.","36644932200;55626698400;7102794006;16229843100;6507020371;55938257300;7005755956;24773633500;15128960800;6603347010;36471561200;7004072716;57204600617;7005916173;","Data Management in Computational Systems Biology: Exploring Standards, Tools, Databases, and Packaging Best Practices",2019,"Methods in Molecular Biology","2049",,,"285","314",,1,"10.1007/978-1-4939-9736-7_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073096401&doi=10.1007%2f978-1-4939-9736-7_17&partnerID=40&md5=5670c57e113da7becc7688b23f2ec4eb","School of Computer Science, University of Manchester, Manchester, United Kingdom; Department of Systems Biology and Bioinformatics, University of Rostock, Rostock, Germany; Heidelberg Institute for Theoretical Studies (HITS), Heidelberg, Germany; Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, United States; Signalling ISP, The Babraham Institute, Cambridge, United Kingdom; Auckland Bioengineering Institute, University of Auckland, Auckland, New Zealand; BIOMS/BioQuant, Heidelberg University, Heidelberg, Germany; Centre for Quantitative Medicine, University of Connecticut, Farmington, CT, United States; Biochemistry, Stellenbosch University, Stellenbosch, South Africa; Medical Informatics, University Medicine Greifswald, Greifswald, Germany","Stanford, N.J., School of Computer Science, University of Manchester, Manchester, United Kingdom; Scharm, M., Department of Systems Biology and Bioinformatics, University of Rostock, Rostock, Germany; Dobson, P.D., School of Computer Science, University of Manchester, Manchester, United Kingdom; Golebiewski, M., Heidelberg Institute for Theoretical Studies (HITS), Heidelberg, Germany; Hucka, M., Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, United States; Kothamachu, V.B., Signalling ISP, The Babraham Institute, Cambridge, United Kingdom; Nickerson, D., Auckland Bioengineering Institute, University of Auckland, Auckland, New Zealand; Owen, S., School of Computer Science, University of Manchester, Manchester, United Kingdom; Pahle, J., BIOMS/BioQuant, Heidelberg University, Heidelberg, Germany; Wittig, U., Heidelberg Institute for Theoretical Studies (HITS), Heidelberg, Germany; Waltemath, D., Medical Informatics, University Medicine Greifswald, Greifswald, Germany; Goble, C., School of Computer Science, University of Manchester, Manchester, United Kingdom; Mendes, P., Centre for Quantitative Medicine, University of Connecticut, Farmington, CT, United States; Snoep, J., School of Computer Science, University of Manchester, Manchester, United Kingdom, Biochemistry, Stellenbosch University, Stellenbosch, South Africa","Computational systems biology involves integrating heterogeneous datasets in order to generate models. These models can assist with understanding and prediction of biological phenomena. Generating datasets and integrating them into models involves a wide range of scientific expertise. As a result these datasets are often collected by one set of researchers, and exchanged with others researchers for constructing the models. For this process to run smoothly the data and models must be FAIR—findable, accessible, interoperable, and reusable. In order for data and models to be FAIR they must be structured in consistent and predictable ways, and described sufficiently for other researchers to understand them. Furthermore, these data and models must be shared with other researchers, with appropriately controlled sharing permissions, before and after publication. In this chapter we explore the different data and model standards that assist with structuring, describing, and sharing. We also highlight the popular standards and sharing databases within computational systems biology. © Springer Science+Business Media, LLC, part of Springer Nature 2019.","Data storage; Databases; FAIR; Metadata; Model storage; Reproducible research; Standards","information storage; metadata; systems biology; article",Book Chapter,"Final",,Scopus,2-s2.0-85073096401
"Wright M.L., Higgins M., Taylor J.Y., Hertzberg V.S.","55470561100;35186267100;15752025200;7003393596;","NuRsing Research in the 21st Century: R You Ready?",2019,"Biological Research for Nursing","21","1",,"114","120",,,"10.1177/1099800418810514","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058142780&doi=10.1177%2f1099800418810514&partnerID=40&md5=09d06220fb5a4ebb47225ecdc4cfefb0","School of Nursing, University of Texas at Austin, Austin, TX, United States; Nell Hodgson Woodruff School of Nursing, Emory University, Atlanta, GA, United States; Rory Meyers College of Nursing, New York University, Emory, Atlanta, United States","Wright, M.L., School of Nursing, University of Texas at Austin, Austin, TX, United States; Higgins, M., Nell Hodgson Woodruff School of Nursing, Emory University, Atlanta, GA, United States; Taylor, J.Y., Rory Meyers College of Nursing, New York University, Emory, Atlanta, United States; Hertzberg, V.S., Nell Hodgson Woodruff School of Nursing, Emory University, Atlanta, GA, United States","Nurse scientists are adept at translating findings from basic science into useful clinical- and community-based interventions to improve health. Over time, the focus of some nursing research has grown to include the assessment and evaluation of genomic and other output from high-throughput, or “omic,” technologies as indicators related to health and disease. To date, the growth in the application of omics technologies in nursing research has included calls to increase attention to omics in nursing school curricula and educational training opportunities, such as the Summer Genetics Institute offered by the National Institute of Nursing Research. However, there has been scant attention paid in the nursing literature to the complexity of data analysis or issues of reproducibility related to omics studies. The goals of this article are to (1) familiarize nurse scientists with tools that encourage reproducibility in omics studies, with a focus on the free and open-source data processing and analysis pipeline, and (2) provide a baseline understanding of how these tools can be used to improve collaboration and cohesion among interdisciplinary research team members. Knowledge of these tools and skill in applying them will be important for communication across disciplines and imperative for the advancement of omics research in nursing. © The Author(s) 2018.","information dissemination; information management; nursing research; omics; reproducible research; statistics","forecasting; human; information dissemination; methodology; nursing research; procedures; reproducibility; trends; Forecasting; Humans; Information Dissemination; Nursing Research; Reproducibility of Results; Research Design",Article,"Final",Open Access,Scopus,2-s2.0-85058142780
"Greene G., Plante R., Hanisch R.","57210576608;14825812700;7004117815;","Building open access to research (OAR) data infrastructure at NIST",2019,"Data Science Journal","18","1", 30,"","",,,"10.5334/dsj-2019-030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071043176&doi=10.5334%2fdsj-2019-030&partnerID=40&md5=8de4030c48fc682eb9cfee92488004ad","National Institute of Standards and Technology, Material Measurement Laboratory Office of Data and Informatics, Gaithersburg, MA, United States","Greene, G., National Institute of Standards and Technology, Material Measurement Laboratory Office of Data and Informatics, Gaithersburg, MA, United States; Plante, R., National Institute of Standards and Technology, Material Measurement Laboratory Office of Data and Informatics, Gaithersburg, MA, United States; Hanisch, R., National Institute of Standards and Technology, Material Measurement Laboratory Office of Data and Informatics, Gaithersburg, MA, United States","As a National Metrology Institute (NMI), the USA National Institute of Standards and Technology (NIST) scientists, engineers and technology experts conduct research across a full spectrum of physical science domains. NIST is a non-regulatory agency within the U.S. Department of Commerce with a mission to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve our quality of life. NIST research results in the production and distribution of standard reference materials, calibration services, and datasets. These are generated from a wide range of complex laboratory instrumentation, expert analyses, and calibration processes. In response to a government open data policy, and in collaboration with the broader research community, NIST has developed a federated Open Access to Research (OAR) scientific data infrastructure aligned with FAIR (Findable, Accessible, Interoperable, Reusable) data principles. Through the OAR initiatives, NIST’s Material Measurement Laboratory Office of Data and Informatics (ODI) recently released a new scientific data discovery portal and public data repository. These science- oriented applications provide dissemination and public access for data from across the broad spectrum of NIST research disciplines, including chemistry, biology, materials science (such as crystallography, nanomaterials, etc.), physics, disaster resilience, cyberinfrastructure, communications, forensics, and others. NIST’s public data consist of carefully curated Standard Reference Data, legacy high valued data, and new research data publications. The repository is thus evolving both in content and features as the nature of research progresses. Implementation of the OAR infrastructure is key to NIST’s role in sharing high integrity reproducible research for measurement science in a rapidly changing world. © 2019 The Author(s).","Data portal; Data repository; Fair; Government; Metrology; Research metadata","Calibration; Competition; Measurement; Data portal; Data repositories; Fair; Government; Laboratory instrumentation; National Institute of Standards and Technology; National metrology institutes; Standard reference material; Open Data",Article,"Final",Open Access,Scopus,2-s2.0-85071043176
"Knopp T., Szwargulski P., Griese F., Grosser M., Boberg M., Möddel M.","15062977800;56674669700;55750278100;57211452422;57208485196;57194689358;","Mpireco.Jl: Julia package for image reconstruction in MPI",2019,"International Journal on Magnetic Particle Imaging","5","1", 1907001,"","",,1,"10.18416/ijmpi.2019.1907001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074022186&doi=10.18416%2fijmpi.2019.1907001&partnerID=40&md5=43cee4cdad925e0a5fe415a41ec813c2","Section for Biomedical Imaging, University Medical Center Hamburg-Eppendorf, Hamburg, Germany; Institute for Biomedical Imaging, Hamburg University of Technology, Hamburg, Germany","Knopp, T., Section for Biomedical Imaging, University Medical Center Hamburg-Eppendorf, Hamburg, Germany, Institute for Biomedical Imaging, Hamburg University of Technology, Hamburg, Germany; Szwargulski, P., Section for Biomedical Imaging, University Medical Center Hamburg-Eppendorf, Hamburg, Germany, Institute for Biomedical Imaging, Hamburg University of Technology, Hamburg, Germany; Griese, F., Section for Biomedical Imaging, University Medical Center Hamburg-Eppendorf, Hamburg, Germany, Institute for Biomedical Imaging, Hamburg University of Technology, Hamburg, Germany; Grosser, M., Section for Biomedical Imaging, University Medical Center Hamburg-Eppendorf, Hamburg, Germany, Institute for Biomedical Imaging, Hamburg University of Technology, Hamburg, Germany; Boberg, M., Section for Biomedical Imaging, University Medical Center Hamburg-Eppendorf, Hamburg, Germany, Institute for Biomedical Imaging, Hamburg University of Technology, Hamburg, Germany; Möddel, M., Section for Biomedical Imaging, University Medical Center Hamburg-Eppendorf, Hamburg, Germany, Institute for Biomedical Imaging, Hamburg University of Technology, Hamburg, Germany","Image reconstruction plays an important role for the tomographic imaging technique magnetic particle imaging (MPI) since the measured raw data cannot be directly interpreted. Instead, one needs to invert the image formation process, which involves the solution of an ill-conditioned linear system of equations. Currently, most MPI researchers have implemented custom reconstruction algorithms that cannot be directly compared since the source code is not openly available. The software package MPIReco.jl aims to change this situation by providing a reference implementation for a variety of reconstruction algorithms. With the recently proposed magnetic particle imaging data format and its reference implementation MPIFiles.jl we have taken the first steps towards standardised data exchange. With MPIReco.jl we complement these initiatives to standardise the reconstruction algorithms and to facilitate reproducible research. We chose to implement the algorithms in the programming language Julia, which provides a high level syntax making the software accessible even for non-professional software developers. On the other hand Julia code has a high run-time performance comparable to low-level C code. In the present paper, we outline some of the design principles of MPIReco.jl and give an overview of the software package. © 2019 Knopp and Infinite Science Publishing.",,,Article,"Final",,Scopus,2-s2.0-85074022186
"Simko T., Cranmer K., Crusoe M.R., Heinrich L., Khodak A., Kousidis D., Rodriguez D.","55480402200;57202562241;57200149783;35317494100;57200148027;57204695459;57204686761;","Search for computational workflow synergies in reproducible research data analyses in particle physics and life sciences",2018,"Proceedings - IEEE 14th International Conference on eScience, e-Science 2018",,, 8588742,"403","404",,,"10.1109/eScience.2018.00123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061405474&doi=10.1109%2feScience.2018.00123&partnerID=40&md5=d067a19936f86e7c67595aa53442e60e","CERN, Geneva, Switzerland; New York University, New York, United States; Common Workflow Language, Vilnius, Lithuania; Wellcome Sanger Institute, Hinxton, United Kingdom","Simko, T., CERN, Geneva, Switzerland; Cranmer, K., New York University, New York, United States; Crusoe, M.R., Common Workflow Language, Vilnius, Lithuania; Heinrich, L., New York University, New York, United States; Khodak, A., Wellcome Sanger Institute, Hinxton, United Kingdom; Kousidis, D., CERN, Geneva, Switzerland; Rodriguez, D., CERN, Geneva, Switzerland","We describe the REANA reusable and reproducible research data analysis platform that originated in the domain of particle physics. We integrated support for running Common Workflow Language (CWL) workflows that originated in the domain of life sciences. This integration allowed us to study the applicability of CWL to particle physics analyses and look for synergies in computational practices in the two communities. © 2018 IEEE.","Computational workflows; Data analysis; Data preservation; Reproducible science","Data reduction; Information analysis; Computational workflows; Data preservations; Integrated supports; Life-sciences; Reproducible research; Reproducible science; Work-flows; Workflow language; Data handling",Conference Paper,"Final",,Scopus,2-s2.0-85061405474
"Schnell S.","7006138397;","“Reproducible” Research in Mathematical Sciences Requires Changes in our Peer Review Culture and Modernization of our Current Publication Approach",2018,"Bulletin of Mathematical Biology","80","12",,"3095","3105",,1,"10.1007/s11538-018-0500-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053707873&doi=10.1007%2fs11538-018-0500-9&partnerID=40&md5=bc8867c6219b0d8eefa856ae20712210","Department of Molecular and Integrative Physiology, University of Michigan Medical School, Ann Arbor, MI  48109, United States; Department of Computational Medicine and Bioinformatics, University of Michigan Medical School, Ann Arbor, MI  48109, United States","Schnell, S., Department of Molecular and Integrative Physiology, University of Michigan Medical School, Ann Arbor, MI  48109, United States, Department of Computational Medicine and Bioinformatics, University of Michigan Medical School, Ann Arbor, MI  48109, United States","The nature of scientific research in mathematical and computational biology allows editors and reviewers to evaluate the findings of a scientific paper. Replication of a research study should be the minimum standard for judging its scientific claims and considering it for publication. This requires changes in the current peer review practice and a strict adoption of a replication policy similar to those adopted in experimental fields such as organic synthesis. In the future, the culture of replication can be easily adopted by publishing papers through dynamic computational notebooks combining formatted text, equations, computer algebra and computer code. © 2018, Society for Mathematical Biology.","Academic publishing; Editorial policies; Repeatability; Replicability; Reproducibility","biology; human; mathematical phenomena; medical research; peer review; publishing; reproducibility; standards; statistics and numerical data; trends; Biomedical Research; Computational Biology; Humans; Mathematical Concepts; Peer Review; Publishing; Reproducibility of Results",Article,"Final",,Scopus,2-s2.0-85053707873
"Kulkarni N., Alessandrì L., Panero R., Arigoni M., Olivero M., Ferrero G., Cordero F., Beccuti M., Calogero R.A.","57200200371;57204181023;57194009065;10139199200;7003451022;55988482200;23049540800;8285239400;7004035394;","Reproducible bioinformatics project: A community for reproducible bioinformatics analysis pipelines",2018,"BMC Bioinformatics","19",, 349,"","",,7,"10.1186/s12859-018-2296-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054791952&doi=10.1186%2fs12859-018-2296-x&partnerID=40&md5=deec957c3aef32a04b9ca9f710be91ef","University of Torino, Department of Molecular Biotechnology and Health Sciences, Torino, Italy; University of Torino, Department of Oncology, Candiolo, Italy; University of Torino, Department of Computer Sciences, Torino, Italy","Kulkarni, N., University of Torino, Department of Molecular Biotechnology and Health Sciences, Torino, Italy; Alessandrì, L., University of Torino, Department of Molecular Biotechnology and Health Sciences, Torino, Italy; Panero, R., University of Torino, Department of Molecular Biotechnology and Health Sciences, Torino, Italy; Arigoni, M., University of Torino, Department of Molecular Biotechnology and Health Sciences, Torino, Italy; Olivero, M., University of Torino, Department of Oncology, Candiolo, Italy; Ferrero, G., University of Torino, Department of Computer Sciences, Torino, Italy; Cordero, F., University of Torino, Department of Computer Sciences, Torino, Italy; Beccuti, M., University of Torino, Department of Computer Sciences, Torino, Italy; Calogero, R.A., University of Torino, Department of Molecular Biotechnology and Health Sciences, Torino, Italy","Background: Reproducibility of a research is a key element in the modern science and it is mandatory for any industrial application. It represents the ability of replicating an experiment independently by the location and the operator. Therefore, a study can be considered reproducible only if all used data are available and the exploited computational analysis workflow is clearly described. However, today for reproducing a complex bioinformatics analysis, the raw data and the list of tools used in the workflow could be not enough to guarantee the reproducibility of the results obtained. Indeed, different releases of the same tools and/or of the system libraries (exploited by such tools) might lead to sneaky reproducibility issues. Results: To address this challenge, we established the Reproducible Bioinformatics Project (RBP), which is a non-profit and open-source project, whose aim is to provide a schema and an infrastructure, based on docker images and R package, to provide reproducible results in Bioinformatics. One or more Docker images are then defined for a workflow (typically one for each task), while the workflow implementation is handled via R-functions embedded in a package available at github repository. Thus, a bioinformatician participating to the project has firstly to integrate her/his workflow modules into Docker image(s) exploiting an Ubuntu docker image developed ad hoc by RPB to make easier this task. Secondly, the workflow implementation must be realized in R according to an R-skeleton function made available by RPB to guarantee homogeneity and reusability among different RPB functions. Moreover she/he has to provide the R vignette explaining the package functionality together with an example dataset which can be used to improve the user confidence in the workflow utilization. Conclusions: Reproducible Bioinformatics Project provides a general schema and an infrastructure to distribute robust and reproducible workflows. Thus, it guarantees to final users the ability to repeat consistently any analysis independently by the used UNIX-like architecture. © 2018 The Author(s).","Chromatin Immuno precipitation sequencing; Community; Docker; MicroRNA sequencing; Reproducible research; Single nucleotide variants; Whole transcriptome sequencing","Industrial research; Reusability; Chromatin Immuno precipitation sequencing; Community; Docker; MicroRNAs; Reproducible research; Single nucleotides; Transcriptomes; Bioinformatics; microRNA; biology; computer interface; genetics; human; procedures; reproducibility; software; workflow; Computational Biology; Humans; MicroRNAs; Reproducibility of Results; Software; User-Computer Interface; Workflow",Article,"Final",Open Access,Scopus,2-s2.0-85054791952
"Guerrera D., Maffia A., Burkhart H.","56446965900;56446973500;7005750160;","Performance output data and configurations of stencil compilers experiments run through PROVA!",2018,"Data in Brief","20",,,"1148","1152",,1,"10.1016/j.dib.2018.08.092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053329141&doi=10.1016%2fj.dib.2018.08.092&partnerID=40&md5=b3391f7451423e5ded3c29261ca10e21","University of Basel, Switzerland","Guerrera, D., University of Basel, Switzerland; Maffia, A., University of Basel, Switzerland; Burkhart, H., University of Basel, Switzerland","The data in this article are related to the research article titled “Reproducible Stencil Compiler Benchmarks Using PROVA!”. Stencil kernels have been implemented using a naïve OpenMP (OpenMP Architecture Review Board, 2016) [1] parallelization and then using the stencil compilers PATUS (Christen et al., 2011) [2] and (Bondhugula et al., 2008) PLUTO [3]. Performance experiments have been run on different architectures, by using PROVA! (Guerrera et al., 2017) [4], a distributed workflow and system management tool to conduct reproducible research in computational sciences. Information like version of the compiler, compilation flags, configurations, experiment parameters and raw results are fundamental contextual information for the reproducibility of an experiment. All this information is automatically stored by PROVA! and, for the experiments presented in this paper, are available at https://github.com/sguera/FGCS17. © 2018 The Authors",,,Data Paper,"Final",Open Access,Scopus,2-s2.0-85053329141
"Funck T., Larcher K., Toussaint P.-J., Evans A.C., Thiel A.","57060089700;34771576500;7005429155;57198743053;7102603653;","APPIAN: Automated Pipeline for PET Image Analysis",2018,"Frontiers in Neuroinformatics","12",, 64,"","",,,"10.3389/fninf.2018.00064","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054790893&doi=10.3389%2ffninf.2018.00064&partnerID=40&md5=e865bfe31128306e99a1cbbb0c02ac5c","Montreal Neurological Institute, McGill University, Montreal, QC, Canada; Jewish General Hospital and Lady Davis Institute for Medical Research, Montreal, QC, Canada; Biospective Inc., Montreal, QC, Canada; Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada","Funck, T., Montreal Neurological Institute, McGill University, Montreal, QC, Canada, Jewish General Hospital and Lady Davis Institute for Medical Research, Montreal, QC, Canada; Larcher, K., Biospective Inc., Montreal, QC, Canada; Toussaint, P.-J., Montreal Neurological Institute, McGill University, Montreal, QC, Canada; Evans, A.C., Montreal Neurological Institute, McGill University, Montreal, QC, Canada, Biospective Inc., Montreal, QC, Canada, Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada; Thiel, A., Jewish General Hospital and Lady Davis Institute for Medical Research, Montreal, QC, Canada, Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada","APPIAN is an automated pipeline for user-friendly and reproducible analysis of positron emission tomography (PET) images with the aim of automating all processing steps up to the statistical analysis of measures derived from the final output images. The three primary processing steps are coregistration of PET images to T1-weighted magnetic resonance (MR) images, partial-volume correction (PVC), and quantification with tracer kinetic modeling. While there are alternate open-source PET pipelines, none offers all of the features necessary for making automated PET analysis as reliably, flexibly and easily extendible as possible. To this end, a novel method for automated quality control (QC) has been designed to facilitate reliable, reproducible research by helping users verify that each processing stage has been performed as expected. Additionally, a web browser-based GUI has been implemented to allow both the 3D visualization of the output images, as well as plots describing the quantitative results of the analyses performed by the pipeline. APPIAN also uses flexible region of interest (ROI) definition—with both volumetric and, optionally, surface-based ROI—to allow users to analyze data from a wide variety of experimental paradigms, e.g., longitudinal lesion studies, large cross-sectional population studies, multi-factorial experimental designs, etc. Finally, APPIAN is designed to be modular so that users can easily test new algorithms for PVC or quantification or add entirely new analyses to the basic pipeline. We validate the accuracy of APPIAN against the Monte-Carlo simulated SORTEO database and show that, after PVC, APPIAN recovers radiotracer concentrations within 93–100% accuracy. © 2018 Funck, Larcher, Toussaint, Evans and Thiel.","Automation; Open science; PET; Pipeline; Quality control; Software",,Article,"Final",Open Access,Scopus,2-s2.0-85054790893
"Gundersen O.E., Gil Y., Aha D.W.","6602254512;7004618158;6701853513;","On reproducible AI: Towards reproducible research, open science, and digital scholarship in AI publications",2018,"AI Magazine","39","3",,"56","68",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054057227&partnerID=40&md5=75ac2c76ff20678b78ae3a3b76dcbbaf","Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Information Sciences Institute, University of Southern California, United States; NRL's Navy Center for Applied Research in AI, Washington, DC, United States","Gundersen, O.E., Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Gil, Y., Information Sciences Institute, University of Southern California, United States; Aha, D.W., NRL's Navy Center for Applied Research in AI, Washington, DC, United States","Artificial intelligence, like any science, must rely on reproducible experiments to validate results. Our objective is to give practical and pragmatic recommendations for how to document AI research so that results are reproducible. Our analysis of the literature shows that AI publications currently fall short of providing enough documentation to facilitate reproducibility. Our suggested best practices are based on a framework for reproducibility and recommendations for best practices given by scientific organizations, scholars, and publishers. We have made a reproducibility checklist based on our investigation and described how every item in the checklist can be documented by authors and examined by reviewers. We encourage authors and reviewers to use the suggested best practices and author checklist when considering submissions for AAAI publications and conferences. Copyright © 2018, Association for the Advancement of Artificial Intelligence. All rights reserved.",,"Best practices; Open science; Reproducibilities; Reproducible research; Artificial intelligence",Review,"Final",,Scopus,2-s2.0-85054057227
"Harris J.K., Johnson K.J., Carothers B.J., Combs T.B., Luke D.A., Wang X.","16401501100;8517001600;6507048170;57194549373;7101973061;57206601361;","Use of reproducible research practices in public health: A survey of public health analysts",2018,"PLoS ONE","13","9", e0202447,"","",,2,"10.1371/journal.pone.0202447","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053127412&doi=10.1371%2fjournal.pone.0202447&partnerID=40&md5=d95acf254ceee72d7d07c083d268af8b","Brown School, Washington University in St. Louis, St. Louis, MO, United States; Center for Public Health Systems Science, Brown School, Washington University in St. Louis, St. Louis, MO, United States","Harris, J.K., Brown School, Washington University in St. Louis, St. Louis, MO, United States; Johnson, K.J., Brown School, Washington University in St. Louis, St. Louis, MO, United States; Carothers, B.J., Brown School, Washington University in St. Louis, St. Louis, MO, United States, Center for Public Health Systems Science, Brown School, Washington University in St. Louis, St. Louis, MO, United States; Combs, T.B., Brown School, Washington University in St. Louis, St. Louis, MO, United States, Center for Public Health Systems Science, Brown School, Washington University in St. Louis, St. Louis, MO, United States; Luke, D.A., Brown School, Washington University in St. Louis, St. Louis, MO, United States, Center for Public Health Systems Science, Brown School, Washington University in St. Louis, St. Louis, MO, United States; Wang, X., Brown School, Washington University in St. Louis, St. Louis, MO, United States, Center for Public Health Systems Science, Brown School, Washington University in St. Louis, St. Louis, MO, United States","Objective Use of reproducible research practices improves the quality of science and the speed of scientific development. We sought to understand use of reproducible research practices in public health and associated barriers and facilitators. Methods In late 2017, we surveyed members of the American Public Health Association Applied Public Health Statistics section and others; 247 of 278 who screened eligible answered the survey, and 209 answered every applicable question. The survey included questions about file management, code annotation and documentation, reproducibility of analyses, and facilitators and barriers of using reproducible practices. Results Just 14.4% of participants had shared code, data, or both. Many participants reported their data (33%) and code (43.2%) would be difficult for colleagues to find if they left their institution. Top reported barriers to using reproducible practices were data privacy (49.8%) and lack of time (41.7%). Participants suggested training (50.9%) and requirements by journals (44.4%) and funders (40.2%) to increase use of reproducible research practices. Conclusions Increasing use of reproducible research practices is important for public health and requires action from researchers, training programs, funders, and journals. © 2018 Harris et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; documentation; female; human; human experiment; male; medical society; privacy; reproducibility; review; scientist; statistics; training; health care organization; personnel; psychology; public health; questionnaire; Humans; Public Health; Reproducibility of Results; Research Personnel; Societies, Scientific; Surveys and Questionnaires",Review,"Final",Open Access,Scopus,2-s2.0-85053127412
"Ramachandran P.","8878850400;","Automan: A python-based automation framework for numerical computing",2018,"Computing in Science and Engineering","20","5", 8452051,"81","97",,1,"10.1109/MCSE.2018.05329818","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053066773&doi=10.1109%2fMCSE.2018.05329818&partnerID=40&md5=c7679c8e8f75987c6afc51e4ce8e8c79","Indian Institute of Technology Bombay, Department of Aerospace Engineering, India","Ramachandran, P., Indian Institute of Technology Bombay, Department of Aerospace Engineering, India","Automating computational workflows leads to more reproducible research. automan assembles a suite of long-running computations, deploys them on your computational resources, and produces final plots from output data, all with a single command. © 1999-2011 IEEE.","Automan; Numerical computing; python; Reproducible research","Computer science; Engineering; Automan; Computational resources; Computational workflows; Numerical computing; Output data; python; Reproducible research; High level languages",Article,"Final",,Scopus,2-s2.0-85053066773
"Bello N.M., Renter D.G.","55147957500;6602499538;","Invited review: Reproducible research from noisy data: Revisiting key statistical principles for the animal sciences",2018,"Journal of Dairy Science","101","7",,"5679","5701",,4,"10.3168/jds.2017-13978","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046622154&doi=10.3168%2fjds.2017-13978&partnerID=40&md5=2c0b88c3841e8c1a6a3a62f9b263efb4","Department of Animal Science, University of Wisconsin, Madison, WI  53706, United States; Department of Statistics, Kansas State University, Manhattan, 66506, United States; Center for Outcomes Research and Epidemiology, Kansas State University, Manhattan, 66506, United States; Department of Diagnostic Medicine and Pathobiology, Kansas State University, Manhattan, 66506, United States","Bello, N.M., Department of Animal Science, University of Wisconsin, Madison, WI  53706, United States, Department of Statistics, Kansas State University, Manhattan, 66506, United States, Center for Outcomes Research and Epidemiology, Kansas State University, Manhattan, 66506, United States; Renter, D.G., Center for Outcomes Research and Epidemiology, Kansas State University, Manhattan, 66506, United States, Department of Diagnostic Medicine and Pathobiology, Kansas State University, Manhattan, 66506, United States","Reproducible results define the very core of scientific integrity in modern research. Yet, legitimate concerns have been raised about the reproducibility of research findings, with important implications for the advancement of science and for public support. With statistical practice increasingly becoming an essential component of research efforts across the sciences, this review article highlights the compelling role of statistics in ensuring that research findings in the animal sciences are reproducible—in other words, able to withstand close interrogation and independent validation. Statistics set a formal framework and a practical toolbox that, when properly implemented, can recover signal from noisy data. Yet, misconceptions and misuse of statistics are recognized as top contributing factors to the reproducibility crisis. In this article, we revisit foundational statistical concepts relevant to reproducible research in the context of the animal sciences, raise awareness on common statistical misuse undermining it, and outline recommendations for statistical practice. Specifically, we emphasize a keen understanding of the data generation process throughout the research endeavor, from thoughtful experimental design and randomization, through rigorous data analysis and inference, to careful wording in communicating research results to peer scientists and society in general. We provide a detailed discussion of core concepts in experimental design, including data architecture, experimental replication, and subsampling, and elaborate on practical implications for proper elicitation of the scope of reach of research findings. For data analysis, we emphasize proper implementation of mixed models, in terms of both distributional assumptions and specification of fixed and random effects to explicitly recognize multilevel data architecture. This is critical to ensure that experimental error for treatments of interest is properly recognized and inference is correctly calibrated. Inferential misinterpretations associated with use of P-values, both significant and not, are clarified, and problems associated with error inflation due to multiple comparisons and selective reporting are illustrated. Overall, we advocate for a responsible practice of statistics in the animal sciences, with an emphasis on continuing quantitative education and interdisciplinary collaboration between animal scientists and statisticians to maximize reproducibility of research findings. © 2018 American Dairy Science Association","experimental replication; model specification; multiple testing; statistical errors","animal; biometry; laboratory; methodology; reproducibility; standards; statistics and numerical data; Animals; Biometry; Laboratory Animal Science; Reproducibility of Results; Research Design",Article,"Final",Open Access,Scopus,2-s2.0-85046622154
"Pasquier T., Lau M.K., Han X., Fong E., Lerner B.S., Boose E.R., Crosas M., Ellison A.M., Seltzer M.","55986227900;54079788000;57196260461;57202967758;57204252159;6603614747;6602344670;34975053400;7102963606;","Sharing and preserving computational analyses for posterity with encapsulator",2018,"Computing in Science and Engineering","20","4",,"111","124",,2,"10.1109/MCSE.2018.042781334","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050016565&doi=10.1109%2fMCSE.2018.042781334&partnerID=40&md5=416b5fb1f55022598792f3772326286b","University of Cambridge, United Kingdom; Harvard University, United States; Mount Holyoke College, United States","Pasquier, T., University of Cambridge, United Kingdom; Lau, M.K., Harvard University, United States; Han, X., Harvard University, United States; Fong, E., Mount Holyoke College, United States; Lerner, B.S., Mount Holyoke College, United States; Boose, E.R., Harvard University, United States; Crosas, M., Harvard University, United States; Ellison, A.M., Harvard University, United States; Seltzer, M., Harvard University, United States","Open data and open source software might be part of the solution to sciences reproducibility crisis, but they are insufficient to guarantee reproducibility. Requiring minimal end-user expertise, the encapsulator system creates a time capsule with reproducible code in a self-contained computational environment. encapsulator provides end users with a fully featured desktop environment for reproducible research. © 1999-2011 IEEE.","computational reproducibility; provenance; reproducible code; reproducible research; scientific computing; software artifact","Natural sciences computing; Open source software; Computational reproducibility; provenance; reproducible code; Reproducible research; Software artifacts; Open systems",Article,"Final",,Scopus,2-s2.0-85050016565
"Piazzi A.C., Cerqueira A.S., Manso L.R., Duque C.A.","57202763051;16686333000;57202754256;35242247800;","Reproducible research platform for electric power quality algorithms",2018,"Proceedings of International Conference on Harmonics and Quality of Power, ICHQP","2018-May",,,"1","6",,1,"10.1109/ICHQP.2018.8378938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049260837&doi=10.1109%2fICHQP.2018.8378938&partnerID=40&md5=f83b2ec3693b0423c276a04194c6a992","Universidade Federal de Juiz de Fora, Juiz de Fora, Brazil","Piazzi, A.C., Universidade Federal de Juiz de Fora, Juiz de Fora, Brazil; Cerqueira, A.S., Universidade Federal de Juiz de Fora, Juiz de Fora, Brazil; Manso, L.R., Universidade Federal de Juiz de Fora, Juiz de Fora, Brazil; Duque, C.A., Universidade Federal de Juiz de Fora, Juiz de Fora, Brazil","Scientific computation is emerging as the central pillar of science. However, loosed research practices and the own nature of the work is leading to a credibility crisis. Reproducible computational research is gaining attraction in the last decades not only because it benefits the validation and attestation of findings, making a more trustworthy publication, but also lowering the barrier of entry, making it more understandable for the target audience and, therefore, increasing its impact. In this article, an online platform where it is possible to store, share and execute linked code and data, from signal processing, applied to electric power quality, is presented. In such manner, this article presents an alternative for researchers in the field to conduct and share their work satisfying the requirements of reproducible research. © 2018 IEEE.","Power Quality; Reproducible Research; Signal Processing; Web Platform","Signal processing; Computational researches; Electric power quality; Online platforms; Reproducible research; Scientific computation; Target audience; Web Platform; Power quality",Conference Paper,"Final",,Scopus,2-s2.0-85049260837
"Deretic V., Prossnitz E., Burge M., Campen M.J., Cannon J., Liu K.J., Sklar L.A., Allers L., Garcia S.A., Baehrecke E.H., Behrends C., Cecconi F., Codogno P., Chen G.-C., Elazar Z., Eskelinen E.-L., Fourie B., Gozuacik D., Hong W., Hotamisligi G., Jäättelä M., Jo E.-K., Johansen T., Juhász G., Kimchi A., Ktistakis N., Kroemer G., MIzushima N., Münz C., Reggiori F., Rubinsztein D., Ryan K., Schroder K., Simonsen A., Tooze S., I. Vaccaro M., Yoshimori T., Yu L., Zhang H., Klionsky D.J.","7005961557;7005298531;7004421258;6602904510;7201637574;57203394850;7103239375;57201462858;57203386541;7003401481;6506663131;7005947086;7006404323;36988410800;7004282023;7004629537;7004999715;6507315780;7401528059;57203400825;57205857274;7003663754;7202347253;57202568841;7005076591;7003359642;35380287000;7006933381;57202558813;6602133625;7201740644;7201820903;8504949200;7005652988;7004652751;57203398912;7006810223;23487437700;57207484000;7004321762;","Autophagy, Inflammation, and Metabolism (AIM) Center of Biomedical Research Excellence: supporting the next generation of autophagy researchers and fostering international collaborations",2018,"Autophagy","14","6",,"925","929",,2,"10.1080/15548627.2018.1465784","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051504459&doi=10.1080%2f15548627.2018.1465784&partnerID=40&md5=c049f17e93dc38c912646b2e31cb6522","Autophagy Inflammation and Metabolism Center of Biomedical Research Excellence, University of New Mexico Health Sciences Center, Albuquerque, NM, United States; Department of Molecular, Cell and Cancer Biology, University of Massachusetts Medical School, Worcester, MA, United States; Munich Cluster of Systems Neurology (SyNergy), Ludwig-Maximilians-Universität München Feodor-Lynen Str, München, Germany; Dulbecco Telethon Institute at the Department of Biology, University of Rome ‘‘Tor Vergata”, Rome, Italy; Danish Cancer Society Research Center, Copenhagen Ø, Denmark; Institut Necker-Enfants Malades (INEM), INSERM U1151- CNRS UMR, Paris, France; The Université Paris Descartes, Sorbonne Paris Cité, Paris, France; Academia Sinica Institute of Biological Chemistry, Taipei, Taiwan; Department of Biomolecular Sciences, The Weizmann Institute of Science, Rehovot, Israel; University of Turku Institute of Biomedicine, Turku, Finland; Department of Medical Microbiology, University of Pretoria, Pretoria, South Africa; Molecular Biology Genetics and Bioengineering Program, SUNUM Nanotechnology Research and Application Center and EFSUN Nanodiagnostics Center of Excellence, Sabanci University, Istanbul, Turkey; Institute of Molecular and Cell Biology (IMCB), A*STAR, Singapore, Singapore; Department of Genetics and Complex Diseases, Harvard School of Public Health, Boston, MA, United States; The Broad Institute of Harvard and MIT, Cambridge, MA, United States; Cell Death and Metabolism Unit, Center for Autophagy, Recycling and Disease, Danish Cancer Society Research Center, Copenhagen, Denmark; Department of Microbiology, Chungnam National University School of Medicine Jung-gu, Daejeon, South Korea; Molecular Cancer Research Group, Institute of Medical Biology, University of Tromsø - The Arctic University of Norway, Tromsø, Norway; Department of Anatomy, Cell and Developmental Biology, Eotvos Lorand University, Budapest, Hungary; Institute of Genetics, Biological Research Center of the Hungarian Academy of Sciences, Szeged, Hungary; Department of Molecular Genetics, Weizmann Institute of Science, Rehovot, Israel; The Babraham Institute, Cambridge, United Kingdom; Equipe 11 labellisée par la Ligue Nationale contre le Cancer, Centre de Recherche des Cordeliers, INSERM U1138, Paris, France; Publique-Hôpitaux de Paris, Labex Immuno-Oncology, The Pôle de Biologie, Hôpital Européen Georges Pompidou, Paris, France; The Metabolomics and Cell Biology Platforms, Institut Gustave Roussy, Villejuif, France; Karolinska Institute, Department of Women’s and Children’s Health, Karolinska University Hospital, Stockholm, Sweden; Department of Biochemistry and Molecular Biology, Graduate School and Faculty of Medicine, The University of Tokyo, Tokyo, Japan; Viral Immunobiology, Institute of Experimental Immunology, University of Zürich, Zürich, Switzerland; Department of Cell Biology, University of Groningen, University Medical Center Groningen, Groningen, Netherlands; Department of Medical Genetics, Cambridge Institute for Medical Research, and UK Dementia Research Institute, Wellcome Trust/MRC Building, Cambridge Biomedical, Cambridge, United Kingdom; Cancer Research UK Beatson Institute, Glasgow, United Kingdom; Institute for Molecular Bioscience (IMB) and IMB Centre for Inflammation and Disease Research, The University of Queensland, St Lucia, Australia; Department of Molecular Medicine, Institute of Basic Medical Sciences and Centre for Cancer Cell Reprogramming, Institute of Clinical Medicine, Faculty of Medicine, University of Oslo, Oslo, Norway; Molecular Cell Biology of Autophagy Laboratory, The Francis Crick Institute, London, United Kingdom; Pathophysiology, CONICET, Institute of Biochemistry and Molecular Medicine, School of Pharmacy and Biochemistry, University of Buenos Aires, Buenos Aires, Argentina; Department of Genetics, Graduate School of Medicine, Osaka University, Osaka, Japan; Laboratory of Intracellular Membrane Dynamics, Graduate School of Frontier Biosciences, Osaka University, Osaka, Japan; The State Key Laboratory of Membrane Biology, Tsinghua University-Peking University Joint Centre for Life Sciences, School of Life Sciences, Tsinghua University, Beijing, China; National Laboratory of Biomacromolecules, CAS Center for Excellence in Biomacromolecules, Institute of Biophysics, and College of Life Sciences, University of Chinese Academy of Sciences, Beijing, China; Life Sciences Institute, University of Michigan, Ann Arbor, United States","Deretic, V., Autophagy Inflammation and Metabolism Center of Biomedical Research Excellence, University of New Mexico Health Sciences Center, Albuquerque, NM, United States; Prossnitz, E., Autophagy Inflammation and Metabolism Center of Biomedical Research Excellence, University of New Mexico Health Sciences Center, Albuquerque, NM, United States; Burge, M., Autophagy Inflammation and Metabolism Center of Biomedical Research Excellence, University of New Mexico Health Sciences Center, Albuquerque, NM, United States; Campen, M.J., Autophagy Inflammation and Metabolism Center of Biomedical Research Excellence, University of New Mexico Health Sciences Center, Albuquerque, NM, United States; Cannon, J., Autophagy Inflammation and Metabolism Center of Biomedical Research Excellence, University of New Mexico Health Sciences Center, Albuquerque, NM, United States; Liu, K.J., Autophagy Inflammation and Metabolism Center of Biomedical Research Excellence, University of New Mexico Health Sciences Center, Albuquerque, NM, United States; Sklar, L.A., Autophagy Inflammation and Metabolism Center of Biomedical Research Excellence, University of New Mexico Health Sciences Center, Albuquerque, NM, United States; Allers, L., Autophagy Inflammation and Metabolism Center of Biomedical Research Excellence, University of New Mexico Health Sciences Center, Albuquerque, NM, United States; Garcia, S.A., Autophagy Inflammation and Metabolism Center of Biomedical Research Excellence, University of New Mexico Health Sciences Center, Albuquerque, NM, United States; Baehrecke, E.H., Department of Molecular, Cell and Cancer Biology, University of Massachusetts Medical School, Worcester, MA, United States; Behrends, C., Munich Cluster of Systems Neurology (SyNergy), Ludwig-Maximilians-Universität München Feodor-Lynen Str, München, Germany; Cecconi, F., Dulbecco Telethon Institute at the Department of Biology, University of Rome ‘‘Tor Vergata”, Rome, Italy, Danish Cancer Society Research Center, Copenhagen Ø, Denmark; Codogno, P., Institut Necker-Enfants Malades (INEM), INSERM U1151- CNRS UMR, Paris, France, The Université Paris Descartes, Sorbonne Paris Cité, Paris, France; Chen, G.-C., Academia Sinica Institute of Biological Chemistry, Taipei, Taiwan; Elazar, Z., Department of Biomolecular Sciences, The Weizmann Institute of Science, Rehovot, Israel; Eskelinen, E.-L., University of Turku Institute of Biomedicine, Turku, Finland; Fourie, B., Department of Medical Microbiology, University of Pretoria, Pretoria, South Africa; Gozuacik, D., Molecular Biology Genetics and Bioengineering Program, SUNUM Nanotechnology Research and Application Center and EFSUN Nanodiagnostics Center of Excellence, Sabanci University, Istanbul, Turkey; Hong, W., Institute of Molecular and Cell Biology (IMCB), A*STAR, Singapore, Singapore; Hotamisligi, G., Department of Genetics and Complex Diseases, Harvard School of Public Health, Boston, MA, United States, The Broad Institute of Harvard and MIT, Cambridge, MA, United States; Jäättelä, M., Cell Death and Metabolism Unit, Center for Autophagy, Recycling and Disease, Danish Cancer Society Research Center, Copenhagen, Denmark; Jo, E.-K., Department of Microbiology, Chungnam National University School of Medicine Jung-gu, Daejeon, South Korea; Johansen, T., Molecular Cancer Research Group, Institute of Medical Biology, University of Tromsø - The Arctic University of Norway, Tromsø, Norway; Juhász, G., Department of Anatomy, Cell and Developmental Biology, Eotvos Lorand University, Budapest, Hungary, Institute of Genetics, Biological Research Center of the Hungarian Academy of Sciences, Szeged, Hungary; Kimchi, A., Department of Molecular Genetics, Weizmann Institute of Science, Rehovot, Israel; Ktistakis, N., The Babraham Institute, Cambridge, United Kingdom; Kroemer, G., The Université Paris Descartes, Sorbonne Paris Cité, Paris, France, Equipe 11 labellisée par la Ligue Nationale contre le Cancer, Centre de Recherche des Cordeliers, INSERM U1138, Paris, France, Publique-Hôpitaux de Paris, Labex Immuno-Oncology, The Pôle de Biologie, Hôpital Européen Georges Pompidou, Paris, France, The Metabolomics and Cell Biology Platforms, Institut Gustave Roussy, Villejuif, France, Karolinska Institute, Department of Women’s and Children’s Health, Karolinska University Hospital, Stockholm, Sweden; MIzushima, N., Department of Biochemistry and Molecular Biology, Graduate School and Faculty of Medicine, The University of Tokyo, Tokyo, Japan; Münz, C., Viral Immunobiology, Institute of Experimental Immunology, University of Zürich, Zürich, Switzerland; Reggiori, F., Department of Cell Biology, University of Groningen, University Medical Center Groningen, Groningen, Netherlands; Rubinsztein, D., Department of Medical Genetics, Cambridge Institute for Medical Research, and UK Dementia Research Institute, Wellcome Trust/MRC Building, Cambridge Biomedical, Cambridge, United Kingdom; Ryan, K., Cancer Research UK Beatson Institute, Glasgow, United Kingdom; Schroder, K., Institute for Molecular Bioscience (IMB) and IMB Centre for Inflammation and Disease Research, The University of Queensland, St Lucia, Australia; Simonsen, A., Department of Molecular Medicine, Institute of Basic Medical Sciences and Centre for Cancer Cell Reprogramming, Institute of Clinical Medicine, Faculty of Medicine, University of Oslo, Oslo, Norway; Tooze, S., Molecular Cell Biology of Autophagy Laboratory, The Francis Crick Institute, London, United Kingdom; I. Vaccaro, M., Pathophysiology, CONICET, Institute of Biochemistry and Molecular Medicine, School of Pharmacy and Biochemistry, University of Buenos Aires, Buenos Aires, Argentina; Yoshimori, T., Department of Genetics, Graduate School of Medicine, Osaka University, Osaka, Japan, Laboratory of Intracellular Membrane Dynamics, Graduate School of Frontier Biosciences, Osaka University, Osaka, Japan; Yu, L., The State Key Laboratory of Membrane Biology, Tsinghua University-Peking University Joint Centre for Life Sciences, School of Life Sciences, Tsinghua University, Beijing, China; Zhang, H., National Laboratory of Biomacromolecules, CAS Center for Excellence in Biomacromolecules, Institute of Biophysics, and College of Life Sciences, University of Chinese Academy of Sciences, Beijing, China; Klionsky, D.J., Life Sciences Institute, University of Michigan, Ann Arbor, United States","Recently, NIH has funded a center for autophagy research named the Autophagy, Inflammation, and Metabolism (AIM) Center of Biomedical Research Excellence, located at the University of New Mexico Health Science Center (UNM HSC), with aspirations to promote autophagy research locally, nationally, and internationally. The center has 3 major missions: (i) to support junior faculty in their endeavors to develop investigations in this area and obtain independent funding; (ii) to develop and provide technological platforms to advance autophagy research with emphasis on cellular approaches for high quality reproducible research; and (iii) to foster international collaborations through the formation of an International Council of Affiliate Members and through hosting national and international workshops and symposia. Scientifically, the AIM center is focused on autophagy and its intersections with other processes, with emphasis on both fundamental discoveries and applied translational research. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.",,"autophagy; cooperation; Editorial; human; inflammation; medical research; metabolism; symposium; translational research; workshop; inflammation; information dissemination; international cooperation; medical research; organization; pathology; personnel; Autophagy; Biomedical Research; Congresses as Topic; Inflammation; Information Dissemination; International Cooperation; Research Personnel",Editorial,"Final",Open Access,Scopus,2-s2.0-85051504459
"Mei Z., Zhao X., Chen H., Chen W.","57192591076;57202323601;57192592821;57087429900;","Bio-signal complexity analysis in epileptic seizure monitoring: A topic review",2018,"Sensors (Switzerland)","18","6", 1720,"","",,6,"10.3390/s18061720","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047843772&doi=10.3390%2fs18061720&partnerID=40&md5=92c511d6d0966801396e24140df29d78","Center for Intelligent Medical Electronics (CIME), School of Information Science and Engineering, Fudan University, Shanghai, 200433, China; Department of Industrial Design, Eindhoven University of Technology, PO Box 513, Eindhoven, 5600 MB, Netherlands; Shanghai Key Laboratory of Medical Imaging Computing and Computer Assisted Intervention, Shanghai, 200032, China","Mei, Z., Center for Intelligent Medical Electronics (CIME), School of Information Science and Engineering, Fudan University, Shanghai, 200433, China; Zhao, X., Center for Intelligent Medical Electronics (CIME), School of Information Science and Engineering, Fudan University, Shanghai, 200433, China; Chen, H., Department of Industrial Design, Eindhoven University of Technology, PO Box 513, Eindhoven, 5600 MB, Netherlands; Chen, W., Center for Intelligent Medical Electronics (CIME), School of Information Science and Engineering, Fudan University, Shanghai, 200433, China, Shanghai Key Laboratory of Medical Imaging Computing and Computer Assisted Intervention, Shanghai, 200032, China","Complexity science has provided new perspectives and opportunities for understanding a variety of complex natural or social phenomena, including brain dysfunctions like epilepsy. By delving into the complexity in electrophysiological signals and neuroimaging, new insights have emerged. These discoveries have revealed that complexity is a fundamental aspect of physiological processes. The inherent nonlinearity and non-stationarity of physiological processes limits the methods based on simpler underlying assumptions to point out the pathway to a more comprehensive understanding of their behavior and relation with certain diseases. The perspective of complexity may benefit both the research and clinical practice through providing novel data analytics tools devoted for the understanding of and the intervention about epilepsies. This review aims to provide a sketchy overview of the methods derived from different disciplines lucubrating to the complexity of bio-signals in the field of epilepsy monitoring. Although the complexity of bio-signals is still not fully understood, bundles of new insights have been already obtained. Despite the promising results about epileptic seizure detection and prediction through offline analysis, we are still lacking robust, tried-and-true real-time applications. Multidisciplinary collaborations and more high-quality data accessible to the whole community are needed for reproducible research and the development of such applications. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Complex network; Epileptic seizure; Machine learning; Non-stationary signal processing; Nonlinear dynamics","Clinical research; Dynamics; Electrophysiology; Learning systems; Neurodegenerative diseases; Neuroimaging; Neurophysiology; Signal processing; Electrophysiological signals; Epileptic seizure detection; Epileptic seizures; Multi-disciplinary collaborations; Nonstationary signal processing; Physiological process; Real-time application; Reproducible research; Complex networks; brain; diagnostic imaging; electroencephalography; human; pathophysiology; physiologic monitoring; procedures; seizure; signal processing; system analysis; Brain; Electroencephalography; Humans; Monitoring, Physiologic; Seizures; Signal Processing, Computer-Assisted; Systems Analysis",Review,"Final",Open Access,Scopus,2-s2.0-85047843772
"Milfont T.L., Klein R.A.","8156566400;56188254500;","Replication and Reproducibility in Cross-Cultural Psychology",2018,"Journal of Cross-Cultural Psychology","49","5",,"735","750",,3,"10.1177/0022022117744892","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047342326&doi=10.1177%2f0022022117744892&partnerID=40&md5=4e73dc9c65155990d34f82fb97517e1a","Centre for Applied Cross-Cultural Research, Victoria University of Wellington, New Zealand; University of Florida, Gainesville, United States","Milfont, T.L., Centre for Applied Cross-Cultural Research, Victoria University of Wellington, New Zealand; Klein, R.A., University of Florida, Gainesville, United States","Replication is the scientific gold standard that enables the confirmation of research findings. Concerns related to publication bias, flexibility in data analysis, and high-profile cases of academic misconduct have led to recent calls for more replication and systematic accumulation of scientific knowledge in psychological science. This renewed emphasis on replication may pose specific challenges to cross-cultural research due to inherent practical difficulties in emulating an original study in other cultural groups. The purpose of the present article is to discuss how the core concepts of this replication debate apply to cross-cultural psychology. Distinct to replications in cross-cultural research are examinations of bias and equivalence in manipulations and procedures, and that targeted research populations may differ in meaningful ways. We identify issues in current psychological research (analytic flexibility, low power) and possible solutions (preregistration, power analysis), and discuss ways to implement best practices in cross-cultural replication attempts. © 2017, © The Author(s) 2017.","cross-cultural psychology; cross-cultural replication; cross-cultural research; replication; reproducible research","article; cultural psychology; human; power analysis; reproducibility",Article,"Final",,Scopus,2-s2.0-85047342326
"Dragly S.-A., Hobbi Mobarhan M., Lepperød M.E., Tennøe S., Fyhn M., Hafting T., Malthe-Sørenssen A.","57196175949;57196177247;55983543900;57196177507;6603079272;8716004500;6602605803;","Experimental directory structure (Exdir): An alternative to HDF5 without introducing a new file format",2018,"Frontiers in Neuroinformatics","12",, 16,"","",,1,"10.3389/fninf.2018.00016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049118577&doi=10.3389%2ffninf.2018.00016&partnerID=40&md5=0fbb537d307f063cbadc0b6c6fb97358","Centre for Integrative Neuroplasticity, University of Oslo, Oslo, Norway; Department of Physics, University of Oslo, Oslo, Norway; Department of Biosciences, University of Oslo, Oslo, Norway; Institute of Basic Medical Sciences, University of Oslo, Oslo, Norway; Department of Informatics, University of Oslo, Oslo, Norway","Dragly, S.-A., Centre for Integrative Neuroplasticity, University of Oslo, Oslo, Norway, Department of Physics, University of Oslo, Oslo, Norway; Hobbi Mobarhan, M., Centre for Integrative Neuroplasticity, University of Oslo, Oslo, Norway, Department of Biosciences, University of Oslo, Oslo, Norway; Lepperød, M.E., Centre for Integrative Neuroplasticity, University of Oslo, Oslo, Norway, Institute of Basic Medical Sciences, University of Oslo, Oslo, Norway; Tennøe, S., Centre for Integrative Neuroplasticity, University of Oslo, Oslo, Norway, Department of Informatics, University of Oslo, Oslo, Norway; Fyhn, M., Centre for Integrative Neuroplasticity, University of Oslo, Oslo, Norway, Department of Biosciences, University of Oslo, Oslo, Norway; Hafting, T., Centre for Integrative Neuroplasticity, University of Oslo, Oslo, Norway, Institute of Basic Medical Sciences, University of Oslo, Oslo, Norway; Malthe-Sørenssen, A., Centre for Integrative Neuroplasticity, University of Oslo, Oslo, Norway, Department of Physics, University of Oslo, Oslo, Norway","Natural sciences generate an increasing amount of data in a wide range of formats developed by different research groups and commercial companies. At the same time there is a growing desire to share data along with publications in order to enable reproducible research. Open formats have publicly available specifications which facilitate data sharing and reproducible research. Hierarchical Data Format 5 (HDF5) is a popular open format widely used in neuroscience, often as a foundation for other, more specialized formats. However, drawbacks related to HDF5’s complex specification have initiated a discussion for an improved replacement. We propose a novel alternative, the Experimental Directory Structure (Exdir), an open specification for data storage in experimental pipelines which amends drawbacks associated with HDF5 while retaining its advantages. HDF5 stores data and metadata in a hierarchy within a complex binary file which, among other things, is not human-readable, not optimal for version control systems, and lacks support for easy access to raw data from external applications. Exdir, on the other hand, uses file system directories to represent the hierarchy, with metadata stored in human-readable YAML files, datasets stored in binary NumPy files, and raw data stored directly in subdirectories. Furthermore, storing data in multiple files makes it easier to track for version control systems. Exdir is not a file format in itself, but a specification for organizing files in a directory structure. Exdir uses the same abstractions as HDF5 and is compatible with the HDF5 Abstract Data Model. Several research groups are already using data stored in a directory hierarchy as an alternative to HDF5, but no common standard exists. This complicates and limits the opportunity for data sharing and development of common tools for reading, writing, and analyzing data. Exdir facilitates improved data storage, data sharing, reproducible research, and novel insight from interdisciplinary collaboration. With the publication of Exdir, we invite the scientific community to join the development to create an open specification that will serve as many needs as possible and as a foundation for open access to and exchange of data. © 2018 Dragly, Hobbi Mobarhan, Lepperød, Tennøe, Fyhn, Hafting and Malthe-Sørenssen.","Analysis; Data management; Data storage; File format; Python","article; control system; directory; human; human experiment; metadata; neuroscience; pipeline; publication; writing",Article,"Final",Open Access,Scopus,2-s2.0-85049118577
"Manninen T., Havela R., Linne M.-L.","7004047491;37099931600;7003720169;","Computational models for calcium-mediated astrocyte functions",2018,"Frontiers in Computational Neuroscience","12",, 14,"","",,10,"10.3389/fncom.2018.00014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049072275&doi=10.3389%2ffncom.2018.00014&partnerID=40&md5=cb176b9cb8317b29fd8caf37912b188e","Computational Neuroscience Group, BioMediTech Institute, Faculty of Biomedical Sciences and Engineering, Tampere University of Technology, Tampere, Finland","Manninen, T., Computational Neuroscience Group, BioMediTech Institute, Faculty of Biomedical Sciences and Engineering, Tampere University of Technology, Tampere, Finland; Havela, R., Computational Neuroscience Group, BioMediTech Institute, Faculty of Biomedical Sciences and Engineering, Tampere University of Technology, Tampere, Finland; Linne, M.-L., Computational Neuroscience Group, BioMediTech Institute, Faculty of Biomedical Sciences and Engineering, Tampere University of Technology, Tampere, Finland","The computational neuroscience field has heavily concentrated on the modeling of neuronal functions, largely ignoring other brain cells, including one type of glial cell, the astrocytes. Despite the short history of modeling astrocytic functions, we were delighted about the hundreds of models developed so far to study the role of astrocytes, most often in calcium dynamics, synchronization, information transfer, and plasticity in vitro, but also in vascular events, hyperexcitability, and homeostasis. Our goal here is to present the state-of-the-art in computational modeling of astrocytes in order to facilitate better understanding of the functions and dynamics of astrocytes in the brain. Due to the large number of models, we concentrated on a hundred models that include biophysical descriptions for calcium signaling and dynamics in astrocytes. We categorized the models into four groups: single astrocyte models, astrocyte network models, neuron-astrocyte synapse models, and neuron-astrocyte network models to ease their use in future modeling projects. We characterized the models based on which earlier models were used for building the models and which type of biological entities were described in the astrocyte models. Features of the models were compared and contrasted so that similarities and differences were more readily apparent. We discovered that most of the models were basically generated froma small set of previously published models with small variations. However, neither citations to all the previous models with similar core structure nor explanations of what was built on top of the previous models were provided, which made it possible, in some cases, to have the same models published several times without an explicit intention to make new predictions about the roles of astrocytes in brain functions. Furthermore, only a fewof the models are available online which makes it difficult to reproduce the simulation results and further develop the models. Thus, we would like to emphasize that only via reproducible research are we able to build better computational models for astrocytes, which truly advance science. Our study is the first to characterize in detail the biophysical and biochemical mechanisms that have been modeled for astrocytes. © 2018 Manninen, Havela and Linne.","Astrocyte; Astrocyte network; Computational model; Glia; Intracellular calcium; Neuron-astrocyte network; Simulation; Synapse","Calcium; Computation theory; Computational methods; Dynamics; Astrocyte; Computational model; Glia; Intracellular calcium; Simulation; Synapse; Neurons; calcium ion; astrocyte; calcium cell level; calcium signaling; calcium transport; cell function; computational fluid dynamics; controlled study; human; molecular dynamics; nerve cell network; Review; synapse",Review,"Final",Open Access,Scopus,2-s2.0-85049072275
"Woodson C., Hayes J.H., Griffioen S.","57170303600;7403554664;57203515048;","Towards reproducible research: Automatic classification of empirical requirements engineering papers",2018,"Proceedings of the ACMSE 2018 Conference","2018-January",, a8,"","",,,"10.1145/3190645.3190689","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052022021&doi=10.1145%2f3190645.3190689&partnerID=40&md5=12c47824050e2c936d29e2edee9ae3aa","Department of Computer Science, University of Kentucky, Lexington, KY, United States","Woodson, C., Department of Computer Science, University of Kentucky, Lexington, KY, United States; Hayes, J.H., Department of Computer Science, University of Kentucky, Lexington, KY, United States; Griffioen, S., Department of Computer Science, University of Kentucky, Lexington, KY, United States","Research must be reproducible in order to make an impact on science and to contribute to the body of knowledge in our field. Yet studies have shown that 70% of research from academic labs cannot be reproduced. In software engineering, and more specifically requirements engineering (RE), reproducible research is rare, with datasets not always available or methods not fully described. This lack of reproducible research hinders progress, with researchers having to replicate an experiment from scratch. A researcher starting out in RE has to sift through conference papers, finding ones that are empirical, then must look through the data available from the empirical paper (if any) to make a preliminary determination if the paper can be reproduced. This paper addresses two parts of that problem, identifying RE papers and identifying empirical papers within the RE papers. Recent RE and empirical conference papers were used to learn features and to build an automatic classifier to identify RE and empirical papers. We introduce the Empirical Requirements Research Classifier (ERRC) method, which uses natural language processing and machine learning to perform supervised classification of conference papers. We compare our method to a baseline keyword-based approach. To evaluate our approach, we examine sets of papers from the IEEE Requirements Engineering conference and the IEEE International Symposium on Software Testing and Analysis. We found that the ERRC method performed better than the baseline method in all but a few cases. © 2018 Association for Computing Machinery.","Empirical research; Information retrieval; Machine learning; Reproducible research; Requirements engineering; Statistical analysis; Supervised classification learning; Text classification","Artificial intelligence; Engineering education; Information retrieval; Learning algorithms; Learning systems; Natural language processing systems; Requirements engineering; Search engines; Software testing; Statistical methods; Supervised learning; Text processing; Automatic classification; Automatic classifiers; Empirical research; Reproducible research; Requirements research; Software testing and analysis; Supervised classification; Text classification; Classification (of information)",Conference Paper,"Final",,Scopus,2-s2.0-85052022021
"Merli R., Preziosi M., Acampora A.","55898797000;56308556300;57200035865;","How do scholars approach the circular economy? A systematic literature review",2018,"Journal of Cleaner Production","178",,,"703","722",,83,"10.1016/j.jclepro.2017.12.112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041837737&doi=10.1016%2fj.jclepro.2017.12.112&partnerID=40&md5=2a007f375bca051e8787f7279aceb52c","Roma Tre University, Department of Business Studies, Via Silvio D'Amico, 77, Roma, 00145, Italy","Merli, R., Roma Tre University, Department of Business Studies, Via Silvio D'Amico, 77, Roma, 00145, Italy; Preziosi, M., Roma Tre University, Department of Business Studies, Via Silvio D'Amico, 77, Roma, 00145, Italy; Acampora, A., Roma Tre University, Department of Business Studies, Via Silvio D'Amico, 77, Roma, 00145, Italy","Circular Economy (CE) aims to overcome the take-make-dispose linear pattern of production and consumption, proposing a circular system in which the value of products, materials and resources is maintained in the economy as long as possible. In recent years there has been a proliferation of scholars' publications on the topic. This study presents the results of a systematic literature review exploring the state-of-the-art of academic research on CE. The paper examines the CE body of literature with a systematic approach, to provide an exhaustive analysis of the phenomenon with rigorous and reproducible research criteria. The revisited material consists of 565 articles collected through the Web of Science and Scopus databases, and has been evaluated using specific structural dimensions to group literature into analytical categories. Starting from being a concept studied in connection with industrial ecology, CE has slowly acquired its independent role in academic research, framed mainly into environmental sustainability related studies. As a result of policies implementation, academic production is mainly concentrated in China and Europe, employing tools and methods for modelling processes and supporting decision-making for CE implementation (e.g. Life Cycle Assessment and Material Flow Analysis). CE studies follow three main lines of action: the first aims to change the social and economic dynamics at macro and administrative level; the second to support firms in circular processes implementation at micro level to spread new forms of consumption and product design; the third, developed at meso level, discusses industrial symbiosis experiences. CE is associated with a variety of concepts, and waste management emerges as the most relevant sub-sector. CE is also strongly connected with the concept of sustainability, proposing ways to operationalize its implementation at the environmental and economic level, while scholars only marginally consider social and institutional implications. The most explored practices are those related to cleaner production, aiming at reducing environmental impact and waste production along the life cycle of a product, and optimizing the performance and efficiency of processes. Conversely, studies on CE may devote greater attention to strategies for social and institutional changes, able to transform the upstream process of production and consumption. Considering business model strategies, scholars mainly focus on studying closing material loops strategy, while slowing the loops, which requires a radical change of consumption and production patterns, is only marginally included with respect to CE implementation. This study's findings highlight CE as an evolving concept that still requires development to consolidate its definition, boundaries, principles and associated practices. © 2017 Elsevier Ltd","Circular business model; Circular economy; Industrial ecology; Sustainability; Systematic literature review","Decision making; Ecology; Efficiency; Environmental impact; Industrial economics; Industrial research; Pollution control; Product design; Sustainable development; Waste management; Business modeling; Circular economy; Environmental sustainability; Industrial ecology; Life Cycle Assessment (LCA); Material flow analysis; Production and consumption; Systematic literature review; Life cycle",Review,"Final",,Scopus,2-s2.0-85041837737
"Fanelli D.","26644812800;","Is science really facing a reproducibility crisis, and do we need it to?",2018,"Proceedings of the National Academy of Sciences of the United States of America","115","11",,"2628","2631",,43,"10.1073/pnas.1708272114","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043790066&doi=10.1073%2fpnas.1708272114&partnerID=40&md5=2d879c76857a7521af2ee3cf61fa4dc7","Department of Methodology, London School of Economics and Political Science, London, WC2A 2AE, United Kingdom","Fanelli, D., Department of Methodology, London School of Economics and Political Science, London, WC2A 2AE, United Kingdom","Efforts to improve the reproducibility and integrity of science are typically justified by a narrative of crisis, according to which most published results are unreliable due to growing problems with research and publication practices. This article provides an overview of recent evidence suggesting that this narrative is mistaken, and argues that a narrative of epochal changes and empowerment of scientists would be more accurate, inspiring, and compelling. © 2018 National Academy of Sciences. All Rights Reserved.","Bias; Crisis; Integrity; Misconduct; Reproducible research","evidence based practice; open access publishing; priority journal; publication; reproducibility; research; Review; science; scientific literature; scientist; systematic error",Review,"Final",Open Access,Scopus,2-s2.0-85043790066
"Stodden V., Seiler J., Ma Z.","15623425400;24544970900;55771384400;","An empirical analysis of journal policy effectiveness for computational reproducibility",2018,"Proceedings of the National Academy of Sciences of the United States of America","115","11",,"2584","2589",,42,"10.1073/pnas.1708290115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043778648&doi=10.1073%2fpnas.1708290115&partnerID=40&md5=6b4b3b6a9c0dfdfdd730cb96548031f1","School of Information Sciences, University of Illinois at Urbana–Champaign, Champaign, IL  61820, United States; Department of Statistics, Columbia University, New York, NY  10027, United States","Stodden, V., School of Information Sciences, University of Illinois at Urbana–Champaign, Champaign, IL  61820, United States; Seiler, J., Department of Statistics, Columbia University, New York, NY  10027, United States; Ma, Z., Department of Statistics, Columbia University, New York, NY  10027, United States","A key component of scientific communication is sufficient information for other researchers in the field to reproduce published findings. For computational and data-enabled research, this has often been interpreted to mean making available the raw data from which results were generated, the computer code that generated the findings, and any additional information needed such as workflows and input parameters. Many journals are revising author guidelines to include data and code availability. This work evaluates the effectiveness of journal policy that requires the data and code necessary for reproducibility be made available postpub-lication by the authors upon request. We assess the effectiveness of such a policy by (i) requesting data and code from authors and (ii) attempting replication of the published findings. We chose a random sample of 204 scientific papers published in the journal Science after the implementation of their policy in February 2011. We found that we were able to obtain artifacts from 44% of our sample and were able to reproduce the findings for 26%. We find this policy—author remission of data and code postpublication upon request—an improvement over no policy, but currently insufficient for reproducibility. © 2018 National Academy of Sciences. All Rights Reserved.","Code access; Data access; Open science; Reproducibility policy; Reproducible research","Article; artifact; data analysis; empirical research; human; journal policy effectiveness; mathematical computing; priority journal; publication; publishing; quality control procedures; reproducibility; sample size; science; scientific literature; article; comparative effectiveness; random sample; remission",Article,"Final",Open Access,Scopus,2-s2.0-85043778648
"Lewis K.P., Vander Wal E., Fifield D.A.","8075014800;35231366100;24078159100;","Wildlife biology, big data, and reproducible research",2018,"Wildlife Society Bulletin","42","1",,"172","179",,7,"10.1002/wsb.847","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044406034&doi=10.1002%2fwsb.847&partnerID=40&md5=d66dc64d647a66ac8938bf1ace157a7d","Department of Biology, Memorial University of Newfoundland, St. John’s, NL  A1B 3X9, Canada; Division of Wildlife Research, Environment and Climate Change Canada, 6 Bruce Street, Mount Pearl, NL  A1N 4T3, Canada; Department of Fisheries and Oceans, NorthWest Atlantic Fisheries Centre, 80 East White Hills Road, PO Box 5667, St. John’s, NL  A1C 5X1, Canada","Lewis, K.P., Department of Biology, Memorial University of Newfoundland, St. John’s, NL  A1B 3X9, Canada, Department of Fisheries and Oceans, NorthWest Atlantic Fisheries Centre, 80 East White Hills Road, PO Box 5667, St. John’s, NL  A1C 5X1, Canada; Vander Wal, E., Department of Biology, Memorial University of Newfoundland, St. John’s, NL  A1B 3X9, Canada; Fifield, D.A., Division of Wildlife Research, Environment and Climate Change Canada, 6 Bruce Street, Mount Pearl, NL  A1N 4T3, Canada","Changes in technology have made it possible to gather vast amounts of data, often of high quality, that in turn can improve the quality of wildlife biology. However, with this growth in data, practices such as data management, exploratory data analysis, data-sharing, and reproducibility of an analysis have become increasingly complex. These practices often depend heavily on computer scripting languages, and are often hidden from the peer-review process despite their influence on the final results. Although these issues have been discussed in the literature, they are generally dealt with in a piecemeal fashion, preventing synthesis, and thereby slowing progress. We offer a conceptual framework to illustrate relationships among these practices, and show where wildlife biology as a field has embraced these changes, where awareness is growing, and where it lags behind other fields. We then present several case studies to emphasize the importance of adopting these practices. Any of these case studies could have been conducted with little attention to these practices or employing scripting languages, but there are many disadvantages to this approach including increased chance of errors, inefficiency, and lack of reproducibility. We suggest that a change in the culture of how wildlife biology is conducted is required and that this change will be fostered by integrating these practices into wildlife biology education, implementation, and embracing the idea of open data and open computer code. © 2018 The Wildlife Society. © The Wildlife Society, 2018","data management; data pipeline; exploratory data analysis; open science; reproducible research","computer simulation; conceptual framework; data assimilation; data management; data quality; exploration; literature review; research work; wildlife management",Article,"Final",,Scopus,2-s2.0-85044406034
"Feeney J.R.","36682359100;","Robust Science: A Review of Journal Practices in Industrial-Organizational Psychology",2018,"Industrial and Organizational Psychology","11","1",,"48","54",,1,"10.1017/iop.2017.84","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043298113&doi=10.1017%2fiop.2017.84&partnerID=40&md5=9a85bedc3d40a91c722921420ebe9894","Hill and Levene Schools of Business, University of Regina, Edu Bldg, Bus. Admin, 3737 Wascana Parkway, Regina, SK  S4S 0A2, Canada","Feeney, J.R., Hill and Levene Schools of Business, University of Regina, Edu Bldg, Bus. Admin, 3737 Wascana Parkway, Regina, SK  S4S 0A2, Canada","The focal article (Grand et al., 2018) provides an exemplary roadmap for improving the practice of robust science in industrial-organizational (I-O) psychology, which includes recommendations for authors such as practicing robust science, even in the absence of reward. However, authors are faced with practical constraints; to succeed in our field, we must publish, at least occasionally, in prestigious journals to secure scholarships, awards, employment, grants, and tenure. We can practice robust science (commonly referred to as open science or reproducible research) without reward - but only to some extent, if there is no support from our gatekeepers. After all, it is difficult to influence the field without a job and research funding. Copyright © 2018 Society for Industrial and Organizational Psychology.",,,Review,"Final",,Scopus,2-s2.0-85043298113
"Alter G., Gonzalez R.","7006576788;55138333000;","Responsible practices for data sharing",2018,"American Psychologist","73","2",,"146","156",,6,"10.1037/amp0000258","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042564785&doi=10.1037%2famp0000258&partnerID=40&md5=5d8fa1f1584f65424f0ee70bdf19f6b7","Inter-university Consortium for Political and Social Research, University of Michigan, United States; Department of Psychology and the Research Center for Group Dynamics, University of Michigan, United States","Alter, G., Inter-university Consortium for Political and Social Research, University of Michigan, United States; Gonzalez, R., Department of Psychology and the Research Center for Group Dynamics, University of Michigan, United States","Research transparency, reproducibility, and data sharing uphold core principles of science at a time when the integrity of scientific research is being questioned. This article discusses how research data in psychology can be made accessible for reproducibility and reanalysis by describing practical ways to overcome barriers to data sharing. We examine key issues surrounding the sharing of data such as who owns research data, how to protect the confidentiality of the research participant, how to give appropriate credit to the data creator, how to deal with metadata and codebooks, how to address provenance, and other specifics such as versioning and file formats. The protection of research subjects is a fundamental obligation, and we explain frameworks and procedures designed to protect against the harms that may result from disclosure of confidential information. We also advocate greater recognition for data creators and the authors of program code used in the management and analysis of data. We argue that research data and program code are important scientific contributions that should be cited in the same way as publications. © 2018 American Psychological Association.","Data sharing; Reproducible research; Research ethics","confidentiality; ethics; human; information dissemination; methodology; psychology; reproducibility; research ethics; research subject; Confidentiality; Ethics, Research; Humans; Information Dissemination; Psychology; Reproducibility of Results; Research Design; Research Subjects",Article,"Final",,Scopus,2-s2.0-85042564785
"Hertwich E., Heeren N., Kuczenski B., Majeau-Bettez G., Myers R.J., Pauliuk S., Stadler K., Lifset R.","6701785583;54892817300;8652033100;37561589300;55162811600;36051903700;34972125100;6602882935;","Nullius in Verba1: Advancing Data Transparency in Industrial Ecology",2018,"Journal of Industrial Ecology","22","1",,"6","17",,11,"10.1111/jiec.12738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041078828&doi=10.1111%2fjiec.12738&partnerID=40&md5=a259e78bb48f8f6f13c7179e1ee5e2d1","School of Forestry and Environmental Studies, Yale University, New Haven, CT, United States; Institute of Environmental Engineering, ETH Zurich, Zurich, Switzerland; Institute for Social, Behavioral, and Economic Research, University of California, Santa Barbara, CA, United States; Ecole Polytechnique de Montreal, CIRAIG, Montreal, QC, Canada; Industrial Ecology Programme, Norwegian University of Science & Technology, Trondheim, Norway; School of Engineering, University of Edinburgh, Edinburgh, United Kingdom; Faculty of Environment and Natural Resources, University of Freiburg, Freiburg, Germany","Hertwich, E., School of Forestry and Environmental Studies, Yale University, New Haven, CT, United States; Heeren, N., Institute of Environmental Engineering, ETH Zurich, Zurich, Switzerland; Kuczenski, B., Institute for Social, Behavioral, and Economic Research, University of California, Santa Barbara, CA, United States; Majeau-Bettez, G., Ecole Polytechnique de Montreal, CIRAIG, Montreal, QC, Canada, Industrial Ecology Programme, Norwegian University of Science & Technology, Trondheim, Norway; Myers, R.J., School of Engineering, University of Edinburgh, Edinburgh, United Kingdom; Pauliuk, S., Faculty of Environment and Natural Resources, University of Freiburg, Freiburg, Germany; Stadler, K., Industrial Ecology Programme, Norwegian University of Science & Technology, Trondheim, Norway; Lifset, R., School of Forestry and Environmental Studies, Yale University, New Haven, CT, United States","With the growth of the field of industrial ecology (IE), research and results have increased significantly leading to a desire for better utilization of the accumulated data in more sophisticated analyses. This implies the need for greater transparency, accessibility, and reusability of IE data, paralleling the considerable momentum throughout the sciences. The Data Transparency Task Force (DTTF) was convened by the governing council of the International Society for Industrial Ecology in late 2016 to propose best-practice guidelines and incentives for sharing data. In this article, the members of the DTTF present an overview of developments toward transparent and accessible data within the IE community and more broadly. We argue that increased transparency, accessibility, and reusability of IE data will enhance IE research by enabling more detailed and reproducible research, and also facilitate meta-analyses. These benefits will make the results of IE work more timely. They will enable independent verification of results, thus increasing their credibility and quality. They will also make the uptake of IE research results easier within IE and in other fields as well as by decision makers and sustainability practitioners, thus increasing the overall relevance and impact of the field. Here, we present two initial actions intended to advance these goals: (1) a minimum publication requirement for IE research to be adopted by the Journal of Industrial Ecology; and (2) a system of optional data openness badges rewarding journal articles that contain transparent and accessible data. These actions will help the IE community to move toward data transparency and accessibility. We close with a discussion of potential future initiatives that could build on the minimum requirements and the data openness badge system. © 2018 The Authors. Journal of Industrial Ecology, published by Wiley Periodicals, Inc., on behalf of Yale University.","academic publishing; data accessibility; data transparency; industrial ecology; open science; publication requirements","Decision making; Ecology; Reusability; Transparency; Transportation; Academic publishing; Data accessibility; Industrial ecology; Open science; Publication requirements; Industrial research; academic research; accessibility; data assimilation; environmental economics; guideline; industrial ecology; meta-analysis; publishing",Article,"Final",Open Access,Scopus,2-s2.0-85041078828
"Benureau F.C.Y., Rougier N.P.","55975701200;12344787800;","Re-run, repeat, reproduce, reuse, replicate: Transforming code into scientific contributions",2018,"Frontiers in Neuroinformatics","11",, 69,"","",,4,"10.3389/fninf.2017.00069","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043753368&doi=10.3389%2ffninf.2017.00069&partnerID=40&md5=41ce1f4ad32f55ee5921ff46025229c7","INRIA Bordeaux Sud-Ouest, Talence, France; Institut des Maladies Neurodégénératives, Université de Bordeaux, Centre National de la Recherche Scientifique UMR 5293, Bordeaux, France; LaBRI, Université de Bordeaux, Bordeaux INP, Centre National de la Recherche Scientifique UMR 5800, Talence, France","Benureau, F.C.Y., INRIA Bordeaux Sud-Ouest, Talence, France, Institut des Maladies Neurodégénératives, Université de Bordeaux, Centre National de la Recherche Scientifique UMR 5293, Bordeaux, France, LaBRI, Université de Bordeaux, Bordeaux INP, Centre National de la Recherche Scientifique UMR 5800, Talence, France; Rougier, N.P., INRIA Bordeaux Sud-Ouest, Talence, France, Institut des Maladies Neurodégénératives, Université de Bordeaux, Centre National de la Recherche Scientifique UMR 5293, Bordeaux, France, LaBRI, Université de Bordeaux, Bordeaux INP, Centre National de la Recherche Scientifique UMR 5800, Talence, France","Scientific code is different from production software. Scientific code, by producing results that are then analyzed and interpreted, participates in the elaboration of scientific conclusions. This imposes specific constraints on the code that are often overlooked in practice. We articulate, with a small example, five characteristics that a scientific code in computational science should possess: re-runnable, repeatable, reproducible, reusable, and replicable. The code should be executable (re-runnable) and produce the same result more than once (repeatable); it should allow an investigator to reobtain the published results (reproducible) while being easy to use, understand and modify (reusable), and it should act as an available reference for any ambiguity in the algorithmic descriptions of the article (replicable). © 2018 Benureau and Rougier.","Best practices; Computational science; Replicability; Reproducibility of results; Reproducible research; Reproducible science; Software development","article; reproducibility; software",Article,"Final",Open Access,Scopus,2-s2.0-85043753368
"Drummond C.","7102876506;","Reproducible research: a minority opinion",2018,"Journal of Experimental and Theoretical Artificial Intelligence","30","1",,"1","11",,3,"10.1080/0952813X.2017.1413140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038128735&doi=10.1080%2f0952813X.2017.1413140&partnerID=40&md5=d866922999a02862c1184e29541da6ff","Information and Communications Technology, National Research Council Canada, Ottawa, Canada","Drummond, C., Information and Communications Technology, National Research Council Canada, Ottawa, Canada","Reproducible research, a growing movement within many scientific fields, including machine learning, would require the code, used to generate the experimental results, be published along with any paper. Probably the most compelling argument for this is that it is simply following good scientific practice, established over the years by the greats of science. The implication is that failure to follow such a practice is unscientific, not a label any machine learning researchers would like to carry. It is further claimed that misconduct is causing a growing crisis of confidence in science. That, without this practice being enforced, science would inevitably fall into disrepute. This viewpoint is becoming ubiquitous but here I offer a differing opinion. I argue that far from being central to science, what is being promulgated is a narrow interpretation of how science works. I contend that the consequences are somewhat overstated. I would also contend that the effort necessary to meet the movement’s aims, and the general attitude it engenders would not serve well any of the research disciplines, including our own. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","machine learning; reproducible research; scientific communication; scientific evaluation","Artificial intelligence; Good scientific practices; Reproducible research; Scientific communication; Scientific evaluations; Scientific fields; Learning systems",Article,"Final",Open Access,Scopus,2-s2.0-85038128735
"Marwick B., Boettiger C., Mullen L.","8572128400;15753693500;57201721990;","Packaging Data Analytical Work Reproducibly Using R (and Friends)",2018,"American Statistician","72","1",,"80","88",,10,"10.1080/00031305.2017.1375986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045886341&doi=10.1080%2f00031305.2017.1375986&partnerID=40&md5=a561a8552c3514a89adc03790c6d76f5","University of Washington, Seattle, WA, United States; University of Wollongong, Wollongong, NSW, Australia; University of California, Berkeley, CA, United States; George Mason University, Fairfax, VA, United States","Marwick, B., University of Washington, Seattle, WA, United States; Boettiger, C., University of Wollongong, Wollongong, NSW, Australia; Mullen, L., University of California, Berkeley, CA, United States, George Mason University, Fairfax, VA, United States","Computers are a central tool in the research process, enabling complex and large-scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognizable way for organizing the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools. © 2018 American Statistical Association.","Computational science; Data science; Open source software; Reproducible research",,Article,"Final",,Scopus,2-s2.0-85045886341
"Nüst D., Granell C., Hofer B., Konkol M., Ostermann F.O., Sileryte R., Cerutti V.","49361950400;8833951100;55651617800;57193205857;34572355000;57190759179;56500619700;","Reproducible research and GIScience: An evaluation using AGILE conference papers",2018,"PeerJ","2018","7", e5072,"","",,10,"10.7717/peerj.5072","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049995495&doi=10.7717%2fpeerj.5072&partnerID=40&md5=57255b0a57d9b4a4a4d8f23c40477717","Institute for Geoinformatics, University of Münster, Münster, Germany; Institute of New Imaging Technologies, Universitat Jaume I de Castellón, Castellón, Spain; Interfaculty Department of Geoinformatics - Z-GIS, University of Salzburg, Salzburg, Austria; Faculty of Geo-Information Science and Earth Observation (ITC), University of Twente, Enschede, Netherlands; Faculty of Architecture and the Built Environment, Delft University of Technology, Delft, Netherlands","Nüst, D., Institute for Geoinformatics, University of Münster, Münster, Germany; Granell, C., Institute of New Imaging Technologies, Universitat Jaume I de Castellón, Castellón, Spain; Hofer, B., Interfaculty Department of Geoinformatics - Z-GIS, University of Salzburg, Salzburg, Austria; Konkol, M., Institute for Geoinformatics, University of Münster, Münster, Germany; Ostermann, F.O., Faculty of Geo-Information Science and Earth Observation (ITC), University of Twente, Enschede, Netherlands; Sileryte, R., Faculty of Architecture and the Built Environment, Delft University of Technology, Delft, Netherlands; Cerutti, V., Faculty of Geo-Information Science and Earth Observation (ITC), University of Twente, Enschede, Netherlands","The demand for reproducible research is on the rise in disciplines concerned with data analysis and computational methods. Therefore, we reviewed current recommendations for reproducible research and translated them into criteria for assessing the reproducibility of articles in the field of geographic information science (GIScience). Using this criteria, we assessed a sample of GIScience studies from the Association of Geographic Information Laboratories in Europe (AGILE) conference series, and we collected feedback about the assessment from the study authors. Results from the author feedback indicate that although authors support the concept of performing reproducible research, the incentives for doing this in practice are too small. Therefore, we propose concrete actions for individual researchers and the GIScience conference series to improve transparency and reproducibility. For example, to support researchers in producing reproducible work, the GIScience conference series could offer awards and paper badges, provide author guidelines for computational research, and publish articles in Open Access formats. © 2018 Nüst et al.","AGILE; Data science; GIScience; Open access; Open science; Reproducible conference publications; Reproducible research","algorithm; Article; author; biology; computer language; conference paper; exploratory research; feedback system; geographic information system; human; information science; medical geography; metadata; practice guideline; publication; reproducibility; research; short survey; software; spatial analysis; translating (language)",Article,"Final",Open Access,Scopus,2-s2.0-85049995495
"Fonseca Cacho J.R., Taghva K.","57201700721;6603957391;","Reproducible Research in Document Analysis and Recognition",2018,"Advances in Intelligent Systems and Computing","738",,,"389","395",,2,"10.1007/978-3-319-77028-4_51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045851201&doi=10.1007%2f978-3-319-77028-4_51&partnerID=40&md5=f4168ca524b19ae23518f5f97790fe3b","Department of Computer Science, University of Nevada, Las Vegas, NV, United States","Fonseca Cacho, J.R., Department of Computer Science, University of Nevada, Las Vegas, NV, United States; Taghva, K., Department of Computer Science, University of Nevada, Las Vegas, NV, United States","With reproducible research becoming a de facto standard in computational sciences, many approaches have been explored to enable researchers in other disciplines to adopt this standard. In this paper, we explore the importance of reproducible research in the field of document analysis and recognition and in the Computer Science field as a whole. First, we report on the difficulties that one can face in trying to reproduce research in the current publication standards. These difficulties for a large percentage of research may include missing raw or original data, a lack of tidied up version of the data, no source code available, or lacking the software to run the experiment. Furthermore, even when we have all these tools available, we found it was not a trivial task to replicate the research due to lack of documentation and deprecated dependencies. In this paper, we offer a solution to these reproducible research issues by utilizing container technologies such as Docker. As an example, we revisit the installation and execution of OCRSpell which we reported on and implemented in 1994. While the code for OCRSpell is freely available on github, we continuously get emails from individuals who have difficulties compiling and using it in modern hardware platforms. We walk through the development of an OCRSpell Docker container for creating an image, uploading such an image, and enabling others to easily run this program by simply downloading the image and running the container. © 2018, Springer International Publishing AG, part of Springer Nature.","Containers; Docker; Document analysis and recognition; OCRSpell; Reproducible research","Computer programming; Computer science; Computational science; De facto standard; Docker; Docker containers; Document analysis; Hardware platform; OCRSpell; Reproducible research; Containers",Conference Paper,"Final",,Scopus,2-s2.0-85045851201
"Berez-Kroeker A.L., Gawne L., Kung S.S., Kelly B.F., Heston T., Holton G., Pulsifer P., Beaver D.I., Chelliah S., Dubinsky S., Meier R.P., Thieberger N., Rice K., Woodbury A.C.","57189192770;55585420800;57200981473;55170855400;56461203100;26121225300;6603428910;8439941900;14831115900;6602248288;7201424839;15842713700;15766064800;16470628700;","Reproducible research in linguistics: A position statement on data citation and attribution in our field",2018,"Linguistics","56","1",,"1","18",,9,"10.1515/ling-2017-0032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041001326&doi=10.1515%2fling-2017-0032&partnerID=40&md5=4277d60e058e6b83f4c74bd06352e94d","Department of Linguistics, University of Hawaii, 1890 East West Road, Honolulu, HI  96822, United States; Department of Languages and Linguistics, SOAS University of London,London WC1H 0XG, UK; La Trobe University, Melbourne,, VIC 3086,, Australia; Trobe University, Melbourne, VIC  3086, Australia; Indigenous Languages of Latin America, University of Texas, Austin, TX  78712, United States; Department of Languages and Linguistics, University of Melbourne, Parkville, VIC  3010, Australia; Payap University, Chiang Mai, 50000, Thailand; Department of Linguistics, University of Hawaii at Manoa, 1890 East West Road, Honolulu, HI  96822, United States; National Snow and Ice Data Center, Boulder, CO  80303, United States; Department of Linguistics, University of North Texas, Denton, TX  76203, United States; University of South Carolina, Columbia, SC  29208, United States; Department of Linguistics, University of Toronto, Toronto, ON  M5S, Canada","Berez-Kroeker, A.L., Department of Linguistics, University of Hawaii, 1890 East West Road, Honolulu, HI  96822, United States; Gawne, L., Department of Languages and Linguistics, SOAS University of London,London WC1H 0XG, UK; La Trobe University, Melbourne,, VIC 3086,, Australia; Kung, S.S., Trobe University, Melbourne, VIC  3086, Australia; Kelly, B.F., Indigenous Languages of Latin America, University of Texas, Austin, TX  78712, United States; Heston, T., Department of Languages and Linguistics, University of Melbourne, Parkville, VIC  3010, Australia; Holton, G., Payap University, Chiang Mai, 50000, Thailand; Pulsifer, P., Department of Linguistics, University of Hawaii at Manoa, 1890 East West Road, Honolulu, HI  96822, United States; Beaver, D.I., National Snow and Ice Data Center, Boulder, CO  80303, United States; Chelliah, S., Department of Linguistics, University of North Texas, Denton, TX  76203, United States; Dubinsky, S., University of South Carolina, Columbia, SC  29208, United States; Meier, R.P., Department of Linguistics, University of Hawaii, 1890 East West Road, Honolulu, HI  96822, United States; Thieberger, N., University of South Carolina, Columbia, SC  29208, United States; Rice, K., Department of Linguistics, University of Hawaii, 1890 East West Road, Honolulu, HI  96822, United States; Woodbury, A.C., Department of Linguistics, University of Toronto, Toronto, ON  M5S, Canada","This paper is a position statement on reproducible research in linguistics, including data citation and attribution, that represents the collective views of some 41 colleagues. Reproducibility can play a key role in increasing verification and accountability in linguistic research, and is a hallmark of social science research that is currently under-represented in our field. We believe that we need to take time as a discipline to clearly articulate our expectations for how linguistic data are managed, cited, and maintained for long-Term access. © 2018 Berez-Kroeker et al., published by De Gruyter 2018.","attribution; data citation; reproducibility",,Article,"Final",Open Access,Scopus,2-s2.0-85041001326
"Hoppe A., Hagen J., Holzmann H., Kniesel G., Ewerth R.","57198201823;57203967212;55668294200;6602434399;6506127251;","An analytics tool for exploring scientific software and related publications",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11057 LNCS",,,"299","303",,1,"10.1007/978-3-030-00066-0_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053832899&doi=10.1007%2f978-3-030-00066-0_27&partnerID=40&md5=1cc4233848e43a7e6359c743091b52dc","Leibniz Information Centre for Science and Technology (TIB), Hannover, Germany; Leibniz Universität Hannover, Hannover, Germany; L3S Research Center, Leibniz Universität Hannover, Hannover, Germany; University of Bonn, Bonn, Germany","Hoppe, A., Leibniz Information Centre for Science and Technology (TIB), Hannover, Germany; Hagen, J., Leibniz Universität Hannover, Hannover, Germany; Holzmann, H., L3S Research Center, Leibniz Universität Hannover, Hannover, Germany; Kniesel, G., University of Bonn, Bonn, Germany; Ewerth, R., Leibniz Information Centre for Science and Technology (TIB), Hannover, Germany, L3S Research Center, Leibniz Universität Hannover, Hannover, Germany","Scientific software is one of the key elements for reproducible research. However, classic publications and related scientific software are typically not (sufficiently) linked, and tools are missing to jointly explore these artefacts. In this paper, we report on our work on developing the analytics tool SciSoftX (https://labs.tib.eu/info/projekt/scisoftx/ ) for jointly exploring software and publications. The presented prototype, a concept for automatic code discovery, and two use cases demonstrate the feasibility and usefulness of the proposal. © 2018, Springer Nature Switzerland AG.","Cross-modal relations; Software reproducibility; Source code exploration","Artificial intelligence; Computer science; Computers; Analytics tools; Automatic codes; Cross-modal; Key elements; Reproducibilities; Reproducible research; Scientific softwares; Source codes; Digital libraries",Conference Paper,"Final",,Scopus,2-s2.0-85053832899
"Lamer A., Ficheur G., Rousselet L., Van Berleere M., Chazard E., Caron A.","55883634500;35169140800;57201948931;57201944957;23388323200;56727806300;","From data extraction to analysis: Proposal of a methodology to optimize hospital data reuse process",2018,"Studies in Health Technology and Informatics","247",,,"41","45",,1,"10.3233/978-1-61499-852-5-41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046554342&doi=10.3233%2f978-1-61499-852-5-41&partnerID=40&md5=29e657eea337dc731db3c96a8c59d434","EA 2694, Univ. Lille, Department of Public Health, CHU Lille, Lille, F-59000, France; Anesthesia Department, CHU Lille, Lille, F-59000, France","Lamer, A., EA 2694, Univ. Lille, Department of Public Health, CHU Lille, Lille, F-59000, France, Anesthesia Department, CHU Lille, Lille, F-59000, France; Ficheur, G., EA 2694, Univ. Lille, Department of Public Health, CHU Lille, Lille, F-59000, France; Rousselet, L., EA 2694, Univ. Lille, Department of Public Health, CHU Lille, Lille, F-59000, France; Van Berleere, M., EA 2694, Univ. Lille, Department of Public Health, CHU Lille, Lille, F-59000, France; Chazard, E., EA 2694, Univ. Lille, Department of Public Health, CHU Lille, Lille, F-59000, France; Caron, A., EA 2694, Univ. Lille, Department of Public Health, CHU Lille, Lille, F-59000, France","In the Lille University Hospital (North of France), data from the Anesthesia Information Management System (Diane®) are linked to the Hospital Information System and stored in a dedicated data warehouse since 2010. These electronic medical records need to be reused and analyzed for observational studies. The aim of this paper is to describe the framework developed to structure the operation of that anesthesia data warehouse for research purposes. The presented framework is structured around three meetings between clinicians, computer scientists, and statisticians. The data scientist acts as a coordinator, leads meetings, and checks each milestone. Reuse of anesthesia-related electronic medical record for research purposes is only allowed through this framework. The aim of the first meeting is to decide the primary and secondary objectives of the study. The aim of the second meeting is to validate the statistical protocol. The data are extracted and the statistical analyses are performed. Finally, the results are presented, explained and discussed during the third meeting. During a 6 months period, 27 projects were included in the framework leading to 5 scientific communications. As a result, case studies with extraction and/or analysis situations are presented. This collaboration led to an empowerment process between all three actors, which increased efficiency of the workflow. Implementation of this framework will keep encouraging collaborative publication in order to provide reproducible research evidence. © 2018 European Federation for Medical Informatics (EFMI) and IOS Press.","Data science; Electronic medical records; Healthcare data reuse; Reproducible research; Statistical analysis","anesthesia; conference paper; data extraction; data warehouse; electronic medical record; empowerment; human; observational study; publication; scientist; statistical analysis; workflow; database management system; electronic health record; France; hospital; hospital information system; Database Management Systems; Electronic Health Records; France; Hospital Information Systems; Hospitals",Conference Paper,"Final",,Scopus,2-s2.0-85046554342
"Klein O., Hardwicke T.E., Aust F., Breuer J., Danielsson H., Mohr A.H., Jzerman H.I., Nilsonne G., Vanpaemel W., Frank M.C.","7006311271;55937009200;54580538100;57202912677;13005836600;57202911341;55659899600;14120128400;6505477789;16432698900;","A practical guide for transparency in psychological science",2018,"Collabra: Psychology","4","1", 20,"","",,20,"10.1525/collabra.158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049799176&doi=10.1525%2fcollabra.158&partnerID=40&md5=e9287b22d8bf2c580e1dcced46933974","Université Libre de Bruxelles, Belgium; Stanford University, United States; University of CologneDE, Germany; GESIS, Leibniz Institute for the Social SciencesDE, Germany; Linköping University, SE, Sweden; Swedish Institute for Disability Research, SE, Sweden; University of Minnesota, United States; Université Grenoble Alpes, France; Karolinska Institutet, Stockholm University, SE, Sweden; University of Leuven, Belgium","Klein, O., Université Libre de Bruxelles, Belgium; Hardwicke, T.E., Stanford University, United States; Aust, F., University of CologneDE, Germany; Breuer, J., GESIS, Leibniz Institute for the Social SciencesDE, Germany; Danielsson, H., Linköping University, SE, Sweden, Swedish Institute for Disability Research, SE, Sweden; Mohr, A.H., University of Minnesota, United States; Jzerman, H.I., Université Grenoble Alpes, France; Nilsonne, G., Stanford University, United States, Karolinska Institutet, Stockholm University, SE, Sweden; Vanpaemel, W., University of Leuven, Belgium; Frank, M.C., Stanford University, United States","The credibility of scientific claims depends upon the transparency of the research products upon which they are based (e.g., study protocols, data, materials, and analysis scripts). As psychology navigates a period of unprecedented introspection, user-friendly tools and services that support open science have flourished. However, the plethora of decisions and choices involved can be bewildering. Here we provide a practical guide to help researchers navigate the process of preparing and sharing the products of their research (e.g., choosing a repository, preparing their research products for sharing, structuring folders, etc.). Being an open scientist means adopting a few straightforward research management practices, which lead to less error prone, reproducible research workflows. Further, this adoption can be piecemeal – each incremental step towards complete transparency adds positive value. Transparent research practices not only improve the efficiency of individual researchers, they enhance the credibility of the knowledge generated by the scientific community. © 2018 The Author(s).","Open science; Transparency; Tutorial",,Article,"Final",Open Access,Scopus,2-s2.0-85049799176
"Schönbrodt F.D., Maier M., Heene M., Bühner M.","33568239700;7201526426;35147940400;6701577640;","Fostering research transparency as a key property of science: Concrete actions for psychological departments [Forschungstransparenz als hohes wissenschaftliches gut stärken: Konkrete ansatzmöglichkeiten für psychologische institute]",2018,"Psychologische Rundschau","69","1",,"37","44",,4,"10.1026/0033-3042/a000386","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040195611&doi=10.1026%2f0033-3042%2fa000386&partnerID=40&md5=84e8cbbcd8e9641d87699dc6a222cc9d","Ludwig-Maximilians-Universität, Department Psychologie, Leopoldstr. 13, München, 80802, Germany","Schönbrodt, F.D., Ludwig-Maximilians-Universität, Department Psychologie, Leopoldstr. 13, München, 80802, Germany; Maier, M., Ludwig-Maximilians-Universität, Department Psychologie, Leopoldstr. 13, München, 80802, Germany; Heene, M., Ludwig-Maximilians-Universität, Department Psychologie, Leopoldstr. 13, München, 80802, Germany; Bühner, M., Ludwig-Maximilians-Universität, Department Psychologie, Leopoldstr. 13, München, 80802, Germany","Recent large-scale replication projects suggest an amount of nonreplicable results in the scientific literature, in psychology but also in other sciences, which is concerning from our point of view. We analyze some causes for this situation, and argue that the change toward more research transparency (""open science"") must be one consequence that should be drawn from the credibility crisis. We call for feasible changes in the local research units and departments and show as an example the steps that have been taken at the Department of Psychology of the Ludwig-Maximilians-Universität München. These changes concern incentive structures, research culture, teaching, and a close integration with the local ethics committee. The goal is to foster a more credible and more reproducible research output without generating unnecessary bureaucratic overhead. © 2018 Hogrefe Verlag.","Credibility crisis; Incentives; Replication crisis; Research quality",,Article,"Final",,Scopus,2-s2.0-85040195611
"Finak G., Mayer B., Fulp W., Obrecht P., Sato A., Chung E., Holman D., Gottardo R.","15072838600;37005811500;19638524200;57211290489;57211294698;57209203733;7006170281;12799324000;","Datapackager: Reproducible data preprocessing, standardization and sharing using r/bioconductor for collaborative data analysis",2018,"Gates Open Research","2",, 31,"","",,3,"10.12688/gatesopenres.12832.2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058512172&doi=10.12688%2fgatesopenres.12832.2&partnerID=40&md5=cb14569bb1852f7fa1a2dc4e42440cea","Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States; Vaccine Immunology Statistical Center, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States; Statistical Center For HIV AIDS Research and Prevention, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States","Finak, G., Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Vaccine Immunology Statistical Center, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Statistical Center For HIV AIDS Research and Prevention, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States; Mayer, B., Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Vaccine Immunology Statistical Center, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Statistical Center For HIV AIDS Research and Prevention, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States; Fulp, W., Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Vaccine Immunology Statistical Center, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Statistical Center For HIV AIDS Research and Prevention, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States; Obrecht, P., Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Vaccine Immunology Statistical Center, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Statistical Center For HIV AIDS Research and Prevention, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States; Sato, A., Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Vaccine Immunology Statistical Center, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Statistical Center For HIV AIDS Research and Prevention, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States; Chung, E., Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Vaccine Immunology Statistical Center, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Statistical Center For HIV AIDS Research and Prevention, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States; Holman, D., Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Vaccine Immunology Statistical Center, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Statistical Center For HIV AIDS Research and Prevention, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States; Gottardo, R., Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Vaccine Immunology Statistical Center, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States, Statistical Center For HIV AIDS Research and Prevention, Fred Hutchinson Cancer Research Center, Seattle, WA  98109, United States","A central tenet of reproducible research is that scientific results are published along with the underlying data and software code necessary to reproduce and verify the findings. A host of tools and software have been released that facilitate such work-flows and scientific journals have increasingly demanded that code and primary data be made available with publications. There has been little practical advice on implementing reproducible research work-flows for large ’omics’ or systems biology data sets used by teams of analysts working in collaboration. In such instances it is important to ensure all analysts use the same version of a data set for their analyses. Yet, instantiating relational databases and standard operating procedures can be unwieldy, with high ""startup"" costs and poor adherence to procedures when they deviate substantially from an analyst’s usual work-flow. Ideally a reproducible research work-flow should fit naturally into an individual’s existing work-flow, with minimal disruption. Here, we provide an overview of how we have leveraged popular open source tools, including Bioconductor, Rmarkdown, git version control, R, and specifically R’s package system combined with a new tool DataPackageR, to implement a lightweight reproducible research work-flow for preprocessing large data sets, suitable for sharing among small-to-medium sized teams of computational scientists. Our primary contribution is the DataPackageR tool, which decouples time-consuming data processing from data analysis while leaving a traceable record of how raw data is processed into analysis-ready data sets. The software ensures packaged data objects are properly documented and performs checksum verification of these along with basic package version management, and importantly, leaves a record of data processing code in the form of package vignettes. Our group has implemented this work-flow to manage, analyze and report on pre-clinical immunological trial data from multi-center, multi-assay studies for the past three years. © 2018 Finak G et al.","Assay data; Bioconductor; Collaboration; Data science; Package; Reproducibility; Rmarkdown; Rstats; Version control",,Article,"Final",Open Access,Scopus,2-s2.0-85058512172
"Pulliza J., Shah C.","57200315347;55684215000;","Improving corpus reproducibility through modular text transformations and connected data set",2018,"Proceedings of the Association for Information Science and Technology","55","1",,"883","884",,,"10.1002/pra2.2018.14505501159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064490570&doi=10.1002%2fpra2.2018.14505501159&partnerID=40&md5=7e76aabe33d50d2be9e30a0dbb396962","Rutgers University, United States","Pulliza, J., Rutgers University, United States; Shah, C., Rutgers University, United States","The Enron Email Corpus is one of the most utilized collections of documents in Natural Language Processing, Machine Learning, and Network Analysis. Different groups of researchers have transformed the corpus, changing the content and format to meet their needs. The many distinct versions can all claim to be the Enron Email Corpus, though they are as distinct from the original publicly available collection as they are from each other. Researchers then have to determine the usefulness of a particular version in comparison to the many others available, as well as ascertain what has been done to the collection and how it would affect their specific research goal. This is especially important for reproducing a particular research method onto a different corpus, as transposing a method necessitates a deep understanding of the original data in the experiment. This project models the various transformations performed on different versions of the collection to form a network of connected datasets, highlighting the most important nodes as well as the most common transformations. Traversing different paths between nodes offers the community a way to model and reproduce the necessary data work performed on one collection that can be transposed onto other collections. Copyright © 2018 by Association for Information Science and Technology","Data Citation; Data Reuse; Email; Enron e-mail dataset; Network Analysis; Reproducible Research",,Article,"Final",,Scopus,2-s2.0-85064490570
"Rowhani-Farid A., Barnett A.G.","57191581190;7203071164;","Badges for sharing data and code at Biostatistics: An observational study",2018,"F1000Research","7",, 90,"","",,,"10.12688/f1000research.13477.2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043677533&doi=10.12688%2ff1000research.13477.2&partnerID=40&md5=33c230402f44a075aa4dafaa81d5bde8","Institute of Health and Biomedical Innovation, Queensland University of Technology, Brisbane, QLD  4001, Australia","Rowhani-Farid, A., Institute of Health and Biomedical Innovation, Queensland University of Technology, Brisbane, QLD  4001, Australia; Barnett, A.G., Institute of Health and Biomedical Innovation, Queensland University of Technology, Brisbane, QLD  4001, Australia","Background: The reproducibility policy at the journal Biostatistics rewards articles with badges for data and code sharing. This study investigates the effect of badges at increasing reproducible research. Methods: The setting of this observational study is the Biostatistics and Statistics in Medicine (control journal) online research archives. The data consisted of 240 randomly sampled articles from 2006 to 2013 (30 articles per year) per journal. Data analyses included: plotting probability of data and code sharing by article submission date, and Bayesian logistic regression modelling. Results: The probability of data sharing was higher at Biostatistics than the control journal but the probability of code sharing was comparable for both journals. The probability of data sharing increased by 3.9 times (95% credible interval: 1.5 to 8.44 times, p-value probability that sharing increased: 0.998) after badges were introduced at Biostatistics. On an absolute scale, this difference was only a 7.6% increase in data sharing (95% CI: 2 to 15%, p-value: 0.998). Badges did not have an impact on code sharing at the journal (mean increase: 1 time, 95% credible interval: 0.03 to 3.58 times, p-value probability that sharing increased: 0.378). 64% of articles at Biostatistics that provide data/code had broken links, and at Statistics in Medicine, 40%; assuming these links worked only slightly changed the effect of badges on data (mean increase: 6.7%, 95% CI: 0.0% to 17.0%, p-value: 0.974) and on code (mean increase: -2%, 95% CI: -10.0 to 7.0%, p-value: 0.286). Conclusions: The effect of badges at Biostatistics was a 7.6% increase in the data sharing rate, 5 times less than the effect of badges at Psychological Science. Though badges at Biostatistics did not impact code sharing, and had a moderate effect on data sharing, badges are an interesting step that journals are taking to incentivise and promote reproducible research. © 2018 Rowhani-Farid A and Barnett AG.","Code sharing; Data sharing; Incentives; Meta-research; Reproducibility; Rewards","article; biostatistics; data analysis; human; information center; medicine; observational study; probability; reproducibility; reward; statistical significance",Article,"Final",Open Access,Scopus,2-s2.0-85043677533
"Fu W., Wang N., Pang F., Huang Y., Wu J., Qi S., Dai Z., Du D.","57118771800;57198399630;57201274418;57201276041;57201281903;55711393500;54408408000;38961185000;","Soil microbiota and plant invasions: Current and future",2017,"Biodiversity Science","25","12",,"1295","1302",,1,"10.17520/biods.2017071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044107838&doi=10.17520%2fbiods.2017071&partnerID=40&md5=e73ce8510e73047aec3e7d44d39cccc7","Institute of Environment and Ecology, School of the Environment and Safety Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China; Institute of Agricultural Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China","Fu, W., Institute of Environment and Ecology, School of the Environment and Safety Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China; Wang, N., Institute of Environment and Ecology, School of the Environment and Safety Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China; Pang, F., Institute of Environment and Ecology, School of the Environment and Safety Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China; Huang, Y., Institute of Environment and Ecology, School of the Environment and Safety Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China; Wu, J., Institute of Environment and Ecology, School of the Environment and Safety Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China; Qi, S., Institute of Environment and Ecology, School of the Environment and Safety Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China; Dai, Z., Institute of Environment and Ecology, School of the Environment and Safety Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China, Institute of Agricultural Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China; Du, D., Institute of Environment and Ecology, School of the Environment and Safety Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China, Institute of Agricultural Engineering, Jiangsu University, Zhenjiang, Jiangsu  212013, China","Profound threats on global biodiversity caused by the expansion and accumulation of invasive species substantiate the urgent need to understand their invasion mechanisms. While most studies of invasive plants have focused on macro-organisms, it has become increasingly clear that microorganisms are pervasive and play central roles in successful invasion processes of exotic plants. According to studies examining soil microbes and invasive plants, we discuss the effects of invasive plants on soil microbial communities by dividing them into three separate groups, namely microbial pathogens, mutualistic microbes, and saprotrophic microbes. Roots are the primary site for interactions with microbes, and the rhizosphere is the largest reservoir of known microbial diversity. The rhizosphere provided a heterogeneity microhabitat at the root-soil interface (rhizosphere soil, rhizoplane, and endorhizosphere) and shapes the habitat into different functions. However, previous studies have tended to focus on either the single dimension or at the hole level, which fails to explain the scope and depth of the phenomenon. When examining this issue, we propose that future studies of the interactions between rhizosphere microbes and invasive plant should combine the root elaborate microhabitat and macro-functional traits. It is essential to construct a systematic and reproducible research framework by using high-throughput DNA sequencing technology and corresponding bioinformatic tools, to switch the mode of research from the description and prediction of the phenomenon into the elaboration of the mechanism in the field of plant invasion. © 2017, Chinese Academy of Sciences. All rights reserved.","Invasion mechanisms; Invasive plant; Microbial molecular ecology; Rhizosphere microhabitat; Soil microbes",,Article,"Final",Open Access,Scopus,2-s2.0-85044107838
"Jansen C., Beier M., Witt M., Frey S., Krefting D.","56286202100;56285341700;36722574100;57205022529;23004694400;","Towards reproducible research in a biomedical collaboration platform following the FAIR guiding principles",2017,"UCC 2017 Companion - Companion Proceedings of the 10th International Conference on Utility and Cloud Computing",,,,"3","8",,2,"10.1145/3147234.3148104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058338731&doi=10.1145%2f3147234.3148104&partnerID=40&md5=3076f41d2ece1b3fcd04b0fa36eb8715","Charité Berlin, CBMI – HTW Berlin, Germany; Karlsruhe Institute of Technology, CBMI – HTW Berlin, Germany; CBMI – HTW Berlin, Germany","Jansen, C., Charité Berlin, CBMI – HTW Berlin, Germany; Beier, M., Charité Berlin, CBMI – HTW Berlin, Germany; Witt, M., Karlsruhe Institute of Technology, CBMI – HTW Berlin, Germany; Frey, S., CBMI – HTW Berlin, Germany; Krefting, D., CBMI – HTW Berlin, Germany","Replication of computational experiments is essential for verifiable research. However, it requires a comprehensive and unambiguous description of all employed digital artifacts, in particular data, code and the computational environment. Recently, the FAIR Guiding Principles have been published to support reproducible research. In this paper, a cloud-based biomedical collaboration platform has been evaluated regarding FAIR principles and has been extended to support reproducibility. The FAICE suite is presented, encompassing tools to thoroughly describe and reproduce a computational experiment within the original execution environment as well as within a dynamically configured VM. © 2017 Copyright held by the owner/author(s).","Cloud Computing; Docker; Medical Data; Repeatability; Reproducibility; XNAT","Computer programming; Computer science; Docker; Medical data; Repeatability; Reproducibilities; XNAT; Cloud computing",Conference Paper,"Final",,Scopus,2-s2.0-85058338731
"Burgard J.P., Kolb J.-P., Merkle H., Münnich R.","36636933300;56988694500;57199235855;6507556624;","Synthetic data for open and reproducible methodological research in social sciences and official statistics",2017,"AStA Wirtschafts- und Sozialstatistisches Archiv","11","3-4",,"233","244",,5,"10.1007/s11943-017-0214-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037682147&doi=10.1007%2fs11943-017-0214-8&partnerID=40&md5=9880a049f799156be479eb557ebec2f8","FB IV, VWL, Wirtschafts- und Sozialstatistik, Universität Trier, Universitätsring 15, Trier, 54296, Germany; Leibniz-Institut für Sozialwissenschaften in Mannheim, GESIS, B2 1, Mannheim, 68159, Germany","Burgard, J.P., FB IV, VWL, Wirtschafts- und Sozialstatistik, Universität Trier, Universitätsring 15, Trier, 54296, Germany; Kolb, J.-P., Leibniz-Institut für Sozialwissenschaften in Mannheim, GESIS, B2 1, Mannheim, 68159, Germany; Merkle, H., FB IV, VWL, Wirtschafts- und Sozialstatistik, Universität Trier, Universitätsring 15, Trier, 54296, Germany; Münnich, R., FB IV, VWL, Wirtschafts- und Sozialstatistik, Universität Trier, Universitätsring 15, Trier, 54296, Germany","Open and reproducible research receives more and more attention in the research community. Whereas empirical research may benefit from research data centres or scientific use files that foster using data in a safe environment or with remote access, methodological research suffers from the availability of adequate data sources. In economic and social sciences, an additional drawback results from the presence of complex survey designs in the data generating process, that has to be considered when developing and applying estimators. In the present paper, we present a synthetic but realistic dataset based on social science data, that fosters evaluating and developing estimators in social sciences. The focus is on supporting comparable and reproducible research in a realistic framework providing individual and household data. The outcome is provided as an open research data resource. © 2017, The Author(s).","Household data; Open and reproducible research; Open data; Simulation experiments",,Article,"Final",Open Access,Scopus,2-s2.0-85037682147
"Tsipas N., Vrysis L., Dimoulas C., Papanikolaou G.","55762300600;57090900500;57105254400;6603800228;","Efficient audio-driven multimedia indexing through similarity-based speech / music discrimination",2017,"Multimedia Tools and Applications","76","24",,"25603","25621",,6,"10.1007/s11042-016-4315-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009195246&doi=10.1007%2fs11042-016-4315-0&partnerID=40&md5=638853dad7b597ee715c5cde3c41147c","Aristotle University of Thessaloniki, Thessaloniki, 54124, Greece","Tsipas, N., Aristotle University of Thessaloniki, Thessaloniki, 54124, Greece; Vrysis, L., Aristotle University of Thessaloniki, Thessaloniki, 54124, Greece; Dimoulas, C., Aristotle University of Thessaloniki, Thessaloniki, 54124, Greece; Papanikolaou, G., Aristotle University of Thessaloniki, Thessaloniki, 54124, Greece","In this paper, an audio-driven algorithm for the detection of speech and music events in multimedia content is introduced. The proposed approach is based on the hypothesis that short-time frame-level discrimination performance can be enhanced by identifying transition points between longer, semantically homogeneous segments of audio. In this context, a two-step segmentation approach is employed in order to initially identify transition points between the homogeneous regions and subsequently classify the derived segments using a supervised binary classifier. The transition point detection mechanism is based on the analysis and composition of multiple self-similarity matrices, generated using different audio feature sets. The implemented technique aims at discriminating events focusing on transition point detection with high temporal resolution, a target that is also reflected in the adopted assessment methodology. Thereafter, multimedia indexing can be efficiently deployed (for both audio and video sequences), incorporating the processes of high resolution temporal segmentation and semantic annotation extraction. The system is evaluated against three publicly available datasets and experimental results are presented in comparison with existing implementations. The proposed algorithm is provided as an open source software package in order to support reproducible research and encourage collaboration in the field. © 2017, Springer Science+Business Media New York.","Self-similarity matrix analysis; Speech/music discrimination; Supervised learning; Transition point detection","Audio acoustics; Indexing (of information); Open source software; Open systems; Semantics; Software engineering; Supervised learning; Transition flow; Assessment methodologies; High temporal resolution; Reproducible research; Self-similarity matrix; Semantic annotations; Speech/music discrimination; Temporal segmentations; Transition point; Speech recognition",Article,"Final",,Scopus,2-s2.0-85009195246
"De Roure D., Willcox P.","6701509117;57023577900;","Experimental humanities: An adventure with lovelace and babbage",2017,"Proceedings - 13th IEEE International Conference on eScience, eScience 2017",,, 8109137,"194","201",,2,"10.1109/eScience.2017.32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043757274&doi=10.1109%2feScience.2017.32&partnerID=40&md5=d7155cdbdfcf9b01ccee2543042cd505","Oxford e-Research Centre, University of Oxford, Oxford, United Kingdom; Centre for Digital Scholarship, University of Oxford, Oxford, United Kingdom","De Roure, D., Oxford e-Research Centre, University of Oxford, Oxford, United Kingdom; Willcox, P., Centre for Digital Scholarship, University of Oxford, Oxford, United Kingdom","The development and innovative application of digital research methods in humanities disciplines, characterised as Digital Humanities or e-Humanities, is an established feature of the e-Science and e-Research landscape. Typically these digital methods enable existing research questions to be tackled in new ways, at a scale and speed that transcend manual methods. In this paper we present a different approach to the application of digital techniques to humanities research, a branch of experimental humanities in which digital experiments bring insight and engagement with historical scenarios and in turn influence our understanding and our thinking today. We illustrate this through a series of experiments and demonstrations inspired by the work of Ada Lovelace and Charles Babbage, including simulation of the Analytical Engine, use of a web-based music application, construction of hardware, and reproduction of earlier mathematical results using contemporary computational methods. © 2017 IEEE.","Ada Lovelace; algorithmic composition; Analytical Engine; Charles Babbage; Digital Humanities; Leonard Euler; Reproducible Research","Humanities computing; Ada Lovelace; Algorithmic compositions; Charles Babbage; Digital humanities; Leonard Euler; Reproducible research; Engines",Conference Paper,"Final",,Scopus,2-s2.0-85043757274
"Barba L.A., Thiruvathukal G.K.","8294521800;6601955304;","Reproducible Research for Computing in Science & Engineering",2017,"Computing in Science and Engineering","19","6", 8090467,"85","87",,,"10.1109/MCSE.2017.3971172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038349285&doi=10.1109%2fMCSE.2017.3971172&partnerID=40&md5=6fb6b00b06138e4c4e6dba4ec568b596","George Washington University, United States; Loyola University Chicago, United States","Barba, L.A., George Washington University, United States; Thiruvathukal, G.K., Loyola University Chicago, United States","The editors of the new track for reproducible research outline the parameters for future peer review, submission, and access, highlighting the magazine's previous work in this field and some of the challenges still to come. © 1999-2011 IEEE.","open access; peer review; reproducible research; scientific computing","Computer science; Engineering; Natural sciences computing; Open Access; Peer review; Reproducible research; Engineering research",Article,"Final",,Scopus,2-s2.0-85038349285
"Jomier J.","6507216580;","Open science - towards reproducible Research",2017,"Information Services and Use","37","3",,"361","367",,2,"10.3233/ISU-170846","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032568749&doi=10.3233%2fISU-170846&partnerID=40&md5=e551028edd91b74209c5cb3d27e210c2","Kitware, 26 rue Louis Guérin, Villeurbanne, 69100, France","Jomier, J., Kitware, 26 rue Louis Guérin, Villeurbanne, 69100, France","This paper presents an overview of several efforts towards reproducible research in the field of medical imaging and visualization. In the first section, the components of Open Science are presented: open access, open data and open source. In the second section, the challenges of open-science are described and potential solutions are mentioned. Finally, a discussion on the potential future of open science and reproducible research is introduced.","Open access; Open data; Open science; Open source; Reproducibility","Computer applications; Information use; Open Access; Open datum; Open science; Open sources; Reproducibilities; Medical imaging",Conference Paper,"Final",Open Access,Scopus,2-s2.0-85032568749
"Kitzes J., Turek D., Deniz F.","12801961000;52264707100;57195149328;","The practice of reproducible research: Case studies and lessons from the data-intensive sciences",2017,"The Practice of Reproducible Research: Case Studies and Lessons from the Data-Intensive Sciences",,,,"1","337",,15,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046435187&partnerID=40&md5=4a1789c09f7ebb336889cf10cffcdbea","Department of Biological Sciences, University of Pittsburgh, Pittsburgh, PA, United States; Department of Mathematics and Statistics, Williams College, Williamstown, MA, United States; International Computer Science Institute, University of California, Berkeley, Berkeley, CA, United States; Helen Wills Neuroscience Institute, University of California, Berkeley, Berkeley, CA, United States; Berkeley Institute for Data Science, University of California, Berkeley, Berkeley, CA, United States","Kitzes, J., Department of Biological Sciences, University of Pittsburgh, Pittsburgh, PA, United States; Turek, D., Department of Mathematics and Statistics, Williams College, Williamstown, MA, United States; Deniz, F., International Computer Science Institute, University of California, Berkeley, Berkeley, CA, United States, Helen Wills Neuroscience Institute, University of California, Berkeley, Berkeley, CA, United States, Berkeley Institute for Data Science, University of California, Berkeley, Berkeley, CA, United States","The Practice of Reproducible Research presents concrete examples of how researchers in the data-intensive sciences are working to improve the reproducibility of their research projects. In each of the thirty-one case studies in this volume, the author or team describes the workflow that they used to complete a real-world research project. Authors highlight how they utilized particular tools, ideas, and practices to support reproducibility, emphasizing the very practical how, rather than the why or what, of conducting reproducible research. Part 1 provides an accessible introduction to reproducible research, a basic reproducible research project template, and a synthesis of lessons learned from across the thirty-one case studies. Parts 2 and 3 focus on the case studies themselves. The Practice of Reproducible Research is an invaluable resource for students and researchers who wish to better understand the practice of data-intensive sciences and learn how to make their own research more reproducible. © 2018 by The Regents of the University of California. All rights reserved.",,,Book,"Final",,Scopus,2-s2.0-85046435187
[No author name available],[No author id available],"Information Services and Use",2017,"Information Services and Use","37","3",,"","",114,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032581162&partnerID=40&md5=79529a705b9a4455c64c57ec309f9f09",,"","The proceedings contain 17 papers. The topics discussed include: leveraging information and collaboration to cure disease; the importance of research data management: the value of electronic laboratory notebooks in the management of data integrity and data availability; open science towards reproducible research; the Napster moment: access and innovation in academic publishing; open access policies and science Europe: state of play; embracing digital: key considerations for publishers, marketers and customers; the journey from excellence to innovation; publishing in the doghouse: protecting copyright, enabling access, or both?; are STM publishers doing the right thing?; scholarly triage: advances in manuscript submission using text analytics techniques; reprinted from STM membership matters February 2017 2017 STM; peer review in the 21st century; data-first manifesto: shifting priorities in scholarly communications; preprints as a complement to the journal system in biology; and advancing library cyberinfrastructure for big data sharing and reuse.",,,Conference Review,"Final",,Scopus,2-s2.0-85032581162
"Sveshnikova S., Gankevich I.","57191576013;56035545000;","Using virtualisation for reproducible research and code portability",2017,"Proceedings - 2017 International Conference on High Performance Computing and Simulation, HPCS 2017",,, 8035178,"891","892",,1,"10.1109/HPCS.2017.139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032369835&doi=10.1109%2fHPCS.2017.139&partnerID=40&md5=48e4e6625b75932873b64e53a84e49d4","Dept. of Computer Modeling and Multiprocessor Systems, Saint Petersburg State University, Saint-Petersburg, Russian Federation","Sveshnikova, S., Dept. of Computer Modeling and Multiprocessor Systems, Saint Petersburg State University, Saint-Petersburg, Russian Federation; Gankevich, I., Dept. of Computer Modeling and Multiprocessor Systems, Saint Petersburg State University, Saint-Petersburg, Russian Federation","Research reproducibility is an emerging topic in computer science. One of the problems in research reproducibility is the absence of tools to reproduce specified operating system with specific version of the software installed. In the proposal reported here we investigate how a tool based on lightweight virtualisation technologies reproduces them. The experiments show that creating reproducible environment adds significant overhead only on the first run of the application, and propose a number of ways to improve the tool. © 2017 IEEE.","Compiler tools; Lightweight virtualisation; Linux cgroups; Linux namespaces","Computer operating systems; Linux; Virtual reality; Code portability; Emerging topics; Namespaces; Reproducibilities; Reproducible research; Virtualisation; Virtualization",Conference Paper,"Final",,Scopus,2-s2.0-85032369835
"Reich M., Tabor T., Liefeld T., Thorvaldsdóttir H., Hill B., Tamayo P., Mesirov J.P.","7102532306;57195355357;8841773900;36769531200;42761401400;6603831607;55763795299;","The GenePattern Notebook Environment",2017,"Cell Systems","5","2",,"149","151.e1",,6,"10.1016/j.cels.2017.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027394119&doi=10.1016%2fj.cels.2017.07.003&partnerID=40&md5=c647fa90ef1d4ea3ee220726be05b126","School of Medicine, University of California, San Diego, La Jolla, CA, United States; The Broad Institute of MIT and Harvard, Cambridge, MA, United States; Moores Cancer Center, University of California, San Diego, La Jolla, CA, United States","Reich, M., School of Medicine, University of California, San Diego, La Jolla, CA, United States; Tabor, T., School of Medicine, University of California, San Diego, La Jolla, CA, United States; Liefeld, T., School of Medicine, University of California, San Diego, La Jolla, CA, United States; Thorvaldsdóttir, H., The Broad Institute of MIT and Harvard, Cambridge, MA, United States; Hill, B., The Broad Institute of MIT and Harvard, Cambridge, MA, United States; Tamayo, P., School of Medicine, University of California, San Diego, La Jolla, CA, United States, Moores Cancer Center, University of California, San Diego, La Jolla, CA, United States; Mesirov, J.P., School of Medicine, University of California, San Diego, La Jolla, CA, United States, The Broad Institute of MIT and Harvard, Cambridge, MA, United States, Moores Cancer Center, University of California, San Diego, La Jolla, CA, United States","Interactive analysis notebook environments promise to streamline genomics research through interleaving text, multimedia, and executable code into unified, sharable, reproducible “research narratives.” However, current notebook systems require programming knowledge, limiting their wider adoption by the research community. We have developed the GenePattern Notebook environment (http://www.genepattern-notebook.org), to our knowledge the first system to integrate the dynamic capabilities of notebook systems with an investigator-focused, easy-to-use interface that provides access to hundreds of genomic tools without the need to write code. © 2017 Elsevier Inc.","bioinformatics; integrative genomics; open science; reproducible research","biology; computer interface; gene expression profiling; genomics; procedures; software; Computational Biology; Gene Expression Profiling; Genomics; Software; User-Computer Interface",Article,"Final",Open Access,Scopus,2-s2.0-85027394119
"Singh M., Jaiswal A., Shree P., Pal A., Mukherjee A., Goyal P.","57022653300;57195423984;57212972885;55794998300;57203731567;57119093300;","Understanding the Impact of Early Citers on Long-Term Scientific Impact",2017,"Proceedings of the ACM/IEEE Joint Conference on Digital Libraries",,, 7991560,"","",,5,"10.1109/JCDL.2017.7991560","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028003485&doi=10.1109%2fJCDL.2017.7991560&partnerID=40&md5=ba88314a70caf097a6e959fd3897bb08","Dept. of Computer Science and Engg., IIT, Kharagpur, India; TCS Innovation Labs, India","Singh, M., Dept. of Computer Science and Engg., IIT, Kharagpur, India; Jaiswal, A., Dept. of Computer Science and Engg., IIT, Kharagpur, India; Shree, P., Dept. of Computer Science and Engg., IIT, Kharagpur, India; Pal, A., TCS Innovation Labs, India; Mukherjee, A., Dept. of Computer Science and Engg., IIT, Kharagpur, India; Goyal, P., Dept. of Computer Science and Engg., IIT, Kharagpur, India","This paper explores an interesting new dimension to the challenging problem of predicting long-term scientific impact (LTSI) usually measured by the number of citations accumulated by a paper in the long-term. It is well known that early citations (within 1-2 years after publication) acquired by a paper positively affects its LTSI. However, there is no work that investigates if the set of authors who bring in these early citations to a paper also affect its LTSI. In this paper, we demonstrate for the first time, the impact of these authors whom we call early citers (EC) on the LTSI of a paper. Note that this study of the complex dynamics of EC introduces a brand new paradigm in citation behavior analysis. Using a massive computer science bibliographic dataset we identify two distinct categories of EC - we call those authors who have high overall publication/citation count in the dataset as influential and the rest of the authors as non- influential. We investigate three characteristic properties of EC and present an extensive analysis of how each category correlates with LTSI in terms of these properties. In contrast to popular perception, we find that influential EC negatively affects LTSI possibly owing to attention stealing. To motivate this, we present several representative examples from the dataset. A closer inspection of the collaboration network reveals that this stealing effect is more profound if an EC is nearer to the authors of the paper being investigated. As an intuitive use case, we show that incorporating EC properties in the state-of-the-art supervised citation prediction models leads to high performance margins. At the closing, we present an online portal to visualize EC statistics along with the prediction results for a given query paper. The portal is accessible online at: http://www.cnergres.iitkgp.ac.in/earlyciters/. To facilitate reproducible research, we make all the codes and the processed dataset available in the public domain. © 2017 IEEE.","citation count; early citers; Long-term scientific impact; supervised regression models","Forecasting; Regression analysis; Behavior analysis; Characteristic properties; citation count; Collaboration network; early citers; Long-term scientific impact; Regression model; Reproducible research; Digital libraries",Conference Paper,"Final",,Scopus,2-s2.0-85028003485
"Thavasimani P., Cala J., Missier P.","57193603476;57191418798;22938389700;","Why-Diff: Explaining differences amongst similar workflow runs by exploiting scientific metadata",2017,"Proceedings - 2017 IEEE International Conference on Big Data, Big Data 2017","2018-January",,,"3031","3041",,2,"10.1109/BigData.2017.8258275","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047784652&doi=10.1109%2fBigData.2017.8258275&partnerID=40&md5=881b1ccd276bbca464debd991b29a6f6","School of Computing Science, Newcastle University, United Kingdom","Thavasimani, P., School of Computing Science, Newcastle University, United Kingdom; Cala, J., School of Computing Science, Newcastle University, United Kingdom; Missier, P., School of Computing Science, Newcastle University, United Kingdom","Majority of workflows executed nowadays need to process a massive amount of data. Re-execution of such dataintensive scientific workflows often results in different outputs. Scientific research progresses when discoveries are reproduced and verified. However, simply re-enacting a scientific computation, such as a workflow, does not guarantee the correctness of results because of unintentional changes that may have interfered with the re-enactment process. We investigate the hypothesis that the metadata of a workflow execution can be used to explain why the experimenter observes different results (cause analysis). Similarly, Scientific metadata can be used to determine the impact of intentional variations that the experimenter may have injected into a new version of the workflow. We explore these two complementary cases using a simple algorithm for traversing two metadata traces in lock-step mode, which we illustrate through two human genomics data analysis workflows. © 2017 IEEE.","Big Data; eScience Central; Metadata; Provenance; Reproducible Research; Why-Diff; Workflow","Metadata; e-Science; Provenance; Reproducible research; Why-Diff; Workflow; Big data",Conference Paper,"Final",,Scopus,2-s2.0-85047784652
"Nussbaum L.","15924076000;","Towards trustworthy testbeds thanks to throughout testing",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,, 7965227,"1571","1578",,2,"10.1109/IPDPSW.2017.101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028031067&doi=10.1109%2fIPDPSW.2017.101&partnerID=40&md5=93458ca60e8adc32d2bb3032e939ee33","Inria, Villers-lés-Nancy, F-54600, France; Université de Lorraine, LORIAF-54500, France; CNRS, LORIA - UMR 7503F-54500, France","Nussbaum, L., Inria, Villers-lés-Nancy, F-54600, France, Université de Lorraine, LORIAF-54500, France, CNRS, LORIA - UMR 7503F-54500, France","When using testbeds in the context of experimental computer science, theability to produce trustworthy and reproducible experiments results dependsgreatly on the trustworthiness of the infrastructure itself. Unfortunately, several factors many issues such as software misconfiguration, hardwareheterogeneity, or service failures, can remain undetected and affect thequality of experimental results. This paper presents the design andimplementation of an automated testbed testing framework. This framework wasdeployed in the context of the Grid'5000 project, and uncovered more than onehundred of issues. © 2017 IEEE.","automated testing; experimentation; regression testing; reproducible research; testbeds","Software testing; Automated testing; experimentation; Misconfigurations; Regression testing; Reproducible research; Service failure; Testing framework; Testbeds",Conference Paper,"Final",,Scopus,2-s2.0-85028031067
"Marwick B.","8572128400;","Computational Reproducibility in Archaeological Research: Basic Principles and a Case Study of Their Implementation",2017,"Journal of Archaeological Method and Theory","24","2",,"424","450",,43,"10.1007/s10816-015-9272-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953396823&doi=10.1007%2fs10816-015-9272-9&partnerID=40&md5=5720addf1a758b087fa44bb31944a489","Department of Anthropology, University of Washington, Seattle, WA, United States; Center for Archaeological Science, University of Wollongong, Wollongong, Australia","Marwick, B., Department of Anthropology, University of Washington, Seattle, WA, United States, Center for Archaeological Science, University of Wollongong, Wollongong, Australia","The use of computers and complex software is pervasive in archaeology, yet their role in the analytical pipeline is rarely exposed for other researchers to inspect or reuse. This limits the progress of archaeology because researchers cannot easily reproduce each other’s work to verify or extend it. Four general principles of reproducible research that have emerged in other fields are presented. An archaeological case study is described that shows how each principle can be implemented using freely available software. The costs and benefits of implementing reproducible research are assessed. The primary benefit, of sharing data in particular, is increased impact via an increased number of citations. The primary cost is the additional time required to enhance reproducibility, although the exact amount is difficult to quantify. © 2016, Springer Science+Business Media New York.","Australian archaeology; Computer programming; Open science; Reproducible research; Software engineering",,Article,"Final",,Scopus,2-s2.0-84953396823
"Lahti L., Huovari J., Kainu M., Biecek P.","8679063700;37003007000;57188314400;23003457600;","Retrieval and analysis of eurostat open data with the eurostat package",2017,"R Journal","9","1",,"385","392",,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021396283&partnerID=40&md5=40cb37272c9757f33201ad5d9ef28eb7","Department of Mathematics and Statistics, University of Turku, PO Box 20014, Finland; Pellervo Economic Research PTT, Eerikinkatu 28 A, Helsinki, 00180, Finland; Research Department, The Social Insurance Institution of Finland, PO Box 450, Helsinki, 00101, Finland; Faculty of Mathematics and Information Science, Warsaw University of Technology, Koszykowa 75, Warsaw, 00-662, Poland","Lahti, L., Department of Mathematics and Statistics, University of Turku, PO Box 20014, Finland; Huovari, J., Pellervo Economic Research PTT, Eerikinkatu 28 A, Helsinki, 00180, Finland; Kainu, M., Research Department, The Social Insurance Institution of Finland, PO Box 450, Helsinki, 00101, Finland; Biecek, P., Faculty of Mathematics and Information Science, Warsaw University of Technology, Koszykowa 75, Warsaw, 00-662, Poland","The increasing availability of open statistical data resources is providing novel opportunities for research and citizen science. Efficient algorithmic tools are needed to realize the full potential of the new information resources. We introduce the eurostat R package that provides a collection of custom tools for the Eurostat open data service, including functions to query, download, manipulate, and visualize these data sets in a smooth, automated and reproducible manner. The online documentation provides detailed examples on the analysis of these spatio-temporal data collections. This work provides substantial improvements over the previously available tools, and has been extensively tested by an active user community. The eurostat R package contributes to the growing open source ecosystem dedicated to reproducible research in computational social science and digital humanities.",,,Article,"Final",,Scopus,2-s2.0-85021396283
"Neville J., Kopko S., Romero K., Corrigan B., Stafford B., LeRoy E., Broadbent S., Cisneroz M., Wilson E., Reiman E., Vanderstichele H., Arnerić S.P., Stephenson D.","35181761100;56538541600;35068449000;7003297850;57194105531;56680832200;56538243800;56282848200;57194104936;7005957089;7003790485;57207533625;7202648428;","Accelerating drug development for Alzheimer's disease through the use of data standards",2017,"Alzheimer's and Dementia: Translational Research and Clinical Interventions","3","2",,"273","283",,2,"10.1016/j.trci.2017.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018774799&doi=10.1016%2fj.trci.2017.03.006&partnerID=40&md5=6b60219483863dd12f1aa36749bca297","Critical Path Institute, Tucson, AZ, United States; CDISC, Austin, TX, United States; Division of Pharmacometrics, Pfizer Global Research and Development, Groton, CT, United States; College of Medicine, The University of Arizona, Tucson, AZ, United States; Arizona State University, Tempe, AZ, United States; Banner Medical institute, Arizona State University, Phoenix, AZ, United States; Biomarkable, bvba, Gent, Belgium","Neville, J., Critical Path Institute, Tucson, AZ, United States; Kopko, S., CDISC, Austin, TX, United States; Romero, K., Critical Path Institute, Tucson, AZ, United States; Corrigan, B., Division of Pharmacometrics, Pfizer Global Research and Development, Groton, CT, United States; Stafford, B., Critical Path Institute, Tucson, AZ, United States; LeRoy, E., CDISC, Austin, TX, United States; Broadbent, S., Critical Path Institute, Tucson, AZ, United States; Cisneroz, M., College of Medicine, The University of Arizona, Tucson, AZ, United States; Wilson, E., Arizona State University, Tempe, AZ, United States; Reiman, E., Banner Medical institute, Arizona State University, Phoenix, AZ, United States; Vanderstichele, H., Biomarkable, bvba, Gent, Belgium; Arnerić, S.P., Critical Path Institute, Tucson, AZ, United States; Stephenson, D., Critical Path Institute, Tucson, AZ, United States","Introduction The exceedingly high rate of failed trials in Alzheimer's disease (AD) calls for immediate attention to improve efficiencies and learning from past, ongoing, and future trials. Accurate, highly rigorous standardized data are at the core of meaningful scientific research. Data standards allow for proper integration of clinical data sets and represent the essential foundation for regulatory endorsement of drug development tools. Such tools increase the potential for success and accuracy of trial results. Methods The development of the Clinical Data Interchange Standards Consortium (CDISC) AD therapeutic area data standard was a comprehensive collaborative effort by CDISC and Coalition Against Major Diseases, a consortium of the Critical Path Institute. Clinical concepts for AD and mild cognitive impairment were defined and a data standards user guide was created from various sources of input, including data dictionaries used in AD clinical trials and observational studies. Results A comprehensive collection of AD-specific clinical data standards consisting of clinical outcome measures, leading candidate genes, and cerebrospinal fluid and imaging biomarkers was developed. The AD version 2.0 (V2.0) Therapeutic Area User Guide was developed by diverse experts working with data scientists across multiple consortia through a comprehensive review and revision process. The AD CDISC standard is a publicly available resource to facilitate widespread use and implementation. Discussion The AD CDISC V2.0 data standard serves as a platform to catalyze reproducible research, data integration, and efficiencies in clinical trials. It allows for the mapping and integration of available data and provides a foundation for future studies, data sharing, and long-term registries in AD. The availability of consensus data standards for AD has the potential to facilitate clinical trial initiation and increase sharing and aggregation of data across observational studies and among clinical trials, thereby improving our understanding of disease progression and treatment. © 2017 The Authors","Biomarkers; CDISC; Clinical outcome assessments; Clinical trials; Data science; Data standards; Drug development and Alzheimer's disease; Mild cognitive impairment; Regulatory science; Therapeutic Area User Guide; Translational science","amyloid beta protein; apolipoprotein E; biological marker; nootropic agent; tau protein; Alzheimer disease; Article; cerebrospinal fluid; clinical outcome; clinical trial (topic); dementia assessment; Disability Assessment for Dementia; disease course; family history; functional assessment; human; Mini Mental State Examination; Modified Hachinski Ischemic Scale; neuroimaging; nuclear magnetic resonance imaging; positron emission tomography; positron emission tomography-computed tomography; priority journal; prognosis; standard; standardization",Article,"Final",Open Access,Scopus,2-s2.0-85018774799
"Kiar G., Gorgolewski K.J., Kleissas D., Roncal W.G., Litt B., Wandell B., Poldrack R.A., Wiener M., Vogelstein R.J., Burns R., Vogelstein J.T.","55682725800;55355064700;55834996800;55746368700;7003317462;7006731808;7004739390;55395695800;6506096493;7401945664;15761214600;","Science in the cloud (SIC): A use case in MRI connectomics",2017,"GigaScience","6","5", gix013,"1","10",,4,"10.1093/gigascience/gix013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020247283&doi=10.1093%2fgigascience%2fgix013&partnerID=40&md5=e3446797e1ad9e62074de6a10297dc9f","Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, United States; Center for Imaging Science, Johns Hopkins University, Baltimore, MD, United States; Department of Psychology, Stanford University, Stanford, CA, United States; Johns Hopkins University Applied Physics Lab, Columbia, MD, United States; Department of Computer Science, Johns Hopkins University, Baltimore, MD, United States; Department of Bioengineering, University of Pennsylvania, Philadelphia, PA, United States; Department of Neurology, Hospital of the University of Pennsylvania, Philadelphia, PA, United States; Center for Cognitive and Neurobiological Imaging, Stanford University, Stanford, CA, United States; Department of Psychology, George Mason University, Fairfax, VA, United States","Kiar, G., Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, United States, Center for Imaging Science, Johns Hopkins University, Baltimore, MD, United States; Gorgolewski, K.J., Department of Psychology, Stanford University, Stanford, CA, United States; Kleissas, D., Johns Hopkins University Applied Physics Lab, Columbia, MD, United States; Roncal, W.G., Johns Hopkins University Applied Physics Lab, Columbia, MD, United States, Department of Computer Science, Johns Hopkins University, Baltimore, MD, United States; Litt, B., Department of Bioengineering, University of Pennsylvania, Philadelphia, PA, United States, Department of Neurology, Hospital of the University of Pennsylvania, Philadelphia, PA, United States; Wandell, B., Department of Psychology, Stanford University, Stanford, CA, United States, Center for Cognitive and Neurobiological Imaging, Stanford University, Stanford, CA, United States; Poldrack, R.A., Department of Psychology, Stanford University, Stanford, CA, United States; Wiener, M., Department of Psychology, George Mason University, Fairfax, VA, United States; Vogelstein, R.J., Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, United States; Burns, R., Department of Computer Science, Johns Hopkins University, Baltimore, MD, United States; Vogelstein, J.T., Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, United States, Center for Imaging Science, Johns Hopkins University, Baltimore, MD, United States","Modern technologies are enabling scientists to collect extraordinary amounts of complex and sophisticated data across a huge range of scales like never before. With this onslaught of data, we can allow the focal point to shift from data collection to data analysis. Unfortunately, lack of standardized sharing mechanisms and practices often make reproducing or extending scientific results very difficult. With the creation of data organization structures and tools that drastically improve code portability, we now have the opportunity to design such a framework for communicating extensible scientific discoveries. Our proposed solution leverages these existing technologies and standards, and provides an accessible and extensible model for reproducible research, called 'science in the cloud' (SIC). Exploiting scientific containers, cloud computing, and cloud data services, we show the capability to compute in the cloud and run a web service that enables intimate interaction with the tools and data presented. We hope this model will inspire the community to produce reproducible and, importantly, extensible results that will enable us to collectively accelerate the rate at which scientific breakthroughs are discovered, replicated, and extended. © The Author 2017. Published by Oxford University Press.","Cloud computing; Connectomics; MRI; Reproducibility","algorithm; Article; cloud computing; computer language; connectome; neuroscience; nuclear magnetic resonance imaging; priority journal; publication; standardization; statistics; technology; cloud computing; connectome; human; image processing; Internet; nuclear magnetic resonance imaging; science; software; Cloud Computing; Connectome; Humans; Image Processing, Computer-Assisted; Internet; Magnetic Resonance Imaging; Science; Software",Article,"Final",Open Access,Scopus,2-s2.0-85020247283
"Meng H., Thain D., Vyushkov A., Wolf M., Woodard A.","56673480600;8900976600;57193811045;57143424300;57188676701;","Conducting reproducible research with Umbrella: Tracking, creating, and preserving execution environments",2017,"Proceedings of the 2016 IEEE 12th International Conference on e-Science, e-Science 2016",,, 7870889,"91","100",,3,"10.1109/eScience.2016.7870889","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016784559&doi=10.1109%2feScience.2016.7870889&partnerID=40&md5=9d2d88c34ec773bf6628029887c87185","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN  46556, United States; Center for Research Computing, University of Notre Dame, Notre Dame, IN  46556, United States; Department of Physics, University of Notre Dame, Notre Dame, IN  46556, United States","Meng, H., Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN  46556, United States; Thain, D., Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN  46556, United States; Vyushkov, A., Center for Research Computing, University of Notre Dame, Notre Dame, IN  46556, United States; Wolf, M., Department of Physics, University of Notre Dame, Notre Dame, IN  46556, United States; Woodard, A., Department of Physics, University of Notre Dame, Notre Dame, IN  46556, United States","Publishing scientific results without the detailed execution environments describing how the results were collected makes it difficult or even impossible for the reader to reproduce the work. However, the configurations of the execution environments are too complex to be described easily by authors. To solve this problem, we propose a framework facilitating the conduct of reproducible research by tracking, creating, and preserving the comprehensive execution environments with Umbrella. The framework includes a lightweight, persistent and deployable execution environment specification, an execution engine which creates the specified execution environments, and an archiver which archives an execution environment into persistent storage services like Amazon S3 and Open Science Framework (OSF). The execution engine utilizes sandbox techniques like virtual machines (VMs), Linux containers and user-space tracers, to create an execution environment, and allows common dependencies like base OS images to be shared by sandboxes for different applications. We evaluate our framework by utilizing it to reproduce three scientific applications from epidemiology, scene rendering, and high energy physics. We evaluate the time and space overhead of reproducing these applications, and the effectiveness of the chosen archive unit and mounting mechanism for allowing different applications to share dependencies. Our results show that these applications can be reproduced using different sandbox techniques successfully and efficiently, even through the overhead and performance slightly vary. © 2016 IEEE.",,"Computer operating systems; Engines; High energy physics; Execution engine; Execution environments; Open science; Persistent storage; Reproducible research; Scientific applications; Scientific results; Space overhead; Network function virtualization",Conference Paper,"Final",,Scopus,2-s2.0-85016784559
"De Roure D., Klyne G., Page K.R., Pybus J., Weigl D.M., Wilcoxson M., Willcox P.","6701509117;24385449500;8104972900;35791194000;55359633400;57193803867;57023577900;","Plans and performances: Parallels in the production of science and music",2017,"Proceedings of the 2016 IEEE 12th International Conference on e-Science, e-Science 2016",,, 7870899,"185","192",,2,"10.1109/eScience.2016.7870899","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016772033&doi=10.1109%2feScience.2016.7870899&partnerID=40&md5=1b0dbe8799b2866745f0ead82431a492","Bodleian Libraries, Oxford E-Research Centre, University of Oxford, Oxford, United Kingdom","De Roure, D., Bodleian Libraries, Oxford E-Research Centre, University of Oxford, Oxford, United Kingdom; Klyne, G., Bodleian Libraries, Oxford E-Research Centre, University of Oxford, Oxford, United Kingdom; Page, K.R., Bodleian Libraries, Oxford E-Research Centre, University of Oxford, Oxford, United Kingdom; Pybus, J., Bodleian Libraries, Oxford E-Research Centre, University of Oxford, Oxford, United Kingdom; Weigl, D.M., Bodleian Libraries, Oxford E-Research Centre, University of Oxford, Oxford, United Kingdom; Wilcoxson, M., Bodleian Libraries, Oxford E-Research Centre, University of Oxford, Oxford, United Kingdom; Willcox, P., Bodleian Libraries, Oxford E-Research Centre, University of Oxford, Oxford, United Kingdom","Whether in the science lab or the music studio, we go in with a plan, we perform, and we make a record of that performance for distribution, consumption, and reuse. Both domains are increasingly data-intensive, with the adoption of new technology, and also socially intensive with democratised and growing citizen engagement. The music industry has embraced digital technology throughout the lifecycle from composition to consumption; scientific practice, and scholarly communication, are also undergoing transformation. Is the music industry more digital than science? We suggest that comparing and contrasting these two systems will provide insights of mutual benefit. Our investigation explores the notion of the Digital Music Object, analogous to the Research Object, for rich capture, sharing and reuse of both process and content. © 2016 IEEE.","Digital Music Object; provenance; Reproducible Research; Research Object; scholarly communication; workflow","Digital music; provenance; Reproducible research; Research object; Scholarly communication; workflow",Conference Paper,"Final",,Scopus,2-s2.0-85016772033
[No author name available],[No author id available],"Proceedings of the 2016 IEEE 12th International Conference on e-Science, e-Science 2016",2017,"Proceedings of the 2016 IEEE 12th International Conference on e-Science, e-Science 2016",,,,"","",459,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016739568&partnerID=40&md5=42cd04a5bbf9ebeeabab1a6686886c6c",,"","The proceedings contain 52 papers. The topics discussed include: campus compute co-operative (CCC): a service oriented cloud federation; prediction of workflow execution time using provenance traces: practical applications in medical data processing; accelerating data-driven discovery with scientific asset management; generating knowledge networks from phenotypic descriptions; conducting reproducible research with umbrella: tracking, creating, and preserving execution environments; fast window aggregate on array database by recursive incremental computation; representation of continuously changing data over time and space: modeling the shape of spatiotemporal phenomena; an n-gram cache for large-scale parallel extraction of multiword relevant expressions with LocalMaxs; budget distribution strategies for scientific workflow scheduling in commercial clouds; Datatrack: an R package for managing data in a multi-stage experimental workflow - data versioning and provenance considerations in interactive scripting; automatic Glomerulus extraction in whole slide images towards computer aided diagnosis; improving data provenance reconstruction via a multi-level funneling approach; plans and performances: parallels in the production of science and music; and a comprehensive scenario agnostic data lifecycle model for an efficient data complexity management.",,,Conference Review,"Final",,Scopus,2-s2.0-85016739568
"Olito C., White C.R., Marshall D.J., Barneche D.R.","26321812100;7404153052;7402186529;25642641700;","Estimating monotonic rates from biological data using local linear regression",2017,"Journal of Experimental Biology","220","5",,"759","764",,5,"10.1242/jeb.148775","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014573994&doi=10.1242%2fjeb.148775&partnerID=40&md5=f2009d4724f25dc667661c58a9dd789b","Centre for Geometric Biology, School of Biological Sciences, Monash University, Clayton, VIC  3800, Australia","Olito, C., Centre for Geometric Biology, School of Biological Sciences, Monash University, Clayton, VIC  3800, Australia; White, C.R., Centre for Geometric Biology, School of Biological Sciences, Monash University, Clayton, VIC  3800, Australia; Marshall, D.J., Centre for Geometric Biology, School of Biological Sciences, Monash University, Clayton, VIC  3800, Australia; Barneche, D.R., Centre for Geometric Biology, School of Biological Sciences, Monash University, Clayton, VIC  3800, Australia","Accessing many fundamental questions in biology begins with empirical estimation of simple monotonic rates of underlying biological processes. Across a variety of disciplines, ranging from physiology to biogeochemistry, these rates are routinely estimated from non-linearand noisy timeseries data using linear regression and adhoc manual truncation of non-linearities. Here, we introduce the R package LoLinR, aflexible toolkit to implement local linear regression techniques to objectively and reproduciblyestimatemonotonic biological rates from non-linear time series data, and demonstrate possible applications using metabolic rate data. LoLinR provides methods to easily and reliably estimate monotonic rates from time series data in a way that is statistically robust, facilitates reproducible research and is applicable to a wide variety of research disciplines in the biological sciences. © 2017. Published by The Company of Biologists Ltd.","Autocorrelation; Biological rates; Linearity; Local linear regression; Reproducible research; Time series","algorithm; animal; basal metabolic rate; biological model; bird; Bryozoa; computer simulation; kinetics; larva; metabolism; oxygen consumption; software; statistical model; Algorithms; Animals; Basal Metabolism; Birds; Bryozoa; Computer Simulation; Kinetics; Larva; Linear Models; Models, Biological; Oxygen Consumption; Software",Article,"Final",Open Access,Scopus,2-s2.0-85014573994
"Cernak M., Komaty A., Mohammadi A., Anjos A., Marcel S.","8717701100;57200081344;57200733407;6506491800;6603136018;","Bob speaks kaldi",2017,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","2017-August",,,"2030","2031",,,"10.21437/Interspeech.2017-2025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039155644&doi=10.21437%2fInterspeech.2017-2025&partnerID=40&md5=7b40ddde3fc9618b7277858c5bccaed3","Idiap Research Institute, Switzerland","Cernak, M., Idiap Research Institute, Switzerland; Komaty, A., Idiap Research Institute, Switzerland; Mohammadi, A., Idiap Research Institute, Switzerland; Anjos, A., Idiap Research Institute, Switzerland; Marcel, S., Idiap Research Institute, Switzerland","This paper introduces and demonstrates Kaldi integration into Bob signal-processing and machine learning toolbox. The motivation for this integration is two-fold. Firstly, Bob benefits from using advanced speech processing tools developed in Kaldi. Secondly, Kaldi benefits from using complementary Bob modules, such as modulation-based VAD with an adaptive thresholding. In addition, Bob is designed as an open science tool, and this integration might offer to the Kaldi speech community a framework for better reproducibility of state-of-The-Art research results. Keywords Kaldi toolkit∗Bob toolbox∗Speaker verification∗Reproducible research∗Open science. Copyright © 2017 ISCA.",,"Integration; Learning systems; Signal processing; Speech processing; Speech recognition; Adaptive thresholding; Open science; Reproducibilities; Reproducible research; Speaker verification; State of the art; Speech communication",Conference Paper,"Final",,Scopus,2-s2.0-85039155644
"Mesnard O., Barba L.A.","57201899749;8294521800;","Reproducible and Replicable Computational Fluid Dynamics: It's Harder Than You Think",2017,"Computing in Science and Engineering","19","4", 8012284,"44","55",,9,"10.1109/MCSE.2017.3151254","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028848136&doi=10.1109%2fMCSE.2017.3151254&partnerID=40&md5=2574292fedc916555f808d10cf0e3159","George Washington University, United States","Mesnard, O., George Washington University, United States; Barba, L.A., George Washington University, United States","Completing a full replication study of the authors' previously published findings on bluff-body aerodynamics was harder than they thought, despite them having good reproducible-research practices, such as sharing their code and data openly. Here's what they learned from three years, four computational fluid dynamics codes, and hundreds of runs. © 1999-2011 IEEE.","CFD; computational fluid dynamics; reproducible research; scientific computing","Dynamics; Fluid dynamics; Natural sciences computing; Bluff body aerodynamics; Computational Fluid Dynamics codes; Replication study; Reproducible research; Computational fluid dynamics",Article,"Final",,Scopus,2-s2.0-85028848136
"Curcin V., Fairweather E., Danger R., Corrigan D.","8510022100;50760998800;55920998300;55871509600;","Templates as a method for implementing data provenance in decision support systems",2017,"Journal of Biomedical Informatics","65",,,"1","21",,11,"10.1016/j.jbi.2016.10.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997684091&doi=10.1016%2fj.jbi.2016.10.022&partnerID=40&md5=d26a47a829e8d54384dec1c64f26ee84","Division of Health and Social Care Research, King's College London, London, United Kingdom; Reed Online Ltd, London, United Kingdom; Royal College of Surgeons in Ireland, Dublin, Ireland","Curcin, V., Division of Health and Social Care Research, King's College London, London, United Kingdom; Fairweather, E., Division of Health and Social Care Research, King's College London, London, United Kingdom; Danger, R., Reed Online Ltd, London, United Kingdom; Corrigan, D., Royal College of Surgeons in Ireland, Dublin, Ireland","Decision support systems are used as a method of promoting consistent guideline-based diagnosis supporting clinical reasoning at point of care. However, despite the availability of numerous commercial products, the wider acceptance of these systems has been hampered by concerns about diagnostic performance and a perceived lack of transparency in the process of generating clinical recommendations. This resonates with the Learning Health System paradigm that promotes data-driven medicine relying on routine data capture and transformation, which also stresses the need for trust in an evidence-based system. Data provenance is a way of automatically capturing the trace of a research task and its resulting data, thereby facilitating trust and the principles of reproducible research. While computational domains have started to embrace this technology through provenance-enabled execution middlewares, traditionally non-computational disciplines, such as medical research, that do not rely on a single software platform, are still struggling with its adoption. In order to address these issues, we introduce provenance templates – abstract provenance fragments representing meaningful domain actions. Templates can be used to generate a model-driven service interface for domain software tools to routinely capture the provenance of their data and tasks. This paper specifies the requirements for a Decision Support tool based on the Learning Health System, introduces the theoretical model for provenance templates and demonstrates the resulting architecture. Our methods were tested and validated on the provenance infrastructure for a Diagnostic Decision Support System that was developed as part of the EU FP7 TRANSFoRm project. © 2016 The Author(s)","D2.1 (Software Engineering) Requirements/specification J.3 (Life and Medical Sciences): Health data provenance; Decision support systems; Model-driven architectures","Artificial intelligence; Diagnosis; Diagnostic products; Embedded systems; Metadata; Software architecture; Software engineering; Computational domains; Decision support tools; Diagnostic performance; Evidence-based system; Life and medical science; Model driven architectures; Reproducible research; Theoretical modeling; Decision support systems; Article; conceptual framework; data processing; decision support system; health promotion; information processing; mathematical computing; mathematical model; medical decision making; medical literature; Open Provenance model; priority journal; reproducibility; responsibility; validation process; clinical decision support system; computer system; human; medical research; software; standards; theoretical model; trends; Biomedical Research; Computer Systems; Data Collection; Decision Support Systems, Clinical; Humans; Models, Theoretical; Software",Article,"Final",Open Access,Scopus,2-s2.0-84997684091
"Stander J., Dalla Valle L.","6603711275;57200118862;","On enthusing students about big data and social media visualization and analysis using R, RStudio, and RMarkdown",2017,"Journal of Statistics Education","25","2",,"60","67",,3,"10.1080/10691898.2017.1322474","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043760207&doi=10.1080%2f10691898.2017.1322474&partnerID=40&md5=97d870ff239ef74331dcac13121ac44b","School of Computing, Electronics and Mathematics, University of Plymouth, Plymouth, United Kingdom","Stander, J., School of Computing, Electronics and Mathematics, University of Plymouth, Plymouth, United Kingdom; Dalla Valle, L., School of Computing, Electronics and Mathematics, University of Plymouth, Plymouth, United Kingdom","We discuss the learning goals, content, and delivery of a University of Plymouth intensive module delivered over four weeks entitled MATH1608PP Understanding Big Data from Social Networks, aimed at introducing students to a broad range of techniques used in modern Data Science. This module made use of R, accessed through RStudio, and some popular R packages. After describing initial examples used to fire student enthusiasm, we explain our approach to teaching data visualization using the ggplot2 package. We discuss other module topics, including basic statistical inference, data manipulation with dplyr and tidyr, data bases and SQL, social media sentiment analysis, Likert-type data, reproducible research using RMarkdown, dimension reduction and clustering, and parallel R. We present four lesson outlines and describe the module assessment. We mention some of the problems encountered when teaching the module, and present student feedback and our plans for next year. © 2017 Julian Stander and Luciana Dalla Valle.","Data science; Data visualization; R software; Social media",,Article,"Final",Open Access,Scopus,2-s2.0-85043760207
"Nüst D., Konkol M., Schutzeichel M., Pebesma E., Kray C., Przibytzin H., Lorenz J.","49361950400;57193205857;57193212148;6603459366;8399247700;57193206033;57203488501;","Opening the publication process with executable research compendia",2017,"D-Lib Magazine","23","1-2",,"","",1,11,"10.1045/january2017-nuest","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011655890&doi=10.1045%2fjanuary2017-nuest&partnerID=40&md5=93e19d5c6aea46748ac05d196e1fa7f3","Institute for Geoinformatics, Münster, Germany; University and State Library, Münster, Germany","Nüst, D., Institute for Geoinformatics, Münster, Germany; Konkol, M., Institute for Geoinformatics, Münster, Germany; Schutzeichel, M., University and State Library, Münster, Germany; Pebesma, E., Institute for Geoinformatics, Münster, Germany; Kray, C., Institute for Geoinformatics, Münster, Germany; Przibytzin, H., University and State Library, Münster, Germany; Lorenz, J., University and State Library, Münster, Germany","A strong movement towards openness has seized science. Open data and methods, open source software, Open Access, open reviews, and open research platforms provide the legal and technical solutions to new forms of research and publishing. However, publishing reproducible research is still not common practice. Reasons include a lack of incentives and a missing standardized infrastructure for providing research material such as data sets and source code together with a scientific paper. Therefore we first study fundamentals and existing approaches. On that basis, our key contributions are the identification of core requirements of authors, readers, publishers, curators, as well as preservationists and the subsequent description of an executable research compendium (ERC). It is the main component of a publication process providing a new way to publish and access computational research. ERCs provide a new standardisable packaging mechanism which combines data, software, text, and a user interface description. We discuss the potential of ERCs and their challenges in the context of user requirements and the established publication processes. We conclude that ERCs provide a novel potential to find, explore, reuse, and archive computer-based research. © 2017 Daniel Nüst, Markus Konkol, Marc Schutzeichel, Edzer Pebesma, Chris Kray, Holger Przibytzin and Jörg Lorenz.","Computational Research; Containerization; ERC; Executable Research Compendium; Open Access; Research Data",,Article,"Final",Open Access,Scopus,2-s2.0-85011655890
"Bowen T., Poylisher A., Serban C., Chadha R., Jason Chiang C.-Y., Marvel L.M.","57200180120;9240439000;15756307700;7005388771;36668768900;6602491689;","Enabling reproducible cyber research-four labeled datasets",2016,"Proceedings - IEEE Military Communications Conference MILCOM",,, 7795383,"539","544",,2,"10.1109/MILCOM.2016.7795383","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011859952&doi=10.1109%2fMILCOM.2016.7795383&partnerID=40&md5=7129b0acef44cc54da6427aba909fd82","Vencore Labs D/b/a/Applied Communication Sciences, Basking Ridge, NJ  07920, United States; U.S. Army Research Laboratory, APG, MD  21005, United States","Bowen, T., Vencore Labs D/b/a/Applied Communication Sciences, Basking Ridge, NJ  07920, United States; Poylisher, A., Vencore Labs D/b/a/Applied Communication Sciences, Basking Ridge, NJ  07920, United States; Serban, C., Vencore Labs D/b/a/Applied Communication Sciences, Basking Ridge, NJ  07920, United States; Chadha, R., Vencore Labs D/b/a/Applied Communication Sciences, Basking Ridge, NJ  07920, United States; Jason Chiang, C.-Y., Vencore Labs D/b/a/Applied Communication Sciences, Basking Ridge, NJ  07920, United States; Marvel, L.M., U.S. Army Research Laboratory, APG, MD  21005, United States","In this paper, we describe the design and creation of four publicly available datasets generated using a testbed with simulated benign users and a manual attacker. The datasets were created to provide examples of cyber exploitations and aid in the production of reproducible research that address cyber security challenges. The CyberVAN testbed provides sophisticated capabilities for high-fidelity cyber experimentation in strategic and tactical network environments. The representative network is sufficiently complex with synthetic users performing normal duties that generate traffic (webpage browsing, e-mail, etc.). Both network and host based facts/logs are included in the dataset along with a diagram of the network and a timeline of events. The four datasets encompass progressively complex scenarios: 1) malware infection injection via a phishing email attachment; 2) propagating botnet injection via phishing email attachment with a Single Fast Flux algorithm for bot master identification/communication; 3) propagating botnet injection via email link using a Domain Generation Algorithm for bot master identification/communication; 4) propagating botnet injection via corruption of a legitimate internal web server with Double Fast Flux for bot master identification/communication. The full datasets along with relevant documentation is available for public download. Additional datasets containing tactical network scenarios and environments will be added to the repository in the future with the goal of enabling reproducible cyber security research that will advance the science of cyber security. © 2016 IEEE.","Computer Network Defense; Computer Network Operations; Cyber Security","Botnet; Complex networks; Computer crime; Electronic mail; Malware; Military communications; Testbeds; Computer network operations; Cyber security; Generation algorithm; High-fidelity; Labeled datasets; Reproducible research; Tactical network; Web servers; Network security",Conference Paper,"Final",,Scopus,2-s2.0-85011859952
"Haas C.N.","7202620514;","Reproducible Risk Assessment",2016,"Risk Analysis","36","10",,"1829","1833",,1,"10.1111/risa.12730","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996554574&doi=10.1111%2frisa.12730&partnerID=40&md5=6a91a4cc9ecb24315d2b69cbdd859df9",,"Haas, C.N.","Reproducible research is a concept that has emerged in data and computationally intensive sciences in which the code used to conduct all analyses, including generation of publication quality figures, is directly available, and preferably in open source manner. This perspective outlines the processes and attributes, and illustrates the execution of reproducible research via a simple exposure assessment of air pollutants in metropolitan Philadelphia. © 2016 Society for Risk Analysis","air pollution; Philadelphia; PM2.5; R; Reproducible research; Sweave",,Note,"Final",,Scopus,2-s2.0-84996554574
"Waltemath D., Wolkenhauer O.","36471561200;6603822253;","How Modeling Standards, Software, and Initiatives Support Reproducibility in Systems Biology and Systems Medicine",2016,"IEEE Transactions on Biomedical Engineering","63","10", 7484267,"1999","2006",,18,"10.1109/TBME.2016.2555481","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991252525&doi=10.1109%2fTBME.2016.2555481&partnerID=40&md5=d99a43493d1916065c73fa9b6d4e2d1e","Institute of Computer Science, University of Rostock, Rostock, 18051, Germany; Stellenbosch Institute for Advanced Study, Wallenberg Research Centre, Stellenbosch University, South Africa","Waltemath, D., Institute of Computer Science, University of Rostock, Rostock, 18051, Germany; Wolkenhauer, O., Stellenbosch Institute for Advanced Study, Wallenberg Research Centre, Stellenbosch University, South Africa","Objective: Only reproducible results are of significance to science. The lack of suitable standards and appropriate support of standards in software tools has led to numerous publications with irreproducible results. Our objectives are to identify the key challenges of reproducible research and to highlight existing solutions. Results: In this paper, we summarize problems concerning reproducibility in systems biology and systems medicine. We focus on initiatives, standards, and software tools that aim to improve the reproducibility of simulation studies. Conclusions: The long-term success of systems biology and systems medicine depends on trustworthy models and simulations. This requires openness to ensure reusability and transparency to enable reproducibility of results in these fields. © 2016 IEEE.","Reproducibility; standards; systems biology; Systems medicine","Biology; Reusability; Standards; Reproducibilities; Reproducible research; Simulation studies; Systems biology; Computer software; instrument validation; medicine; model; reproducibility; software; systems biology; biological model; human; medical research; standards; systems biology; Biomedical Research; Humans; Models, Biological; Reproducibility of Results; Software; Systems Biology",Article,"Final",,Scopus,2-s2.0-84991252525
"Kapur T., Pieper S., Fedorov A., Fillion-Robin J.-C., Halle M., O'Donnell L., Lasso A., Ungi T., Pinter C., Finet J., Pujol S., Jagadeesan J., Tokuda J., Norton I., Estepar R.S.J., Gering D., Aerts H.J.W.L., Jakab M., Hata N., Ibanez L., Blezek D., Miller J., Aylward S., Grimson W.E.L., Fichtinger G., Wells W.M., Lorensen W.E., Schroeder W., Kikinis R.","7003383916;7004506474;8232501700;55279746000;7006617404;8430466800;25030035000;8956745200;54385777900;38561197900;57205962407;13806310900;6602751652;18437683600;6506402426;6602857504;16479697600;7004115166;56940125400;57190663785;6603545781;13907465600;7004344836;35518664500;6602161432;21433923100;6701850407;7201900328;7101859155;","Increasing the impact of medical image computing using community-based open-access hackathons: The NA-MIC and 3D Slicer experience",2016,"Medical Image Analysis","33",,,"176","180",,10,"10.1016/j.media.2016.06.035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982182311&doi=10.1016%2fj.media.2016.06.035&partnerID=40&md5=33086ecedbe7c217111f2b44c0a28f2b","Brigham and Women's Hospital and Harvard Medical School, United States; Isomics Inc., United States; Kitware Inc., United States; Queens University, United States; Healthmyne Inc., United States; Google, United States; Mayo Clinic, United States; General Electric Research, United States; MIT, United States; Emeritus, General Electric Research, United States","Kapur, T., Brigham and Women's Hospital and Harvard Medical School, United States; Pieper, S., Isomics Inc., United States; Fedorov, A., Brigham and Women's Hospital and Harvard Medical School, United States; Fillion-Robin, J.-C., Kitware Inc., United States; Halle, M., Brigham and Women's Hospital and Harvard Medical School, United States; O'Donnell, L., Brigham and Women's Hospital and Harvard Medical School, United States; Lasso, A., Queens University, United States; Ungi, T., Queens University, United States; Pinter, C., Queens University, United States; Finet, J., Kitware Inc., United States; Pujol, S., Brigham and Women's Hospital and Harvard Medical School, United States; Jagadeesan, J., Brigham and Women's Hospital and Harvard Medical School, United States; Tokuda, J., Brigham and Women's Hospital and Harvard Medical School, United States; Norton, I., Brigham and Women's Hospital and Harvard Medical School, United States; Estepar, R.S.J., Brigham and Women's Hospital and Harvard Medical School, United States; Gering, D., Healthmyne Inc., United States; Aerts, H.J.W.L., Brigham and Women's Hospital and Harvard Medical School, United States; Jakab, M., Brigham and Women's Hospital and Harvard Medical School, United States; Hata, N., Brigham and Women's Hospital and Harvard Medical School, United States; Ibanez, L., Google, United States; Blezek, D., Mayo Clinic, United States; Miller, J., General Electric Research, United States; Aylward, S., Kitware Inc., United States; Grimson, W.E.L., MIT, United States; Fichtinger, G., Queens University, United States; Wells, W.M., Brigham and Women's Hospital and Harvard Medical School, United States; Lorensen, W.E., Emeritus, General Electric Research, United States; Schroeder, W., Kitware Inc., United States; Kikinis, R., Brigham and Women's Hospital and Harvard Medical School, United States","The National Alliance for Medical Image Computing (NA-MIC) was launched in 2004 with the goal of investigating and developing an open source software infrastructure for the extraction of information and knowledge from medical images using computational methods. Several leading research and engineering groups participated in this effort that was funded by the US National Institutes of Health through a variety of infrastructure grants. This effort transformed 3D Slicer from an internal, Boston-based, academic research software application into a professionally maintained, robust, open source platform with an international leadership and developer and user communities. Critical improvements to the widely used underlying open source libraries and tools—VTK, ITK, CMake, CDash, DCMTK—were an additional consequence of this effort. This project has contributed to close to a thousand peer-reviewed publications and a growing portfolio of US and international funded efforts expanding the use of these tools in new medical computing applications every year. In this editorial, we discuss what we believe are gaps in the way medical image computing is pursued today; how a well-executed research platform can enable discovery, innovation and reproducible science (“Open Science”); and how our quest to build such a software platform has evolved into a productive and rewarding social engineering exercise in building an open-access community with a shared vision. © 2016 Elsevier B.V.","3D Slicer; Hackathon; Medical image computing; NA-MIC; Open access; Open science; Open source; Project week; Reproducible research","community; Editorial; fee; food; frequency; human; image analysis; imaging software; leadership; longevity; mathematical analysis; national health organization; peer review; priority journal; publication; reproducibility; sample size; algorithm; diagnostic imaging; image processing; open access publishing; software; Algorithms; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Open Access Publishing; Reproducibility of Results; Software",Editorial,"Final",,Scopus,2-s2.0-84982182311
"Bruno R.","56789576400;","Version Control Systems to Facilitate Research Collaboration in Economics",2016,"Computational Economics","48","3",,"547","553",,1,"10.1007/s10614-015-9513-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939613943&doi=10.1007%2fs10614-015-9513-8&partnerID=40&md5=7ced6db254e2e942adc9ced4ce6df1a8","Beta, Université de Strasbourg, 61 avenue de la Forêt Noire, Strasbourg Cedex, 67085, France","Bruno, R., Beta, Université de Strasbourg, 61 avenue de la Forêt Noire, Strasbourg Cedex, 67085, France","Reliable and reproducible research is an important cornerstone of science, and version control systems not only make reproducible research possible in a rapid and easy way, but also provide a way of collaborating with co-authors. The purpose of this methodological paper is to present Git, a very successful version control system and how it can be used by economists working together on their papers and the accompanying computer code. Version control systems also make sharing the findings with the rest of the scientific community more easy and streamlined. To understand how version control systems came to be, one must be familiar with the history of free software. In the introduction, I will present free software and its philosophy and show how version control systems make free software possible. In the second section I present Git which is a widely used version control system. In the third section I show a basic usage of Git. In the fourth section, I conclude. © 2015, Springer Science+Business Media New York.","Econometric software; Economic methodology; Version control systems",,Article,"Final",,Scopus,2-s2.0-84939613943
"Tardiff M.F., Bonheyo G.T., Cort K.A., Edgar T.W., Hess N.J., Hutton W.J., Miller E.A., Nowak K.E., Oehmen C.S., Purvine E.A.H., Schenter G.K., Paul D.","14049546200;7801424454;24176612000;36625104400;35560631000;55670551500;24483575800;57191589647;9432589100;57190974451;6701767060;57191592751;","Applying the scientific method to cybersecurity research",2016,"2016 IEEE Symposium on Technologies for Homeland Security, HST 2016",,, 7568886,"","",,2,"10.1109/THS.2016.7568886","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991758974&doi=10.1109%2fTHS.2016.7568886&partnerID=40&md5=56aa4fee1b1e511e408a14e4fdf61e98","Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States","Tardiff, M.F., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States; Bonheyo, G.T., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States; Cort, K.A., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States; Edgar, T.W., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States; Hess, N.J., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States; Hutton, W.J., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States; Miller, E.A., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States; Nowak, K.E., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States; Oehmen, C.S., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States; Purvine, E.A.H., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States; Schenter, G.K., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States; Paul, D., Whitney National Security Directorate, Pacific Northwest National Laboratory, Richland, WA, United States","The cyber environment has rapidly evolved from a curiosity to an essential component of the contemporary world. As the cyber environment has expanded and become more complex, so have the nature of adversaries and styles of attacks. Today, cyber incidents are an expected part of life. As a result, cybersecurity research emerged to address adversarial attacks interfering with or preventing normal cyber activities. Historical response to cybersecurity attacks is heavily skewed to tactical responses with an emphasis on rapid recovery. While threat mitigation is important and can be time critical, a knowledge gap exists with respect to developing the science of cybersecurity. Such a science will enable the development and testing of theories that lead to understanding the broad sweep of cyber threats and the ability to assess trade-offs in sustaining network missions while mitigating attacks. The Asymmetric Resilient Cybersecurity Initiative at Pacific Northwest National Laboratory is a multi-year, multi-million dollar investment to develop approaches for shifting the advantage to the defender and sustaining the operability of systems under attack. The initiative established a Science Council to focus attention on the research process for cybersecurity. The Council shares science practices, critiques research plans, and AIDS in documenting and reporting reproducible research results. The Council members represent ecology, economics, statistics, physics, computational chemistry, microbiology and genetics, and geochemistry. This paper reports the initial work of the Science Council to implement the scientific method in cybersecurity research. The second section describes the scientific method. The third section in this paper discusses scientific practices for cybersecurity research. Section four describes initial impacts of applying the science practices to cybersecurity research. © 2016 IEEE.",,"Ability testing; Complex networks; Computation theory; Economic and social effects; Economics; National security; Security systems; Development and testing; Pacific northwest national laboratories; Rapid recovery; Reproducible research; Research process; Scientific method; Tactical response; Threat mitigation; Computational chemistry",Conference Paper,"Final",,Scopus,2-s2.0-84991758974
"Higgins J., Holmes V., Venters C.","57026971700;35292226300;8623738900;","Securing user defined containers for scientific computing",2016,"2016 International Conference on High Performance Computing and Simulation, HPCS 2016",,, 7568369,"449","453",,2,"10.1109/HPCSim.2016.7568369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991736658&doi=10.1109%2fHPCSim.2016.7568369&partnerID=40&md5=f30f9d67df604d3c441a102f09d9dc98","University of Huddersfield, High Performance Computing Research Group, Huddersfield, United Kingdom","Higgins, J., University of Huddersfield, High Performance Computing Research Group, Huddersfield, United Kingdom; Holmes, V., University of Huddersfield, High Performance Computing Research Group, Huddersfield, United Kingdom; Venters, C., University of Huddersfield, High Performance Computing Research Group, Huddersfield, United Kingdom","Linux containers and Docker have gained immense popularity as a lightweight alternative to hypervisor based Virtual Machines (VMs). In the context of High Performance Computing and the scientific community, it is clear that containers can serve many useful purposes from system administration, to improved cluster resource management and as a format for sharing reproducible research. However, when compared to VMs, containers seem to trade isolation for performance and ease of use, which poses unique security challenges. In this paper we review how Docker is being used in science, highlight easy to perform exploits, and evaluate the impact of these on HPC deployments. We also summarise a number of strategies for hardening such a system to reduce the vulnerability of hosting User Defined Containers. Based on these, an original solution to enforce default options and container ownership for nonadministrative users in the HPC use case is presented, in addition to the experience of implementing such a system on a cluster at the University of Huddersfield. © 2016 IEEE.","Docker; HPC; security; user defined containers","Cluster computing; Computer operating systems; Docker; High performance computing; Reproducible research; Resource management; Scientific community; security; Security challenges; System administration; Containers",Conference Paper,"Final",,Scopus,2-s2.0-84991736658
"Sinha R., Sudhish P.S.","57191365709;55627031900;","A principled approach to reproducible research: A comparative review towards scientific integrity in computational research",2016,"2016 IEEE International Symposium on Ethics in Engineering, Science and Technology, ETHICS 2016",,, 7560050,"","",,2,"10.1109/ETHICS.2016.7560050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989159613&doi=10.1109%2fETHICS.2016.7560050&partnerID=40&md5=5319e5873af22273e9d55a042f1de8ba","Principal Scientist, Tata Consultancy Services Limited, India; Department of Physics and Computer Science, Dayalbagh Educational Institute, Agra, India","Sinha, R., Principal Scientist, Tata Consultancy Services Limited, India; Sudhish, P.S., Department of Physics and Computer Science, Dayalbagh Educational Institute, Agra, India","Independent replication has stood up sciences in good stead, allowing for a process of selfcorrection and weeding out spurious claims. The factors related to inability of replication are usually related to lack of resources (e.g. money, primary data sources), uniqueness of study or a lack of time or opportunity. As the cost of irreproducible research escalates, computationally intensive research fields such as cancer research show extremely poor results in actual clinical trials pointing to acceptance of poor quality research at preclinical stage. Between complete replication and reliance purely on peer reviews, reproducible research has emerged as a common minimum, allowing regeneration of all facts and figures reported in a research. In this paper, we evaluate concepts for reproducible research, such as literate statistical programming, literate computing frameworks and scientific workflow systems along with set of practices that enable researchers create reproducible research documents. We then present a maturity model wherein reproducible research must require a minimal compliance. The paper also presents details of possible set of copyright laws and open source licenses that can be mixed to provide a compelling open access publication platform protection for researchers. © 2016 IEEE.","Intellectual Property; Replicability; Reproducibility; Research Documentation; Research Ethics","Intellectual property; Open source software; Computational researches; Computing frameworks; Replicability; Reproducibilities; Reproducible research; Research documentation; Research ethics; Scientific workflows; Philosophical aspects",Conference Paper,"Final",,Scopus,2-s2.0-84989159613
"Bond-Lamberty B., Smith A.P., Bailey V.","6602729986;57192318906;57205849412;","Running an open experiment: Transparency and reproducibility in soil and ecosystem science",2016,"Environmental Research Letters","11","8", 084004,"","",,4,"10.1088/1748-9326/11/8/084004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985911808&doi=10.1088%2f1748-9326%2f11%2f8%2f084004&partnerID=40&md5=d279ecffd789592aa0e6bf44ebffaafa","Joint Global Change Research Institute, DOE Pacific Northwest National Laboratory, College Park, MD, United States; Biological Sciences Division, Pacific Northwest National Laboratory, Richland, WA, United States","Bond-Lamberty, B., Joint Global Change Research Institute, DOE Pacific Northwest National Laboratory, College Park, MD, United States; Smith, A.P., Biological Sciences Division, Pacific Northwest National Laboratory, Richland, WA, United States; Bailey, V., Biological Sciences Division, Pacific Northwest National Laboratory, Richland, WA, United States","Researchers in soil and ecosystem science, and almost every other field, are being pushed - by funders, journals, governments, and their peers - to increase transparency and reproducibility of their work. A key part of this effort is a move towards open data as a way to fight post-publication data loss, improve data and code quality, enable powerful meta- and cross-disciplinary analyses, and increase trust in, and the efficiency of, publicly-funded research. Many scientists however lack experience in, and may be unsure of the benefits of, making their data and fully-reproducible analyses publicly available. Here we describe a recent 'open experiment', in which we documented every aspect of a soil incubation online, making all raw data, scripts, diagnostics, final analyses, and manuscripts available in real time. We found that using tools such as version control, issue tracking, and open-source statistical software improved data integrity, accelerated our team's communication and productivity, and ensured transparency. There are many avenues to improve scientific reproducibility and data availability, of which is this only one example, and it is not an approach suited for every experiment or situation. Nonetheless, we encourage the communities in our respective fields to consider its advantages, and to lead rather than follow with respect to scientific reproducibility, transparency, and data availability. © 2016 IOP Publishing Ltd.","open data; open science; reproducible research; soil science","Ecosystems; Open source software; Open systems; Soils; Cross-disciplinary; Data availability; Open datum; Open science; Reproducibilities; Reproducible research; Soil science; Statistical software; Transparency; data assimilation; experimental study; Internet; research work; software; soil ecosystem; soil science; transparency",Article,"Final",Open Access,Scopus,2-s2.0-84985911808
"Irving D.","36634371000;","A minimum standard for publishing computational results in the weather and climate sciences",2016,"Bulletin of the American Meteorological Society","97","7",,"1149","1158",,12,"10.1175/BAMS-D-15-00010.1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983498742&doi=10.1175%2fBAMS-D-15-00010.1&partnerID=40&md5=48503fa35253b57dbbbedb0740cf003e","School of Earth Sciences, University of Melbourne, Parkville, VIC  3010, Australia","Irving, D., School of Earth Sciences, University of Melbourne, Parkville, VIC  3010, Australia","Weather and climate science has undergone a computational revolution in recent decades, to the point where all modern research relies heavily on software and code. Despite this profound change in the research methods employed by weather and climate scientists, the reporting of computational results has changed very little in relevant academic journals. This lag has led to something of a reproducibility crisis, whereby it is impossible to replicate and verify most of today's published computational results. While it is tempting to simply decry the slow response of journals and funding agencies in the face of this crisis, there are very few examples of reproducible weather and climate research upon which to base new communication standards. In an attempt to address this deficiency, this essay describes a procedure for reporting computational results that was employed in a recent Journal of Climate paper. The procedure was developed to be consistent with recommended computational best practices and seeks to minimize the time burden on authors, which has been identified as the most important barrier to publishing code. It should provide a starting point for weather and climate scientists looking to publish reproducible research, and it is proposed that journals could adopt the procedure as a minimum standard. ©2016 American Meteorological Society.",,"Earth atmosphere; Meteorology; Academic journal; Climate research; Climate scientists; Communication standards; Computational results; Funding agencies; Reproducibilities; Reproducible research; Climate change",Review,"Final",Open Access,Scopus,2-s2.0-84983498742
"Hatakeyama M., Opitz L., Russo G., Qi W., Schlapbach R., Rehrauer H.","56902316200;23480204000;57205667618;8269893200;6602908115;6602545134;","SUSHI: An exquisite recipe for fully documented, reproducible and reusable NGS data analysis",2016,"BMC Bioinformatics","17","1", 228,"","",,15,"10.1186/s12859-016-1104-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971536987&doi=10.1186%2fs12859-016-1104-8&partnerID=40&md5=0693d8f34f5a0f46fc049a6727892640","ETH Zurich/University of Zurich, Functional Genomics Center Zurich, Winterthurerstrasse. 190, Zurich, 8057, Switzerland; University of Zurich, Department of Evolutionary Biology and Environmental Studies, Winterthurerstrasse. 190, Zurich, 8057, Switzerland","Hatakeyama, M., ETH Zurich/University of Zurich, Functional Genomics Center Zurich, Winterthurerstrasse. 190, Zurich, 8057, Switzerland, University of Zurich, Department of Evolutionary Biology and Environmental Studies, Winterthurerstrasse. 190, Zurich, 8057, Switzerland; Opitz, L., ETH Zurich/University of Zurich, Functional Genomics Center Zurich, Winterthurerstrasse. 190, Zurich, 8057, Switzerland; Russo, G., ETH Zurich/University of Zurich, Functional Genomics Center Zurich, Winterthurerstrasse. 190, Zurich, 8057, Switzerland; Qi, W., ETH Zurich/University of Zurich, Functional Genomics Center Zurich, Winterthurerstrasse. 190, Zurich, 8057, Switzerland; Schlapbach, R., ETH Zurich/University of Zurich, Functional Genomics Center Zurich, Winterthurerstrasse. 190, Zurich, 8057, Switzerland; Rehrauer, H., ETH Zurich/University of Zurich, Functional Genomics Center Zurich, Winterthurerstrasse. 190, Zurich, 8057, Switzerland","Background: Next generation sequencing (NGS) produces massive datasets consisting of billions of reads and up to thousands of samples. Subsequent bioinformatic analysis is typically done with the help of open source tools, where each application performs a single step towards the final result. This situation leaves the bioinformaticians with the tasks to combine the tools, manage the data files and meta-information, document the analysis, and ensure reproducibility. Results: We present SUSHI, an agile data analysis framework that relieves bioinformaticians from the administrative challenges of their data analysis. SUSHI lets users build reproducible data analysis workflows from individual applications and manages the input data, the parameters, meta-information with user-driven semantics, and the job scripts. As distinguishing features, SUSHI provides an expert command line interface as well as a convenient web interface to run bioinformatics tools. SUSHI datasets are self-contained and self-documented on the file system. This makes them fully reproducible and ready to be shared. With the associated meta-information being formatted as plain text tables, the datasets can be readily further analyzed and interpreted outside SUSHI. Conclusion: SUSHI provides an exquisite recipe for analysing NGS data. By following the SUSHI recipe, SUSHI makes data analysis straightforward and takes care of documentation and administration tasks. Thus, the user can fully dedicate his time to the analysis itself. SUSHI is suitable for use by bioinformaticians as well as life science researchers. It is targeted for, but by no means constrained to, NGS data analysis. Our SUSHI instance is in productive use and has served as data analysis interface for more than 1000 data analysis projects. SUSHI source code as well as a demo server are freely available. © 2016 Hatakeyama et al.","Data analysis framework; Meta-level system design; Reproducible research","Bioinformatics; Computer software reusability; Data handling; Open source software; Semantics; Administration tasks; Analysis frameworks; Bioinformatic analysis; Bioinformatics tools; Command line interface; Meta levels; Next-generation sequencing; Reproducible research; Information analysis; bioinformatics; biomedicine; data analysis; documentation; human; next generation sequencing; scientist; semantics; workflow; biology; evaluation study; high throughput sequencing; procedures; reproducibility; software; statistics; Computational Biology; High-Throughput Nucleotide Sequencing; Reproducibility of Results; Software; Statistics as Topic",Article,"Final",Open Access,Scopus,2-s2.0-84971536987
"Dubois J., Adolphs R.","26535724900;7006157399;","Building a Science of Individual Differences from fMRI",2016,"Trends in Cognitive Sciences","20","6",,"425","443",,144,"10.1016/j.tics.2016.03.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971224863&doi=10.1016%2fj.tics.2016.03.014&partnerID=40&md5=4ca7209dd8a525b45634af67ad905946","Division of the Humanities and Social Sciences, California Institute of Technology, Pasadena, CA  91125, United States","Dubois, J., Division of the Humanities and Social Sciences, California Institute of Technology, Pasadena, CA  91125, United States; Adolphs, R., Division of the Humanities and Social Sciences, California Institute of Technology, Pasadena, CA  91125, United States","To date, fMRI research has been concerned primarily with evincing generic principles of brain function through averaging data from multiple subjects. Given rapid developments in both hardware and analysis tools, the field is now poised to study fMRI-derived measures in individual subjects, and to relate these to psychological traits or genetic variations. We discuss issues of validity, reliability and statistical assessment that arise when the focus shifts to individual subjects and that are applicable also to other imaging modalities. We emphasize that individual assessment of neural function with fMRI presents specific challenges and necessitates careful consideration of anatomical and vascular between-subject variability as well as sources of within-subject variability. Interpretation of fMRI data at the level of individual brains is essential for characterizing brain function in health and disease.Two core challenges are validity (do we measure what we intend to measure?) and reliability (is our measure stable in the face of variations that should not matter?) of fMRI-derived individual differences; these challenges can be partly addressed with recent tools.Interpretation of single-subject fMRI measures relies on establishing a relationship with an independent measure in the same subjects. Out-of-sample prediction should be used over correlation analysis.Accumulation of large samples through consortia and data sharing, as well as careful attention to statistical power issues, are crucial for reproducible research.Whole-brain characterization in naturalistic conditions, such as while watching a movie or listening to a story, may provide an alternative to resting-state data that permits a rich link to sensory and semantic stimulus variables. © 2016 Elsevier Ltd.","BOLD fMRI; Individual differences; Neurometrics; Prediction; Reliability; Validity","Forecasting; Reliability; Semantics; BOLD fMRI; Genetic variation; Imaging modality; Individual Differences; Neurometrics; Statistical assessment; Statistical power; Validity; Functional neuroimaging; central nervous system agents; vasoactive agent; BOLD signal; brain function; brain size; echo planar imaging; electroencephalogram; functional magnetic resonance imaging; functional neuroimaging; head movement; hemodynamics; human; neurophysiology; Review; sample size; sensorimotor function; statistical parameters; topography; brain; brain mapping; diagnostic imaging; individuality; nuclear magnetic resonance imaging; procedures; reproducibility; Brain; Brain Mapping; Humans; Individuality; Magnetic Resonance Imaging; Reproducibility of Results",Review,"Final",,Scopus,2-s2.0-84971224863
"Pardos Z.A., Whyte A., Kao K.","23091281300;57072929200;56597542500;","moocRP: Enabling Open Learning Analytics with an Open Source Platform for Data Distribution, Analysis, and Visualization",2016,"Technology, Knowledge and Learning","21","1",,"75","98",,8,"10.1007/s10758-015-9268-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961285707&doi=10.1007%2fs10758-015-9268-2&partnerID=40&md5=6a0cdc81b5f32c865036adb6bf0dcf45","University of California at Berkeley, Berkeley, CA  94720, United States; University of Michigan, Ann Arbor, MI, United States","Pardos, Z.A., University of California at Berkeley, Berkeley, CA  94720, United States; Whyte, A., University of Michigan, Ann Arbor, MI, United States; Kao, K., University of California at Berkeley, Berkeley, CA  94720, United States","In this paper, we address issues of transparency, modularity, and privacy with the introduction of an open source, web-based data repository and analysis tool tailored to the Massive Open Online Course community. The tool integrates data request/authorization and distribution workflow features as well as provides a simple analytics module upload format to enable reuse and replication of analytics results among instructors and researchers. We survey the evolving landscape of competing established and emerging data models, all of which are accommodated in the platform. Data model descriptions are provided to analytics authors who choose, much like with smartphone app stores, to write for any number of data models depending on their needs and the proliferation of the particular data model. Two case study examples of analytics and responsive visualizations based on different data models are described in the paper. The result is a simple but effective approach to learning analytics immediately applicable to X consortium MOOCs and beyond. © 2016, Springer Science+Business Media Dordrecht.","Dashboards; Modularization; MOOC; Open learning analytics; Reproducible research; Visualizations","Modular construction; Visualization; Dashboards; Modularizations; MOOC; Open learning; Reproducible research; Data visualization",Article,"Final",,Scopus,2-s2.0-84961285707
"Hofner B., Schmid M., Edler L.","25627901400;55684265900;7004935604;","Reproducible research in statistics: A review and guidelines for the Biometrical Journal",2016,"Biometrical Journal","58","2",,"416","427",,11,"10.1002/bimj.201500156","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959244742&doi=10.1002%2fbimj.201500156&partnerID=40&md5=d5aa215a8028f3ec3de5b8fbb495e58e","Department of Medical Informatics, Biometry and Epidemiology, Friedrich-Alexander University, Erlangen-Nuremberg, Waldstraße 6, Erlangen, 91054, Germany; Department of Medical Biometry, Informatics and Epidemiology, University of Bonn, Sigmund-Freud-Straße 25, Bonn, 53127, Germany; Division of Biostatistics-C060, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69120, Germany","Hofner, B., Department of Medical Informatics, Biometry and Epidemiology, Friedrich-Alexander University, Erlangen-Nuremberg, Waldstraße 6, Erlangen, 91054, Germany; Schmid, M., Department of Medical Biometry, Informatics and Epidemiology, University of Bonn, Sigmund-Freud-Straße 25, Bonn, 53127, Germany; Edler, L., Division of Biostatistics-C060, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69120, Germany","Reproducible research (RR) constitutes the idea that a publication should be accompanied by all relevant material to reproduce the results and findings of a scientific work. Hence, results can be verified and researchers are able to build upon these. Efforts of the Biometrical Journal over the last five years have increased the number of manuscripts which are reproducible by a factor of 4 to almost 50%. Yet, more than half of the code submission could not be executed in the initial review due to missing code, missing data or errors in the code. Careful checks of the submitted code as part of the reviewing process are essential to eliminate these issues and to foster RR. In this article, we reviewed recent submissions of code and data to identify common reproducibility issues. Based on these findings, guidelines for structuring code submission to the Biometrical Journal have been established to help authors. These guidelines should help researchers to implement RR in general. Together with the code reviews, this supports the mission of the Biometrical Journal in publishing highest quality, novel and relevant papers on statistical methods and their applications in life sciences. Source code and data to reproduce the presented data analyses are available as Supplementary Material on the journal's web page. © 2016 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.","Biometrical Journal; Guideline; Reproducible research","biometry; documentation; practice guideline; publication; reproducibility; software; statistics; Biometry; Documentation; Guidelines as Topic; Periodicals as Topic; Reproducibility of Results; Software; Statistics as Topic",Article,"Final",,Scopus,2-s2.0-84959244742
"Iqbal S.A., Wallach J.D., Khoury M.J., Schully S.D., Ioannidis J.P.A.","57187764400;57187952700;26643049700;8839523200;35377033000;","Reproducible Research Practices and Transparency across the Biomedical Literature",2016,"PLoS Biology","14","1", e1002333,"","",,102,"10.1371/journal.pbio.1002333","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961317148&doi=10.1371%2fjournal.pbio.1002333&partnerID=40&md5=018b03bb7e83fa11e27ce38d401a54aa","Department of Epidemiology, Rollins School of Public Health, Emory University, Atlanta, GA, United States; Department of Health Research and Policy, Stanford School of Medicine, Palo Alto, CA, United States; Meta-Research Innovation Center at Stanford, Stanford University, Stanford, CA, United States; Division of Cancer Control and Population Sciences, National Cancer Institute, National Institutes of Health, Bethesda, MD, United States; Office of Public Health Genomics, Centers for Disease Control and Prevention, Atlanta, GA, United States; Stanford Prevention Research Center, Department of Medicine, Stanford University, Stanford, CA, United States; Department of Statistics, Stanford University School of Humanities and Sciences, Stanford, CA, United States","Iqbal, S.A., Department of Epidemiology, Rollins School of Public Health, Emory University, Atlanta, GA, United States; Wallach, J.D., Department of Health Research and Policy, Stanford School of Medicine, Palo Alto, CA, United States, Meta-Research Innovation Center at Stanford, Stanford University, Stanford, CA, United States; Khoury, M.J., Division of Cancer Control and Population Sciences, National Cancer Institute, National Institutes of Health, Bethesda, MD, United States, Office of Public Health Genomics, Centers for Disease Control and Prevention, Atlanta, GA, United States; Schully, S.D., Division of Cancer Control and Population Sciences, National Cancer Institute, National Institutes of Health, Bethesda, MD, United States; Ioannidis, J.P.A., Department of Health Research and Policy, Stanford School of Medicine, Palo Alto, CA, United States, Meta-Research Innovation Center at Stanford, Stanford University, Stanford, CA, United States, Stanford Prevention Research Center, Department of Medicine, Stanford University, Stanford, CA, United States, Department of Statistics, Stanford University School of Humanities and Sciences, Stanford, CA, United States","There is a growing movement to encourage reproducibility and transparency practices in the scientific community, including public access to raw data and protocols, the conduct of replication studies, systematic integration of evidence in systematic reviews, and the documentation of funding and potential conflicts of interest. In this survey, we assessed the current status of reproducibility and transparency addressing these indicators in a random sample of 441 biomedical journal articles published in 2000–2014. Only one study provided a full protocol and none made all raw data directly available. Replication studies were rare (n = 4), and only 16 studies had their data included in a subsequent systematic review or meta-analysis. The majority of studies did not mention anything about funding or conflicts of interest. The percentage of articles with no statement of conflict decreased substantially between 2000 and 2014 (94.4% in 2000 to 34.6% in 2014); the percentage of articles reporting statements of conflicts (0% in 2000, 15.4% in 2014) or no conflicts (5.6% in 2000, 50.0% in 2014) increased. Articles published in journals in the clinical medicine category versus other fields were almost twice as likely to not include any information on funding and to have private funding. This study provides baseline data to compare future progress in improving these indicators in the scientific literature. © 2016, Public Library of Science. All Rights Reserved.",,"clinical medicine; conflict of interest; controlled study; documentation; funding; human; meta analysis; random sample; replication study; reproducibility; scientific literature; systematic review; economics; medical research; publication; reproducibility; statistics and numerical data; Biomedical Research; Conflict of Interest; Periodicals as Topic; Reproducibility of Results",Article,"Final",Open Access,Scopus,2-s2.0-84961317148
"Playford C.J., Gayle V., Connelly R., Gray A.J.G.","56730845600;6507865234;55616557100;25521946600;","Administrative social science data: The challenge of reproducible research",2016,"Big Data and Society","3","2",,"","",,6,"10.1177/2053951716684143","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049753202&doi=10.1177%2f2053951716684143&partnerID=40&md5=015f9b00966f64531826369965bf3f6a","Administrative Data Research Centre – Scotland, School of Social and Political Science, University of Edinburgh, United Kingdom; Department of Sociology, University of Warwick, United Kingdom; School of Mathematical & Computer Sciences, Heriot-Watt University, United Kingdom","Playford, C.J., Administrative Data Research Centre – Scotland, School of Social and Political Science, University of Edinburgh, United Kingdom; Gayle, V., Administrative Data Research Centre – Scotland, School of Social and Political Science, University of Edinburgh, United Kingdom; Connelly, R., Department of Sociology, University of Warwick, United Kingdom; Gray, A.J.G., School of Mathematical & Computer Sciences, Heriot-Watt University, United Kingdom","Powerful new social science data resources are emerging. One particularly important source is administrative data, which were originally collected for organisational purposes but often contain information that is suitable for social science research. In this paper we outline the concept of reproducible research in relation to micro-level administrative social science data. Our central claim is that a planned and organised workflow is essential for high quality research using micro-level administrative social science data. We argue that it is essential for researchers to share research code, because code sharing enables the elements of reproducible research. First, it enables results to be duplicated and therefore allows the accuracy and validity of analyses to be evaluated. Second, it facilitates further tests of the robustness of the original piece of research. Drawing on insights from computer science and other disciplines that have been engaged in e-Research we discuss and advocate the use of Git repositories to provide a useable and effective solution to research code sharing and rendering social science research using micro-level administrative data reproducible. © The Author(s) 2016.","administrative data; Big Data; Git; replication; reproducibility; workflow",,Article,"Final",Open Access,Scopus,2-s2.0-85049753202
"Chen X., Dallmeier-Tiessen S., Dani A., Dasler R., Fernández J.D., Fokianos P., Herterich P., Šimko T.","57190963813;55496905200;56938304200;57190961692;55865569146;57190798183;55866504500;55480402200;","CERN analysis preservation: A novel digital library service to enable reusable and reproducible research",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","9819 LNCS",,,"347","356",,9,"10.1007/978-3-319-43997-6_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984838177&doi=10.1007%2f978-3-319-43997-6_27&partnerID=40&md5=9a9ef64b66882cae74ef3fc23ec0c718","CERN, Geneva, Switzerland; Alexander Technological Educational Institute of Thessaloniki, Thessaloniki, Greece; Humboldt-Universität zu Berlin, Berlin, Germany; Universidad de Oviedo, Oviedo, Spain; University of Sheffield, Sheffield, United Kingdom","Chen, X., CERN, Geneva, Switzerland, University of Sheffield, Sheffield, United Kingdom; Dallmeier-Tiessen, S., CERN, Geneva, Switzerland; Dani, A., CERN, Geneva, Switzerland, Alexander Technological Educational Institute of Thessaloniki, Thessaloniki, Greece; Dasler, R., CERN, Geneva, Switzerland; Fernández, J.D., CERN, Geneva, Switzerland, Universidad de Oviedo, Oviedo, Spain; Fokianos, P., CERN, Geneva, Switzerland; Herterich, P., CERN, Geneva, Switzerland, Humboldt-Universität zu Berlin, Berlin, Germany; Šimko, T., CERN, Geneva, Switzerland","The latest policy developments require immediate action for data preservation, as well as reproducible and Open Science. To address this, an unprecedented digital library service is presented to enable the High-Energy Physics community to preserve and share their research objects (such as data, code, documentation, notes) throughout their research process. While facing the challenges of; “big data” community, the internal service builds on existing internal databases to make the process as easy and intrinsic as possible for researchers. Given the “work in progress” nature of the objects preserved, versioning is supported. It is expected that the service will not only facilitate better preservation techniques in the community, but will foremost make collaborative research easier as detailed metadata and novel retrieval functionality provide better access to ongoing works. This new type of e-infrastructure, fully integrated into the research workflow, could help in fostering Open Science practices across disciplines. © Springer International Publishing Switzerland 2016.","Digital repository; Long-term preservation; Reproducible science; Research data; Research workflow","Big data; High energy physics; Collaborative research; Data preservations; Digital repository; Long-term preservation; Preservation techniques; Reproducible research; Reproducible science; Research data; Digital libraries",Conference Paper,"Final",Open Access,Scopus,2-s2.0-84984838177
"Krause A.","56668364300;","Reproducible research in real estate: A review and an example",2016,"Journal of Real Estate Practice and Education","19","1",,"69","85",,3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982899180&partnerID=40&md5=c97a294ae67aefe0572c72ff7ecd9b79","University of Melbourne, Parkville, VIC  3010, Australia","Krause, A., University of Melbourne, Parkville, VIC  3010, Australia","The practice of reproducible research, a central component of the burgeoning ""open science"" movement, has been thrust into the public spotlight over the past few years. In this paper, I offer an overview of reproducibility in science, review specific concerns for the real estate field, and survey the current policy regarding reproducibility among top real estate journals. Performing research reproducibly requires a change from the status quo and represents an educational issue. Toward that end, I demonstrate reproducible research via a fully documented and freely-available example of a reproducible hedonic price analysis complete with all data, code, and results hosted online.",,,Review,"Final",,Scopus,2-s2.0-84982899180
"Cao Y., Jones C., Cuevas-Vicenttín V., Jones M.B., Ludäscher B., McPhillips T., Missier P., Schwalm C., Slaughter P., Vieglais D., Walker L., Wei Y.","57190032667;57206810590;14826623900;57203774541;8902316800;35996406400;22938389700;8747205100;23986393100;6507582456;57190035016;15623656400;","DataONE: A data federation with provenance support",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","9672",,,"230","234",,6,"10.1007/978-3-319-40593-3_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976619554&doi=10.1007%2f978-3-319-40593-3_28&partnerID=40&md5=3954250d13eba10df0062ece7c61f5e2","University of Illinois, Urbana-ChampaignIL, United States; National Center for Ecological Analysis and Synthesis, UCSB, Santa Barbara, United States; Universidad Popular Autónoma del Estado de Puebla, Puebla, Mexico; School of Computing Science, Newcastle University, Newcastle upon Tyne, United Kingdom; Woods Hole Research Center, Falmouth, MA, United States; University of Kansas, Lawrence, United States; Environmental Sciences Division, ORNL, Oak Ridge, TN, United States","Cao, Y., University of Illinois, Urbana-ChampaignIL, United States; Jones, C., National Center for Ecological Analysis and Synthesis, UCSB, Santa Barbara, United States; Cuevas-Vicenttín, V., Universidad Popular Autónoma del Estado de Puebla, Puebla, Mexico; Jones, M.B., National Center for Ecological Analysis and Synthesis, UCSB, Santa Barbara, United States; Ludäscher, B., University of Illinois, Urbana-ChampaignIL, United States; McPhillips, T., University of Illinois, Urbana-ChampaignIL, United States; Missier, P., School of Computing Science, Newcastle University, Newcastle upon Tyne, United Kingdom; Schwalm, C., Woods Hole Research Center, Falmouth, MA, United States; Slaughter, P., National Center for Ecological Analysis and Synthesis, UCSB, Santa Barbara, United States; Vieglais, D., University of Kansas, Lawrence, United States; Walker, L., National Center for Ecological Analysis and Synthesis, UCSB, Santa Barbara, United States; Wei, Y., Environmental Sciences Division, ORNL, Oak Ridge, TN, United States","DataONE is a federated data network focusing on earth and environmental science data. We present the provenance and search features of DataONE by means of an example involving three earth scientists who interact through a DataONE Member Node. DataONE provenance systems enable reproducible research and facilitate proper attribution of scientific results transitively across generations of derived data products. © Springer International Publishing Switzerland 2016.",,"Computer science; Computers; Data federation; Data network; Derived data; Environmental science data; Reproducible research; Scientific results; Artificial intelligence",Conference Paper,"Final",,Scopus,2-s2.0-84976619554
"Gymrek M., Farjoun Y.","35183061200;55981835300;","Recommendations for open data science",2016,"GigaScience","5","1", 22,"","",,7,"10.1186/s13742-016-0127-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006230929&doi=10.1186%2fs13742-016-0127-4&partnerID=40&md5=f8f3e3a57e8f3ba9b7b892d76de65f66","Program in Medical and Population Genetics, Broad Institute of MIT and Harvard, Cambridge, MA, United States; Analytic and Translational Genetics Unit, Massachusetts General Hospital, Boston, MA, United States; Data Science and Data Engineering, Broad Institute of MIT and Harvard, Cambridge, MA, United States","Gymrek, M., Program in Medical and Population Genetics, Broad Institute of MIT and Harvard, Cambridge, MA, United States, Analytic and Translational Genetics Unit, Massachusetts General Hospital, Boston, MA, United States; Farjoun, Y., Data Science and Data Engineering, Broad Institute of MIT and Harvard, Cambridge, MA, United States","Life science research increasingly relies on large-scale computational analyses. However, the code and data used for these analyses are often lacking in publications. To maximize scientific impact, reproducibility, and reuse, it is crucial that these resources are made publicly available and are fully transparent. We provide recommendations for improving the openness of data-driven studies in life sciences. © 2016 Gymrek and Farjoun.","Best practices; Open science; Reproducible research","access to information; data analysis; data base; data processing; information; mathematical computing; medical research; Note; open data; priority journal; publication; reproducibility; standard; biology; biomedicine; human; information dissemination; open access publishing; practice guideline; procedures; Biological Science Disciplines; Computational Biology; Guidelines as Topic; Humans; Information Dissemination; Open Access Publishing; Reproducibility of Results",Note,"Final",Open Access,Scopus,2-s2.0-85006230929
"Pröll S., Mayer R., Rauber A.","55882154000;23397787500;57074846700;","Reproducible database queries in privacy sensitive applications",2016,"IFAC-PapersOnLine","28","1",,"113","114",,,"10.1016/j.ifacol.2015.05.202","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954126126&doi=10.1016%2fj.ifacol.2015.05.202&partnerID=40&md5=cd4ea49cb8f0e8fface9b326be964024","SBA-Research, Vienna, Austria; Institute of Software Technology and Interactive Systems, Vienna University of Technology, Austria","Pröll, S., SBA-Research, Vienna, Austria; Mayer, R., SBA-Research, Vienna, Austria; Rauber, A., Institute of Software Technology and Interactive Systems, Vienna University of Technology, Austria","Research databases are an important building block in eScience and computational science investigations. For enabling reproducible research, an approach is needed which supports the identification and citation of the exact data (sub)sets utilized in experiments. While this itself is a challenge, in many cases the data stored in databases is sensitive and needs to be protected. Due to the increasing complexity of eScience investigations, data is often integrated from different sources, potentially stemming from competing data owners. In order to achieve the research goals, the data needs to be combined and analysed as a whole. As data owners of such sources may have potential conflicts of interest in certain aspects, a mechanism is needed which prevents the retrieval and or recombination of privacy related data while still full access to own data must be granted at all times. © 2015, IFAC (International Federation of Automatic Control) Hosting by Elsevier Ltd. All rights reserved.","Data handling systems; Data privacy; Data sets; Relational databases; Reproducibility","Data handling; Query languages; Computational science; Data handling systems; Data sets; Potential conflict; Relational Database; Reproducibilities; Reproducible research; Sensitive application; Data privacy",Conference Paper,"Final",Open Access,Scopus,2-s2.0-84954126126
"Cassidy S.","56795000800;","The alveo virtual lab: Working with an API for linguistic data (invited tutorial)",2016,"Communications in Computer and Information Science","588",,,"XIX","XX",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964063202&partnerID=40&md5=cbde0c80c40e7d2ed92c9e93f8b9d2d8","Department of Computing, Macquarie University, Sydney, Australia","Cassidy, S., Department of Computing, Macquarie University, Sydney, Australia","Alveo is a new Virtual Laboratory to support research on Human Communication Science. It provides a repository for language and communication data and an API that provides an interface for tools to work on the data. Some of the goals of the project are to provide a home for data sharing, to make new tools available to researchers in a range of disciplines and to support reproducible research by capturing repeatable workflows for data analysis. This tutorial will describe the main features of the platform and give students the opportunity to work with the API and explore the data holdings in the repository. © Springer International Publishing Switzerland 2016.","Corpora; Language processing; Repository; Workflow","Application programming interfaces (API); Data handling; Linguistics; Virtual reality; Communication data; Corpora; Human communications; Language processing; Repository; Reproducible research; Virtual laboratories; Workflow; Computational linguistics",Conference Paper,"Final",,Scopus,2-s2.0-84964063202
"Kutyniok G., Lim W.-Q., Reisenhofer R.","6603116420;8213109400;57016735000;","ShearLab 3D: Faithful digital shearlet transforms based on compactly supported shearlets",2016,"ACM Transactions on Mathematical Software","42","1", 5,"","",,58,"10.1145/2740960","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975918311&doi=10.1145%2f2740960&partnerID=40&md5=d72373f1a3f75dd929528476e5be38d8","Department of Mathematics, Technische Universität Berlin, Berlin, 10623, Germany; Fraunhofer Institute for Telecommunications, Heinrich Hertz Institute, Berlin, 10587, Germany; Universität Bremen, Fachbereich 3, Bremen, 28334, Germany","Kutyniok, G., Department of Mathematics, Technische Universität Berlin, Berlin, 10623, Germany; Lim, W.-Q., Fraunhofer Institute for Telecommunications, Heinrich Hertz Institute, Berlin, 10587, Germany; Reisenhofer, R., Universität Bremen, Fachbereich 3, Bremen, 28334, Germany","Wavelets and their associated transforms are highly efficient when approximating and analyzing onedimensional signals. However, multivariate signals such as images or videos typically exhibit curvilinear singularities, which wavelets are provably deficient in sparsely approximating and also in analyzing in the sense of, for instance, detecting their direction. Shearlets are a directional representation system extending the wavelet framework, which overcomes those deficiencies. Similar to wavelets, shearlets allow a faithful implementation and fast associated transforms. In this article, we will introduce a comprehensive carefully documented software package coined ShearLab 3D (www.ShearLab.org) and discuss its algorithmic details. This package provides MATLAB code for a novel faithful algorithmic realization of the 2D and 3D shearlet transform (and their inverses) associated with compactly supported universal shearlet systems incorporating the option of using CUDA. We will present extensive numerical experiments in 2D and 3D concerning denoising, inpainting, and feature extraction, comparing the performance of ShearLab 3D with similar transform-based algorithms such as curvelets, contourlets, or surfacelets. In the spirit of reproducible research, all scripts are accessible on www.ShearLab.org. © 2016 ACM.","Imaging sciences; Shearlets; Software package; Wavelets","MATLAB; Software packages; Algorithmic realization; Curvilinear singularity; Digital shearlet transforms; Multivariate signals; Numerical experiments; Reproducible research; Shearlets; Wavelets; Wavelet transforms",Article,"Final",,Scopus,2-s2.0-84975918311
"Plummer A.R., Beckman M.E.","36742465100;35902578600;","Sharing speech synthesis software for research and education within low-tech and low-resource communities",2016,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","08-12-September-2016",,,"1618","1622",,1,"10.21437/Interspeech.2016-1540","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994311178&doi=10.21437%2fInterspeech.2016-1540&partnerID=40&md5=bd684e3787f38bd11f35622b021196b4","Dept. of Computer Science and Engineering, Ohio State University, United States; Dept. of Linguistics, Ohio State University, United States","Plummer, A.R., Dept. of Computer Science and Engineering, Ohio State University, United States; Beckman, M.E., Dept. of Linguistics, Ohio State University, United States","Parametric speech synthesis has played an integral role in speech research since the 1950s. However, software sharing is unwieldy, making replication of experiments difficult, creating obstacles to communication between laboratories, and hindering entry into research. This paper describes our use of the Speech Recognition Virtual Kitchen environment (www.speechkitchen.org) to develop an infrastructure for sharing synthesis software for research and education. We tested the infrastructure by using it in teaching a seminar on ""the speech science of speech synthesis"" to students from several of the graduate programs in linguistics at the Ohio State University. Using the virtual machines that we developed for Klatt's formant synthesis program and Kawahara's STRAIGHT speech analysis, modification, and synthesis system enabled the students to advance much further in their understanding of the basic principles underlying these acoustic-domain models by comparison to the students enrolled in a similar seminar that we taught previously without the virtual machines. At the same time, implementing these and two other virtual machines for the course did not live up to our expectations for the course, in ways that highlight the need to adapt both the Speech Kitchen environment and the synthesis software systems to the needs of low-tech, low-resource users. Copyright © 2016 ISCA.","Reproducible research tools; Sharable educational software; Speech synthesis","Education; Education computing; Speech; Speech communication; Speech processing; Speech synthesis; Students; Teaching; Network security; Speech recognition; Basic principles; Educational software; Formant synthesis; Ohio State University; Reproducible research; Sharing synthesis; Software sharing; Virtual machines; Speech recognition; Speech communication",Conference Paper,"Final",,Scopus,2-s2.0-84994311178
"Metze F., Riebling E., Warlaumont A.S., Bergelson E.","6505996325;56414704800;23096778100;26323118600;","Virtual machines and containers as a platform for experimentation",2016,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","08-12-September-2016",,,"1603","1607",,2,"10.21437/Interspeech.2016-997","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994339219&doi=10.21437%2fInterspeech.2016-997&partnerID=40&md5=5fe067cf8865145c410fc3dfc7a4f8d1","Language Technologies Institute, Carnegie Mellon University, United States; Cognitive and Information Sciences, University of California, Merced, United States; Center for Language Sciences, University of Rochester, United States; Psychology and Neuroscience Department, Duke University, United States","Metze, F., Language Technologies Institute, Carnegie Mellon University, United States; Riebling, E., Language Technologies Institute, Carnegie Mellon University, United States; Warlaumont, A.S., Cognitive and Information Sciences, University of California, Merced, United States; Bergelson, E., Center for Language Sciences, University of Rochester, United States, Psychology and Neuroscience Department, Duke University, United States","Research on computational speech processing has traditionally relied on the availability of a relatively large and complex infrastructure, which encompasses data (text and audio), tools (feature extraction, model training, scoring, possibly on-line and off-line, etc.), glue code, and computing. Traditionally, it has been very hard to move experiments from one site to another, and to replicate experiments. With the increasing availability of shared platforms such as commercial cloud computing platforms or publicly funded super-computing centers, there is a need and an opportunity to abstract the experimental environment from the hardware, and distribute complete setups as a virtual machine, a container, or some other shareable resource, that can be deployed and worked with anywhere. In this paper, we discuss our experience with this concept and present some tools that the community might find useful. We outline, as a case study, how such tools can be applied to a naturalistic language acquisition audio corpus. Copyright © 2016 ISCA.","Citizen science; Cloud computing; Reproducible research; Shared platforms; Speech processing","Abstracting; Containers; Feature extraction; Java programming language; Speech communication; Speech processing; Network security; Citizen science; Cloud computing platforms; Complex infrastructures; Experimental environment; Language acquisition; Reproducible research; Shared platforms; Virtual machines; Cloud computing",Conference Paper,"Final",,Scopus,2-s2.0-84994339219
"Russo F., Righelli D., Angelini C.","56355347800;57148428100;35965781000;","Advancements in RNASeqGUI towards a Reproducible Analysis of RNA-Seq Experiments",2016,"BioMed Research International","2016",, 7972351,"","",,5,"10.1155/2016/7972351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959432943&doi=10.1155%2f2016%2f7972351&partnerID=40&md5=777adb490c457d50f27228ce1c4936bc","Istituto per le Applicazioni del Calcolo, CNR, Napoli, 80131, Italy","Russo, F., Istituto per le Applicazioni del Calcolo, CNR, Napoli, 80131, Italy; Righelli, D., Istituto per le Applicazioni del Calcolo, CNR, Napoli, 80131, Italy; Angelini, C., Istituto per le Applicazioni del Calcolo, CNR, Napoli, 80131, Italy","We present the advancements and novelties recently introduced in RNASeqGUI, a graphical user interface that helps biologists to handle and analyse large data collected in RNA-Seq experiments. This work focuses on the concept of reproducible research and shows how it has been incorporated in RNASeqGUI to provide reproducible (computational) results. The novel version of RNASeqGUI combines graphical interfaces with tools for reproducible research, such as literate statistical programming, human readable report, parallel executions, caching, and interactive and web-explorable tables of results. These features allow the user to analyse big datasets in a fast, efficient, and reproducible way. Moreover, this paper represents a proof of concept, showing a simple way to develop computational tools for Life Science in the spirit of reproducible research. Copyright © 2016 Francesco Russo et al.",,"biomedicine; human; biology; computer interface; genetics; Internet; procedures; sequence analysis; software; RNA; Computational Biology; Humans; Internet; RNA; Sequence Analysis, RNA; Software; User-Computer Interface",Article,"Final",Open Access,Scopus,2-s2.0-84959432943
"Honaas L.A., Altman N.S., Krzywinski M.","6504270757;55842734300;6602162335;","Study design for sequencing studies",2016,"Methods in Molecular Biology","1418",,,"39","66",,1,"10.1007/978-1-4939-3578-9_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961629677&doi=10.1007%2f978-1-4939-3578-9_3&partnerID=40&md5=c375548e172dc3bba05cf996bc361072",,"Honaas, L.A.; Altman, N.S.; Krzywinski, M.","Once a biochemical method has been devised to sample RNA or DNA of interest, sequencing can be used to identify the sampled molecules with high fidelity and low bias. High-throughput sequencing has therefore become the primary data acquisition method for many genomics studies and is being used more and more to address molecular biology questions. By applying principles of statistical experimental design, sequencing experiments can be made more sensitive to the effects under study as well as more biologically sound, hence more replicable. © Springer Science+Business Media New York 2016.","Block design; Multiplexing; Pilot study; Pooling; Precision; Randomization; Replication; Reproducible research; Sample size; Sequencing depth","DNA extraction; gene expression; genomics; genotype; high throughput sequencing; human; information processing; molecular biology; next generation sequencing; nonhuman; RNA extraction; RNA sequence; animal; DNA sequence; methodology; procedures; sequence analysis; standards; Animals; High-Throughput Nucleotide Sequencing; Humans; Research Design; Sequence Analysis; Sequence Analysis, DNA; Sequence Analysis, RNA",Book Chapter,"Final",,Scopus,2-s2.0-84961629677
"Monajemi H., Donoho D.L., Stodden V.","55568759900;7006144847;15623425400;","Making massive computational experiments painless",2016,"Proceedings - 2016 IEEE International Conference on Big Data, Big Data 2016",,, 7840870,"2368","2373",,7,"10.1109/BigData.2016.7840870","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015233713&doi=10.1109%2fBigData.2016.7840870&partnerID=40&md5=5b8c747ca4f4d58589266d21957fb827","Department of Statistics, Stanford University, Stanford, CA  94305, United States; School of Information Sciences, University of Illinois at Urbana-Champaign, Champaign, IL  61801, United States","Monajemi, H., Department of Statistics, Stanford University, Stanford, CA  94305, United States; Donoho, D.L., Department of Statistics, Stanford University, Stanford, CA  94305, United States; Stodden, V., School of Information Sciences, University of Illinois at Urbana-Champaign, Champaign, IL  61801, United States","The increasing availability of access to large-scale computing clusters -for example via the cloud -is changing the way scientific research can be conducted, enabling experiments of a scale and scope that would have been inconceivable several years ago. An ambitious data scientist today can carry out projects involving several million CPU hours. In the near future, we anticipate a typical Ph.D. in computational science may be expected or even required to offer findings based on at least 1 million CPU hours of computations. The massive scale of these soon-to-be-upon-us computational experiments demands that we change how we organize our experimental practices. Traditionally, and still the dominant paradigm today, the end-to-end process of experiment design and execution involves a significant amount of manual intervention and situational tweaking, cutting and pasting, and the use of disparate disconnected tools, much of which is undocumented and easily lost. This makes it difficult to detect and understand possible failure points in the computational workflow, making it virtually impossible to correct, let alone simply rerun the experiment. This is an amazing state of affairs, considering the ubiquity of error in scientific computation and in research generally. Following such unstructured and undocumented research practices limits the ability of the researcher to exploit cluster and cloud-based paradigms, as each increase in scale under the dominant paradigm is likely to lead to ever more errors and misunderstandings. A better paradigm will integrate the design of large experiments seamlessly with job management, output harvesting, data analysis, reporting, and publication of code and data. In particular such a paradigm would submerge the details of all the processing, harvesting, and management while exposing transparently the description of the discovery process itself, including details such as the parameter space exploration. Reproducing any job would be a push-button affair, and creating a new experiment from a previous one might involve only changes of a line or two of code followed again by push-button execution and reporting. Even though such experiments would be operating at a much greater scale than today, under such a paradigm they would be easier to conduct, obtain a lower error rate, and offer a much greater opportunity for 'outsiders' to understand the results. In this article, we discuss the challenges of massive computational experimentation and present a taxonomy of some of the desiderata which such paradigms should offer. We then present ClusterJob (CJ), an efficient computing environment that we and other researchers have used to conduct and share million-CPU-hour experiments in a painless and reproducible way. © 2016 IEEE.","Big Data; High-throughput Computing; Reproducible Research","Cutting tools; Errors; Information management; Space research; Computational experiment; Computing environments; High-throughput computing; Large-scale computing; Parameter space explorations; Reproducible research; Scientific computation; Scientific researches; Big data",Conference Paper,"Final",,Scopus,2-s2.0-85015233713
"Sochat V.V., Eisenberg I.W., Enkavi A.Z., Li J., Bissett P.G., Poldrack R.A.","56145621000;55680915400;56469632300;57189689994;33267481200;7004739390;","The experiment factory: Standardizing behavioral experiments",2016,"Frontiers in Psychology","7","APR", 610,"","",,16,"10.3389/fpsyg.2016.00610","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974603456&doi=10.3389%2ffpsyg.2016.00610&partnerID=40&md5=efcef1ab1f27e8cf0dde58d864eef0be","Stanford University, Stanford, CA, United States; Department of Psychology, Stanford University, Stanford, CA, United States","Sochat, V.V., Stanford University, Stanford, CA, United States, Department of Psychology, Stanford University, Stanford, CA, United States; Eisenberg, I.W., Department of Psychology, Stanford University, Stanford, CA, United States; Enkavi, A.Z., Department of Psychology, Stanford University, Stanford, CA, United States; Li, J., Department of Psychology, Stanford University, Stanford, CA, United States; Bissett, P.G., Department of Psychology, Stanford University, Stanford, CA, United States; Poldrack, R.A., Department of Psychology, Stanford University, Stanford, CA, United States","The administration of behavioral and experimental paradigms for psychology research is hindered by lack of a coordinated effort to develop and deploy standardized paradigms. While several frameworks (Mason and Suri, 2011; McDonnell et al., 2012; de Leeuw, 2015; Lange et al., 2015) have provided infrastructure and methods for individual research groups to develop paradigms, missing is a coordinated effort to develop paradigms linked with a system to easily deploy them. This disorganization leads to redundancy in development, divergent implementations of conceptually identical tasks, disorganized and error-prone code lacking documentation, and difficulty in replication. The ongoing reproducibility crisis in psychology and neuroscience research (Baker, 2015; Open Science Collaboration, 2015) highlights the urgency of this challenge: Reproducible research in behavioral psychology is conditional on deployment of equivalent experiments. A large, accessible repository of experiments for researchers to develop collaboratively is most efficiently accomplished through an open source framework. Here we present the Experiment Factory, an open source framework for the development and deployment of web-based experiments. The modular infrastructure includes experiments, virtual machines for local or cloud deployment, and an application to drive these components and provide developers with functions and tools for further extension. We release this infrastructure with a deployment (http://www.expfactory.org) that researchers are currently using to run a set of over 80 standardized web-based experiments on Amazon Mechanical Turk. By providing open source tools for both deployment and development, this novel infrastructure holds promise to bring reproducibility to the administration of experiments, and accelerate scientific progress by providing a shared community resource of psychological paradigms. © 2016 Sochat, Eisenberg, Enkavi, Li, Bissett and Poldrack.","Assessment; Behavior; Docker; Experiments; Reproducibility; Web-experiments",,Article,"Final",Open Access,Scopus,2-s2.0-84974603456
"Sahoo S.S., Valdez J., Rueschman M.","9735293400;57190257137;54409453700;","Scientific Reproducibility in Biomedical Research: Provenance Metadata Ontology for Semantic Annotation of Study Description",2016,"AMIA ... Annual Symposium proceedings. AMIA Symposium","2016",,,"1070","1079",,3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995893655&partnerID=40&md5=e7cf474e4b0e41969de69827b7ee9603","Department of Medicine, Brigham and Women's Hospital and Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Department of Medicine, Brigham and Women's Hospital and Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States","Sahoo, S.S., Department of Medicine, Brigham and Women's Hospital and Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Valdez, J., Department of Medicine, Brigham and Women's Hospital and Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Rueschman, M., Department of Medicine, Brigham and Women's Hospital and Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States","Scientific reproducibility is key to scientific progress as it allows the research community to build on validated results, protect patients from potentially harmful trial drugs derived from incorrect results, and reduce wastage of valuable resources. The National Institutes of Health (NIH) recently published a systematic guideline titled ""Rigor and Reproducibility "" for supporting reproducible research studies, which has also been accepted by several scientific journals. These journals will require published articles to conform to these new guidelines. Provenance metadata describes the history or origin of data and it has been long used in computer science to capture metadata information for ensuring data quality and supporting scientific reproducibility. In this paper, we describe the development of Provenance for Clinical and healthcare Research (ProvCaRe) framework together with a provenance ontology to support scientific reproducibility by formally modeling a core set of data elements representing details of research study. We extend the PROV Ontology (PROV-O), which has been recommended as the provenance representation model by World Wide Web Consortium (W3C), to represent both: (a) data provenance, and (b) process provenance. We use 124 study variables from 6 clinical research studies from the National Sleep Research Resource (NSRR) to evaluate the coverage of the provenance ontology. NSRR is the largest repository of NIH-funded sleep datasets with 50,000 studies from 36,000 participants. The provenance ontology reuses ontology concepts from existing biomedical ontologies, for example the Systematized Nomenclature of Medicine Clinical Terms (SNOMED CT), to model the provenance information of research studies. The ProvCaRe framework is being developed as part of the Big Data to Knowledge (BD2K) data provenance project.",,"biological ontology; data base; human; medical research; metadata; national health organization; reproducibility; semantics; sleep; sleep disorder; standards; United States; Biological Ontologies; Biomedical Research; Databases as Topic; Humans; Metadata; National Institutes of Health (U.S.); Reproducibility of Results; Semantics; Sleep; Sleep Wake Disorders; United States",Article,"Final",,Scopus,2-s2.0-84995893655
"Heistermann M., Collis S., Dixon M.J., Helmus J.J., Henja A., Michelson D.B., Pfaff T.","30467702000;36342344200;14019285600;56940594600;6506548660;56265877500;57157138600;","An open virtual machine for cross-platform weather radar science",2015,"Bulletin of the American Meteorological Society","96","10",,"1641","1645",,2,"10.1175/BAMS-D-14-00220.1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946100241&doi=10.1175%2fBAMS-D-14-00220.1&partnerID=40&md5=45c391610f4044939494709785a71ce9","University of Potsdam, Institute of Earth and Environmental Sciences, Potsdam, Germany; Argonne National Laboratory, Argonne, IL, United States; National Center for Atmospheric Research (NCAR), Boulder, CO, United States; HENJAB, Växjö, Sweden; Swedish Meteorological and Hydrological Institute, Norrköping, Sweden; Blue Yonder, Karlsruhe, Germany","Heistermann, M., University of Potsdam, Institute of Earth and Environmental Sciences, Potsdam, Germany; Collis, S., Argonne National Laboratory, Argonne, IL, United States; Dixon, M.J., National Center for Atmospheric Research (NCAR), Boulder, CO, United States; Helmus, J.J., Argonne National Laboratory, Argonne, IL, United States; Henja, A., HENJAB, Växjö, Sweden; Michelson, D.B., Swedish Meteorological and Hydrological Institute, Norrköping, Sweden; Pfaff, T., Blue Yonder, Karlsruhe, Germany","A community-based Open Source Software (OSS) could foster scientific progress in weather radar research. More specifically, it could make weather radar software more affordable, more flexible, more transparent, more sustainable, and more interoperable. a virtual machine (VM) is a software implementation of a machine that executes programs just as a physical machine would virtual appliance is a preconfigured virtual machine image, ready to run on any computer and any operating system that provides the required software. From a research perspective, the VM is an ideal environment to compare the performance of different algorithms from different software packages in bench marking experiments. The VM could be a useful component in achieving reproducible weather radar research, as it provides an open and fully reproducible environment across platforms. It should be noted, though, that achieving reproducible research not only requires open and reproducible software platforms, but also open access to raw data that were used in corresponding studies along with openly and completely documented algorithms.",,"Computer operating systems; Meteorological radar; Open systems; Radar; Software engineering; Community-based; Cross-platform; Reproducible research; Scientific progress; Software implementation; Software platforms; Virtual appliance; Virtual machines; Open source software",Article,"Final",,Scopus,2-s2.0-84946100241
"Hill D.R.C.","34769599500;","Parallel Random Numbers, Simulation, and Reproducible Research",2015,"Computing in Science and Engineering","17","4", 7131416,"66","71",,5,"10.1109/MCSE.2015.79","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934282578&doi=10.1109%2fMCSE.2015.79&partnerID=40&md5=7164a3c3701334ff831a674d9210ae4c","Clermont University, Blaise Pascal University, France","Hill, D.R.C., Clermont University, Blaise Pascal University, France","Parallel and distributed simulation is an area with extensive research into effective solutions. In the context of parallel stochastic simulations, it's important to know the right techniques for generating parallel pseudorandom numbers. In addition, it's possible and necessary for anyone wishing to produce a scientific work of quality to pay attention to numerical reproducibility of simulation results. Significant differences are observed in the results of parallel stochastic simulations if practitioners fail to apply best practices. By implementing a rigorous method, it's possible to reproduce the same numerical results for parallel stochastic simulations and to check them with their sequential counterpart. © 1999-2011 IEEE.","high-performance computing; parallel random numbers; reproducibility; scientific computing; stochastic simulation","Natural sciences computing; Numerical methods; Random number generation; Stochastic models; Effective solution; High performance computing; Parallel and distributed simulation; Pseudo-random numbers; Random Numbers; Reproducibilities; Reproducible research; Stochastic simulations; Stochastic systems",Article,"Final",,Scopus,2-s2.0-84934282578
"Meng H., Kommineni R., Pham Q., Gardner R., Malik T., Thain D.","56673480600;55615648000;23091602300;7401523694;7005177091;8900976600;","An invariant framework for conducting reproducible computational science",2015,"Journal of Computational Science","9",,,"137","142",,12,"10.1016/j.jocs.2015.04.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930635950&doi=10.1016%2fj.jocs.2015.04.012&partnerID=40&md5=a4ec05d97e641e5f479fd11518a5e944","Computation Institute, University of Chicago, Chicago, IL, United States; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, United States","Meng, H., Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, United States; Kommineni, R., Computation Institute, University of Chicago, Chicago, IL, United States; Pham, Q., Computation Institute, University of Chicago, Chicago, IL, United States; Gardner, R., Computation Institute, University of Chicago, Chicago, IL, United States; Malik, T., Computation Institute, University of Chicago, Chicago, IL, United States; Thain, D., Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, United States","Computational reproducibility depends on the ability to not only isolate necessary and sufficient computational artifacts but also to preserve those artifacts for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that result over time-all of which conspire to break the reproducibility of an application. Sandboxing is a technique that has been used extensively in OS environments in order to isolate computational artifacts. Several tools were proposed recently that employ sandboxing as a mechanism to ensure reproducibility. However, none of these tools preserve the sandboxed application for re-distribution to a larger scientific community aspects that are equally crucial for ensuring reproducibility as sandboxing itself. In this paper, we describe a framework of combined sandboxing and preservation, which is not only efficient and invariant, but also practical for large-scale reproducibility. We present case studies of complex high-energy physics applications and show how the framework can be useful for sandboxing, preserving, and distributing applications. We report on the completeness, performance, and efficiency of the framework, and suggest possible standardization approaches. © 2015 Elsevier B.V.","Container; Preservation framework; Reproducible research; Virtualization","Containers; High energy physics; Computational reproducibility; Computational science; Re-distribution; Reproducibilities; Reproducible research; Resource distribution; Scientific community; Virtualizations; Application programs",Article,"Final",,Scopus,2-s2.0-84930635950
"Masca N.G.D., Hensor E.M.A., Cornelius V.R., Buffa F.M., Marriott H.M., Eales J.M., Messenger M.P., Anderson A.E., Boot C., Bunce C., Goldin R.D., Harris J., Hinchliffe R.F., Junaid H., Kingston S., Martin-Ruiz C., Nelson C.P., Peacock J., Seed P.T., Shinkins B., Staples K.J., Toombs J., Wright A.K.A., Dawn Teare M.","36615441600;8099170300;6603318530;7004195101;10539634500;25027164800;36770624500;56309820000;56673894500;7005268305;35242224200;55474575800;7006330918;56674682200;56673932600;6701718262;57199851850;35548124700;57200763137;55220166800;6701613987;14029427000;57206860183;8980946300;","RIPOSTE: A framework for improving the design and analysis of laboratory-based research",2015,"eLife","4","MAY",,"1","45",,17,"10.7554/eLife.05519","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930619829&doi=10.7554%2feLife.05519&partnerID=40&md5=2170cc9f474f3654feb919406790a14a","Cardiovascular Biomedical Research Unit, University of Leicester, Leicester, United Kingdom; Leeds Institute of Rheumatic and Musculoskeletal Medicine, University of Leeds and NIHR Leeds Musculoskeletal Biomedical Research Unit, Leeds, United Kingdom; Department of Primary Care and Public Health Sciences, King’s College London, United Kingdom; Applied Computational Genomics, University of Oxford, Oxford, United Kingdom; Department of Infection and Immunity and The Florey Institute, University of Sheffield, Sheffield, United Kingdom; Department of Cardiovascular Sciences, University of Leicester, Leicester, United Kingdom; NIHR Diagnostic Evidence Co-Operative Leeds, Leeds Teaching Hospitals NHS Trust, Leeds, United Kingdom; Musculoskeletal Research Group, Institute of Cellular Medicine, University of Newcastle, Newcastle, United Kingdom; Newcastle Hospitals NHS Trust, Newcastle, United Kingdom; NIHR Biomedical Research Centre at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, United Kingdom; London School of Hygiene and Tropical Medicine, London, United Kingdom; Centre for Pathology, Imperial College, London, United Kingdom; Clinical Trials and Evaluation Unit, School of Clinical Sciences, University of Bristol, Bristol, United Kingdom; Department of Paediatric Haematology, Sheffield Children's NHS Foundation Trust, Western Bank, Sheffield, United Kingdom; Royal London Hospital, London, United Kingdom; Royal Brompton and Harefield NHS Trust, London, United Kingdom; Institute for Ageing and Health, Newcastle University, Newcastle, United Kingdom; Department of Cardiovascular Sciences, University of Leicester and National Institute for Health Research Leicester Cardiovascular Biomedical Research Unit, Leicester, United Kingdom; Division of Health and Social Care Research, King’s College London, NIHR Biomedical Research Centre at Guy’s and St Thomas’ NHS Foundation Trust and King's College London, United Kingdom; Division of Women’s Health, King’s College London, London, United Kingdom; Nuffield Department of Primary Care Health Sciences, University of Oxford, Oxford, United Kingdom; Academic Unit of Clinical and Experimental Sciences, University of Southampton and NIHR Southampton Respiratory Biomedical Research Unit, Southampton General Hospital, Southampton, United Kingdom; Department of Molecular Neuroscience, Institute of Neurology, University College London, London, United Kingdom; Institute of Lung Health, Respiratory Biomedical Unit, University Hospitals of Leicester NHS Trust, Leicestershire, United Kingdom; Sheffield School of Health and Related Research, University of Sheffield, Sheffield, United Kingdom","Masca, N.G.D., Cardiovascular Biomedical Research Unit, University of Leicester, Leicester, United Kingdom; Hensor, E.M.A., Leeds Institute of Rheumatic and Musculoskeletal Medicine, University of Leeds and NIHR Leeds Musculoskeletal Biomedical Research Unit, Leeds, United Kingdom; Cornelius, V.R., Department of Primary Care and Public Health Sciences, King’s College London, United Kingdom; Buffa, F.M., Applied Computational Genomics, University of Oxford, Oxford, United Kingdom; Marriott, H.M., Department of Infection and Immunity and The Florey Institute, University of Sheffield, Sheffield, United Kingdom; Eales, J.M., Department of Cardiovascular Sciences, University of Leicester, Leicester, United Kingdom; Messenger, M.P., NIHR Diagnostic Evidence Co-Operative Leeds, Leeds Teaching Hospitals NHS Trust, Leeds, United Kingdom; Anderson, A.E., Musculoskeletal Research Group, Institute of Cellular Medicine, University of Newcastle, Newcastle, United Kingdom; Boot, C., Newcastle Hospitals NHS Trust, Newcastle, United Kingdom; Bunce, C., NIHR Biomedical Research Centre at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, United Kingdom, London School of Hygiene and Tropical Medicine, London, United Kingdom; Goldin, R.D., Centre for Pathology, Imperial College, London, United Kingdom; Harris, J., Clinical Trials and Evaluation Unit, School of Clinical Sciences, University of Bristol, Bristol, United Kingdom; Hinchliffe, R.F., Department of Paediatric Haematology, Sheffield Children's NHS Foundation Trust, Western Bank, Sheffield, United Kingdom; Junaid, H., Royal London Hospital, London, United Kingdom; Kingston, S., Royal Brompton and Harefield NHS Trust, London, United Kingdom; Martin-Ruiz, C., Institute for Ageing and Health, Newcastle University, Newcastle, United Kingdom; Nelson, C.P., Department of Cardiovascular Sciences, University of Leicester and National Institute for Health Research Leicester Cardiovascular Biomedical Research Unit, Leicester, United Kingdom; Peacock, J., Division of Health and Social Care Research, King’s College London, NIHR Biomedical Research Centre at Guy’s and St Thomas’ NHS Foundation Trust and King's College London, United Kingdom; Seed, P.T., Division of Women’s Health, King’s College London, London, United Kingdom; Shinkins, B., Nuffield Department of Primary Care Health Sciences, University of Oxford, Oxford, United Kingdom; Staples, K.J., Academic Unit of Clinical and Experimental Sciences, University of Southampton and NIHR Southampton Respiratory Biomedical Research Unit, Southampton General Hospital, Southampton, United Kingdom; Toombs, J., Department of Molecular Neuroscience, Institute of Neurology, University College London, London, United Kingdom; Wright, A.K.A., Institute of Lung Health, Respiratory Biomedical Unit, University Hospitals of Leicester NHS Trust, Leicestershire, United Kingdom; Dawn Teare, M., Sheffield School of Health and Related Research, University of Sheffield, Sheffield, United Kingdom","Lack of reproducibility is an ongoing problem in some areas of the biomedical sciences. Poor experimental design and a failure to engage with experienced statisticians at key stages in the design and analysis of experiments are two factors that contribute to this problem. The RIPOSTE (Reducing IrreProducibility in labOratory STudiEs) framework has been developed to support early and regular discussions between scientists and statisticians in order to improve the design, conduct and analysis of laboratory studies and, therefore, reduce irreproducibility. This framework is intended for use during the early stages of a research project, when specific questions or hypotheses are proposed. The essential points within the framework are explained and illustrated using three examples (a medical equipment test, a macrophage study and a gene expression study). Sound study design minimises the possibility of bias being introduced into experiments and leads to higher quality research with more reproducible results. © 2015, eLife Sciences Publications Ltd. All rights reserved.","Experimental design; Interdisciplinary research; Reproducible research; Statistical design","Article; comparative study; conceptual framework; decision making; experimental design; gene expression; good laboratory practice; hypothesis; laboratory based research; logistic regression analysis; macrophage; medical device; outcome variable; practice guideline; predictor variable; qualitative analysis; quantitative analysis; randomization; Reducing IrreProducibility in labOratory STudiEs framework; reproducibility; research; resource management; study design; total quality management; medical research; methodology; procedures; standards; statistical analysis; trends; Biomedical Research; Data Interpretation, Statistical; Reproducibility of Results; Research Design",Article,"Final",Open Access,Scopus,2-s2.0-84930619829
"Loraine A.E., Blakley I.C., Jagadeesan S., Harper J., Miller G., Firon N.","6603339553;56554122600;56554044300;7402361756;18634897200;6602099566;","Analysis and visualization of RNA-Seq expression data using rstudio, bioconductor, and integrated genome browser",2015,"Plant Functional Genomics: Methods and Protocols: Second Edition",,,,"481","501",,1,"10.1007/978-1-4939-2444-8_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954578418&doi=10.1007%2f978-1-4939-2444-8_24&partnerID=40&md5=dd4d2ab0414f0a5101846ab5c24d6c2e","Department of Bioinformatics and Genomics, University of North Carolina at Charlotte, Charlotte, NC, United States; Department of Vegetable Research, Institute of Plant Sciences, Agricultural Research Organization, Bet Dagan, Israel; Department of Biochemistry and Molecular Biology, University of Nevada, Reno, NV, United States; The Mina and Everard Goodman Faculty of Life Sciences, Bar-Ilan University, Ramat-Gan, Israel","Loraine, A.E., Department of Bioinformatics and Genomics, University of North Carolina at Charlotte, Charlotte, NC, United States; Blakley, I.C., Department of Bioinformatics and Genomics, University of North Carolina at Charlotte, Charlotte, NC, United States; Jagadeesan, S., Department of Vegetable Research, Institute of Plant Sciences, Agricultural Research Organization, Bet Dagan, Israel; Harper, J., Department of Biochemistry and Molecular Biology, University of Nevada, Reno, NV, United States; Miller, G., The Mina and Everard Goodman Faculty of Life Sciences, Bar-Ilan University, Ramat-Gan, Israel; Firon, N., Department of Vegetable Research, Institute of Plant Sciences, Agricultural Research Organization, Bet Dagan, Israel","Sequencing costs are falling, but the cost of data analysis remains high, often because unforeseen problems arise, such as insufficient depth of sequencing or batch effects. Experimenting with data analysis methods during the planning phase of an experiment can reveal unanticipated problems and build valuable bioinformatics expertise in the organism or process being studied. This protocol describes using R Markdown and RStudio, user-friendly tools for statistical analysis and reproducible research in bioinformatics, to analyze and document the analysis of an example RNA-Seq data set from tomato pollen undergoing chronic heat stress. Also, we show how to use Integrated Genome Browser to visualize read coverage graphs for differentially expressed genes. Applying the protocol described here and using the provided data sets represent a useful first step toward building RNA-Seq data analysis expertise in a research group. © Springer Science+Business Media New York 2015. All rights are reserved.","Differential gene expression; edgeR; Integrated genome browser; Pollen; R; RNA-Seq; Tomato; Visualization","RNA; biology; computer program; genetics; genomics; high throughput sequencing; procedures; tomato; web browser; Computational Biology; Genomics; High-Throughput Nucleotide Sequencing; Lycopersicon esculentum; RNA; Software; Web Browser",Book Chapter,"Final",,Scopus,2-s2.0-84954578418
"Degara N., Kuppanda T., Neate T., Yang J., Torres A.","36607579800;56512318500;56512364200;57189240686;56510970500;","Reproducible sonification for virtual navigation",2015,"2014 IEEE VR Workshop: Sonic Interaction in Virtual Environments, SIVE 2014",,, 07006288,"35","40",,3,"10.1109/SIVE.2014.7006288","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922567871&doi=10.1109%2fSIVE.2014.7006288&partnerID=40&md5=917700aa8b8e5ef73afa6eda82d1c55c","Audio Department, Fraunhofer IIS, Germany; FIT Lab, Swansea University, United Kingdom; Audio Lab, University of York, United Kingdom; Interaction Design, Zurich University of the Arts, Switzerland","Degara, N., Audio Department, Fraunhofer IIS, Germany; Kuppanda, T., Audio Department, Fraunhofer IIS, Germany; Neate, T., FIT Lab, Swansea University, United Kingdom; Yang, J., Audio Lab, University of York, United Kingdom; Torres, A., Interaction Design, Zurich University of the Arts, Switzerland","The use of sonification for navigation, localization and obstacle avoidance is considered to be one of the most important tasks in auditory display research for its potential application to navigation systems in vehicles and smartphones, assistive technology and other eyes-free applications. The aim of this technology is to deliver location-based information to support navigation through sound. In this paper a comparison of two sonification methods for navigation and obstacle avoidance is presented. These methods were initially developed during a sonification hack day that was ran during the Interactive Sonification (ISon) workshop 2013. In order to allow the formal comparison of methods, we followed a reproducible sonification approach using a set of guidelines provided by SonEX (Sonification Evaluation eXchange). SonEX is a community-based environment that enables the definition and evaluation of standardized tasks, supporting open science standards and reproducible research. In order to allow for reproducible research, the system has been made publicly available. © 2014 IEEE.","Auditory displays; Blind navigation; Interactive sonification; Reproducibility; Spatial auditorydisplays","Navigation systems; Auditory display; Blind navigation; Interactive sonification; Reproducibilities; Spatial auditorydisplays; Virtual reality",Conference Paper,"Final",,Scopus,2-s2.0-84922567871
"Skaggs T.H., Young M.H., Vrugt J.A.","6603809730;7404193334;6603506913;","Reproducible research in vadose zone sciences",2015,"Vadose Zone Journal","14","10",,"","",5,12,"10.2136/vzj2015.06.0088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944338975&doi=10.2136%2fvzj2015.06.0088&partnerID=40&md5=6fec35dfee2ff083d5f3c51e193804ab","U.S. Salinity Laboratory, 450 W. Big Springs Rd, Riverside, CA  92507, United States; Bureau of Economic Geology, Jackson School of Geosciences, University of Texas at Austin, Austin, TX, United States; Dep. Of Civil and Environmental Engineering, University of California, Irvine, CA, United States","Skaggs, T.H., U.S. Salinity Laboratory, 450 W. Big Springs Rd, Riverside, CA  92507, United States; Young, M.H., Bureau of Economic Geology, Jackson School of Geosciences, University of Texas at Austin, Austin, TX, United States; Vrugt, J.A., Dep. Of Civil and Environmental Engineering, University of California, Irvine, CA, United States","A significant portion of present-day soil and Earth science research is computational, involving complex data analysis pipelines, advanced mathematical and statistical models, and sophisticated computer codes. Opportunities for scientific progress are greatly diminished if reproducing and building on published research is difficult or impossible due to the complexity of these computational systems. Vadose Zone Journal (VZJ) is launching a Reproducible Research (RR) program in which code and data underlying a research article will be published alongside the article, thereby enabling readers to analyze data in a manner similar to that presented in the article and build on results in future research and applications. In this article, we discuss reproducible research, its background and use across other disciplines, its value to the scientific community, and its implementation in VZJ. © Soil Science Society of America.",,"Application programs; Pipeline codes; Computational system; Computer codes; Reproducible research; Research and application; Science research; Scientific community; Scientific progress; Vadose Zone; Groundwater; complexity; computer simulation; data assimilation; numerical model; pipeline; research program; statistical analysis; vadose zone",Article,"Final",Open Access,Scopus,2-s2.0-84944338975
"Fomel S.","6603684193;","Reproducible research as a community effort: Lessons from the Madagascar project",2015,"Computing in Science and Engineering","17","1", 6880240,"20","26",,5,"10.1109/MCSE.2014.94","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922879147&doi=10.1109%2fMCSE.2014.94&partnerID=40&md5=3937e51c3b1fcfe937f40495594536a2","University of Texas at Austin, United States","Fomel, S., University of Texas at Austin, United States","Reproducible research is the discipline of attaching software code and data to publications, which enables the reader to reproduce, verify, and extend published computational experiments. Instead of being the responsibility of an individual author, computational reproducibility should become the responsibility of open source scientific-software communities. A dedicated community effort can keep a body of computational research alive by actively maintaining its reproducibility. The Madagascar open source software project offers an example of such a community. © 1999-2011 IEEE.","open source; reproducible research; scientific computing; scientific software","Natural sciences computing; Open systems; Computational experiment; Computational reproducibility; Computational researches; Open source software projects; Open sources; Reproducibilities; Reproducible research; Scientific softwares; Open source software",Article,"Final",,Scopus,2-s2.0-84922879147
"Dittrich J., Bender P.","10739786000;57045586500;","Janiform intra-document analytics for reproducible research",2015,"Proceedings of the VLDB Endowment","8","12",,"1972","1975",,2,"10.14778/2824032.2824114","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953864569&doi=10.14778%2f2824032.2824114&partnerID=40&md5=4ea4db01ca958d805d0ab17f7606c0ab","Saarland University, Germany","Dittrich, J., Saarland University, Germany; Bender, P., Saarland University, Germany","Peer-reviewed publication of research papers is a cornerstone of science. However, one of the many issues of our publication culture is that our publications only publish a summary of the final result of a long project. This means that we put well-polished graphs describing (some) of our experimental results into our publications. However, the algorithms, input datasets, benchmarks, raw result datasets, as well as scripts that were used to produce the graphs in the first place are rarely published and typically not available to other researchers. Often they are only available when personally asking the authors. In many cases, however, they are not available at all. This means from a long workflow that led to producing a graph for a research paper, we only publish the final result rather than the entire workflow. This is unfortunate and has been criticized in various scientific communities. In this demo we argue that one part of the problem is our dated view on what a ""document"" and hence ""a publication"" is, should, and can be. As a remedy, we introduce portable database files (PDbF). These files are janiform, i.e. they are at the same time a standard static pdf as well as a highly dynamic (online) HTML-document. PDbFs allow you to access the raw data behind a graph, perform OLAP-style analysis, and reproduce your own graphs from the raw data-all of this within a portable document. We demo a tool allowing you to create PDbFs smoothly from within LATEX. This tool allows you to preserve the workflow of raw measurement data to its final graphical output through all processing steps. Notice that this pdf already showcases our technology: rename this file to "".html"" and see what happens (currently we support the desktop versions of Firefox, Chrome, and Safari). But please: do not try to rename this file to "".ova"" and mount it in VirtualBox. © 2015 VLDB Endowment 2150-8097/15/08.",,"Firefox; HTML documents; One parts; Processing steps; Raw measurements; Reproducible research; Research papers; Scientific community; Publishing",Book Chapter,"Final",,Scopus,2-s2.0-84953864569
"Atmanspacher H., Maasen S.","6603833733;13806650100;","Reproducibility: Principles, Problems, Practices, and Prospects",2015,"Reproducibility: Principles, Problems, Practices, and Prospects",,,,"1","574",,2,"10.1002/9781118865064","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984825579&doi=10.1002%2f9781118865064&partnerID=40&md5=dbaf6ad086f7d36d3d6fa19e3453441d","Collegium Helveticum, University and ETH Zurich, Zurich, Switzerland; Munich Center for Technology in Society, Technical University, Munich, Germany","Atmanspacher, H., Collegium Helveticum, University and ETH Zurich, Zurich, Switzerland; Maasen, S., Munich Center for Technology in Society, Technical University, Munich, Germany","""A comprehensive, insightful treatment of the reproducibility challenges facing science today and of ways in which the scientific community can address them."" Kathleen Hall Jamieson, Elizabeth Ware Packard Professor of Communication, University of Pennsylvania. ""How can we make sure that reproducible research remains a key imperative of scientific communication under increasing commercialization, media attention, and publication pressure? This handbook offers the first interdisciplinary and fundamental treatment of this important question."" Torsten Hothorn, Professor of Biostatistics, University of Zurich. Featuring peer-reviewed contributions from noted experts in their fields of research, Reproducibility: Principles, Problems, Practices, and Prospects presents state-of-the-art approaches to reproducibility, the gold standard of sound science, from multi- and interdisciplinary perspectives. Including comprehensive coverage for implementing and reflecting the norm of reproducibility in various pertinent fields of research, the book focuses on how the reproducibility of results is applied, how it may be limited, and how such limitations can be understood or even controlled in the natural sciences, computational sciences, life sciences, social sciences, and studies of science and technology. The book presents many chapters devoted to a variety of methods and techniques, as well as their epistemic and ontological underpinnings, which have been developed to safeguard reproducible research and curtail deficits and failures. The book also investigates the political, historical, and social practices that underlie reproducible research in contemporary science studies, including the difficulties of good scientific practice and the ethos of reproducibility in modern innovation societies. Reproducibility: Principles, Problems, Practices, and Prospects is a guide for researchers who are interested in the general and overarching questions behind the concept of reproducibility; for active scientists who are confronted with practical reproducibility problems in their everyday work; and for economic stakeholders and political decision makers who need to better understand the challenges of reproducibility. In addition, the book is a useful in-depth primer for undergraduate and graduate-level courses in scientific methodology and basic issues in the philosophy and sociology of science from a modern perspective. © 2016 by John Wiley & Sons, Inc. All rights reserved.",,"Decision making; Social sciences computing; Computational science; Good scientific practices; Graduate level course; Reproducible research; Science and Technology; Scientific communication; Scientific methodology; State-of-the-art approach; Ontology",Book,"Final",,Scopus,2-s2.0-84984825579
"Lefebvre A., Spruit M., Omta W.","57169815200;16178767900;56225739400;","Towards reusability of computational experiments capturing and sharing research objects from knowledge discovery processes",2015,"IC3K 2015 - Proceedings of the 7th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management","1",,,"456","462",,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960910993&partnerID=40&md5=123be337eb90de4d8a18da9bcee4af1f","Department of Information and Computer Sciences, Utrecht University, Princetonplein 5, Utrecht, Netherlands","Lefebvre, A., Department of Information and Computer Sciences, Utrecht University, Princetonplein 5, Utrecht, Netherlands; Spruit, M., Department of Information and Computer Sciences, Utrecht University, Princetonplein 5, Utrecht, Netherlands; Omta, W., Department of Information and Computer Sciences, Utrecht University, Princetonplein 5, Utrecht, Netherlands","Calls for more reproducible research by sharing code and data are released in a large number of fields from biomedical science to signal processing. At the same time, the urge to solve data analysis bottlenecks in the biomedical field generates the need for more interactive data analytics solutions. These interactive solutions are oriented towards wet lab users whereas bioinformaticians favor custom analysis tools. In this position paper we elaborate on why Reproducible Research, by presenting code and data sharing as a gold standard for reproducibility misses important challenges in data analytics. We suggest new ways to design interactive tools embedding constraints of reusability with data exploration. Finally, we seek to integrate our solution with Research Objects as they are expected to bring promising advances in reusability and partial reproducibility of computational work. © 2015 by SCITEPRESS - Science and Technology Publications, Lda.","Bioinformatics; Knowledge discovery; Reproducible research; Research objects; Software development","Bioinformatics; Data mining; Knowledge engineering; Knowledge management; Reusability; Signal processing; Software design; Software engineering; Bioinformaticians; Biomedical fields; Biomedical science; Computational experiment; Computational work; Knowledge discovery process; Reproducible research; Research object; Engineering research",Conference Paper,"Final",,Scopus,2-s2.0-84960910993
"Stodden V., Miguez S., Seiler J.","15623425400;56451007500;24544970900;","ResearchCompendia.org: Cyberinfrastructure for reproducibility and collaboration in computational science",2015,"Computing in Science and Engineering","17","1", 7030302,"12","19",,11,"10.1109/MCSE.2015.18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922949197&doi=10.1109%2fMCSE.2015.18&partnerID=40&md5=c72e4cbc30b0d72505735e01be2b2c3a","University of Illinois at Urbana-Champaign, United States; Columbia University, United States","Stodden, V., University of Illinois at Urbana-Champaign, United States; Miguez, S., Columbia University, United States; Seiler, J., Columbia University, United States","We outline three goals to consider in building cyberinfrastructure to support scientific research and dissemination, and present our demonstration project ResearchCompendia. We posit that cyberinfrastructure should reinforce scientific norms, such as transparency and reproducibility, while embedding and encouraging best practices in scientific research, such as citation. Finally, we believe cyberinfrastucture should consider the entire soup-to-nuts discovery pipeline, even if focusing only on a subset of the workflow. In this article, we develop these ideas in the context of the ResearchCompendia project. ResearchCompendia is designed to facilitate reproducibility in computational science by persistently linking data and code that generated published findings to the article, and executing the code in the cloud to validate or certify those findings. We conclude with a discussion of the future vision of cyberinfrastructure and ResearchCompendia in support of science. © 1999-2011 IEEE.","open code; open data; open science; reproducible research; research compendia; scientific computing; sustainable software; validation; verification","Natural sciences computing; Verification; Open codes; Open datum; Open science; Reproducible research; Sustainable softwares; validation; Codes (symbols)",Article,"Final",,Scopus,2-s2.0-84922949197
"Diggle P.J.","7006313409;","Statistics: A data science for the 21st century",2015,"Journal of the Royal Statistical Society. Series A: Statistics in Society","178","4",,"793","813",,18,"10.1111/rssa.12132","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942342280&doi=10.1111%2frssa.12132&partnerID=40&md5=7bd568eca8a93a44a456c088a15bd1e5","Lancaster University, United Kingdom","Diggle, P.J., Lancaster University, United Kingdom","The rise of data science could be seen as a potental threat to the long-term status of the statistics discipline. I first argue that, although there is a threat, there is also a much greater opportunity to re-emphasize the universal relevance of statistical method to the interpretation of data, and I give a short historical outline of the increasingly important links between statistics and information technology. The core of the paper is a summary of several recent research projects, through which I hope to demonstrate that statistics makes an essential, but incomplete, contribution to the emerging field of 'electronic health' research. Finally, I offer personal thoughts on how statistics might best be organized in a research-led university, on what we should teach our students and on some issues broadly related to data science where the Royal Statistical Society can take a lead. © 2015 The Royal Statistical Society and John Wiley & Sons Ltd.","Data science; Electronic health research; Health surveillance; Informatics; National Health Service prescribing patterns; Reproducible research; Statistical education",,Article,"Final",,Scopus,2-s2.0-84942342280
"Cooper J., Vik J.O., Waltemath D.","55243567700;6602748569;36471561200;","A call for virtual experiments: Accelerating the scientific process",2015,"Progress in Biophysics and Molecular Biology","117","1",,"99","106",,19,"10.1016/j.pbiomolbio.2014.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924718205&doi=10.1016%2fj.pbiomolbio.2014.10.001&partnerID=40&md5=2e8b14c8f0abe1b4d0f124afbbaeddc2","Department of Computer Science, University of Oxford, Parks Road, Oxford, OX1 3QD, United Kingdom; Department of Animal and Aquacultural Sciences, Centre for Integrative Genetics, Norwegian University of Life Sciences, P.O. Box 5003, Ås, N-1432, Norway; Department of Systems Biology and Bioinformatics, University of Rostock, Rostock, D-18051, Germany","Cooper, J., Department of Computer Science, University of Oxford, Parks Road, Oxford, OX1 3QD, United Kingdom; Vik, J.O., Department of Animal and Aquacultural Sciences, Centre for Integrative Genetics, Norwegian University of Life Sciences, P.O. Box 5003, Ås, N-1432, Norway; Waltemath, D., Department of Systems Biology and Bioinformatics, University of Rostock, Rostock, D-18051, Germany","Experimentation is fundamental to the scientific method, whether for exploration, description or explanation. We argue that promoting the reuse of virtual experiments (the in silico analogues of wet-lab or field experiments) would vastly improve the usefulness and relevance of computational models, encouraging critical scrutiny of models and serving as a common language between modellers and experimentalists. We review the benefits of reusable virtual experiments: in specifying, assaying, and comparing the behavioural repertoires of models; as prerequisites for reproducible research; to guide model reuse and composition; and for quality assurance in the translational application of models. A key step towards achieving this is that models and experimental protocols should be represented separately, but annotated so as to facilitate the linking of models to experiments and data. Lastly, we outline how the rigorous, streamlined confrontation between experimental datasets and candidate models would enable a ""continuous integration"" of biological knowledge, transforming our approach to systems biology. © 2014 Elsevier Ltd.","Computational physiology; Functional curation; Model comparison; Reproducible research; Virtual experiments","computer simulation; human; procedures; research; science; Computer Simulation; Humans; Research; Science",Article,"Final",,Scopus,2-s2.0-84924718205
"Stodden V.","15623425400;","Reproducing statistical results",2015,"Annual Review of Statistics and Its Application","2",,,"1","19",,25,"10.1146/annurev-statistics-010814-020127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928107878&doi=10.1146%2fannurev-statistics-010814-020127&partnerID=40&md5=b1e38cc21c8fccb6c81c3b6c71338b13","Graduate School of Library and Information Science, University of Illinois at Urbana-Champaign, Champaign, IL, United States","Stodden, V., Graduate School of Library and Information Science, University of Illinois at Urbana-Champaign, Champaign, IL, United States","The reproducibility of statistical findings has become a concern not only for statisticians, but for all researchers engaged in empirical discovery. Section 2 of this article identifies key reasons statistical findings may not replicate, including power and sampling issues; misapplication of statistical tests; the instability of findings under reasonable perturbations of data or models; lack of access to methods, data, or equipment; and cultural barriers such as researcher incentives and rewards. Section 3 discusses five proposed remedies for these replication failures: improved prepublication and postpublication validation of findings; the complete disclosure of research steps; assessment of the stability of statistical findings; providing access to digital research objects, in particular data and software; and ensuring these objects are legally reusable. Copyright ©2015 by Annual Reviews. All rights resesrved.","Code sharing; Data sharing; Open code; Open data; Open licensing; Open science; Replication; Reproducible research; Statistical reproducibility",,Article,"Final",,Scopus,2-s2.0-84928107878
"Terrel A., Tobis M., Thiruvathukal G.K.","24462653300;8698322600;6601955304;","Scientific software communities",2015,"Computing in Science and Engineering","17","1", 7030313,"8","10",,1,"10.1109/MCSE.2015.21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922896036&doi=10.1109%2fMCSE.2015.21&partnerID=40&md5=ea6dec28730f1e2bbcdc3893ced5eeb0","Continuum Analytics, United States; Planet 3.0, United States; Loyola University Chicago, United States","Terrel, A., Continuum Analytics, United States; Tobis, M., Planet 3.0, United States; Thiruvathukal, G.K., Loyola University Chicago, United States","The articles in this issue provide some examples of how a more considered focus on the software development process can feed the development of science. Two different approaches to reproducible software practices, an approach on maintaining documentation for important base libraries, and a discussion on ways of extending a software library's functionality to keep it relevant as a community evolves over time. These topics challenge the boundaries of what software can be for an individual and for a community. The authors expose eaknesses in our state-of-the-art practices with an eye towards a sustainable future. By using these techniques, we avoid numerous withdrawn results-a current crisis due to reliance on software without verification. © 1999-2011 IEEE.","extensible software; knowledge sharing; open source; reproducible research; scientific computing; scientific software",,Editorial,"Final",,Scopus,2-s2.0-84922896036
"Loraine A.E., Blakley I.C., Jagadeesan S., Harper J., Miller G., Firon N.","6603339553;56554122600;56554044300;7402361756;18634897200;6602099566;","Analysis and visualization of RNA-Seq expression data using Rstudio, bioconductor, and integrated genome browser",2015,"Methods in Molecular Biology","1284",,,"481","501",,17,"10.1007/978-1-4939-2444-8_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924891523&doi=10.1007%2f978-1-4939-2444-8_24&partnerID=40&md5=5c7d6ae82e5c001948bbc10ac0221c85",,"Loraine, A.E.; Blakley, I.C.; Jagadeesan, S.; Harper, J.; Miller, G.; Firon, N.","Sequencing costs are falling, but the cost of data analysis remains high, often because unforeseen problems arise, such as insuffi cient depth of sequencing or batch effects. Experimenting with data analysis methods during the planning phase of an experiment can reveal unanticipated problems and build valuable bioinformatics expertise in the organism or process being studied. This protocol describes using R Markdown and RStudio, user-friendly tools for statistical analysis and reproducible research in bioinformatics, to analyze and document the analysis of an example RNA-Seq data set from tomato pollen undergoing chronic heat stress. Also, we show how to use Integrated Genome Browser to visualize read coverage graphs for differentially expressed genes. Applying the protocol described here and using the provided data sets represent a useful fi rst step toward building RNA-Seq data analysis expertise in a research group. © Springer Science+Business Media New York 2015.","Differential gene expression; edgeR; Integrated genome browser; Pollen; R; RNA-Seq; Tomato; Visualization","Article; bioinformatics; chronic stress; computer program; data analysis; gene expression; gene ontology; heat stress; integrated genome browser; pollen; priority journal; protein expression; reproducibility; RNA analysis; RNA sequence; statistical analysis; tomato; web browser; Lycopersicon esculentum",Article,"Final",,Scopus,2-s2.0-84924891523
"Rödiger S., Burdukiewicz M., Blagodatskikh K., Jahn M., Schierack P.","49962220600;56497097300;36241346100;55561255400;55908377800;","R as an environment for reproducible analysis of DNA amplification experiments",2015,"R Journal","7","1",,"127","150",,10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934754609&partnerID=40&md5=ea8007a856fa016fca6b92ff98ca0701","Faculty of Natural Sciences, Brandenburg University of Technology Cottbus-Senftenberg, Senftenberg, Germany; University of Wroclaw, Faculty of Biotechnoloy, Department of Genomics, Wroclaw, Poland; All-Russia Research Institute of Agricultural Biotechnology, Center for collective use 'Biotechnology', Moscow, Russian Federation; Helmholtz Centre for Environmental Research - UFZ, Flow cytometry group/Environmental microbiology, Leipzig, Germany","Rödiger, S., Faculty of Natural Sciences, Brandenburg University of Technology Cottbus-Senftenberg, Senftenberg, Germany; Burdukiewicz, M., University of Wroclaw, Faculty of Biotechnoloy, Department of Genomics, Wroclaw, Poland; Blagodatskikh, K., All-Russia Research Institute of Agricultural Biotechnology, Center for collective use 'Biotechnology', Moscow, Russian Federation; Jahn, M., Helmholtz Centre for Environmental Research - UFZ, Flow cytometry group/Environmental microbiology, Leipzig, Germany; Schierack, P., Faculty of Natural Sciences, Brandenburg University of Technology Cottbus-Senftenberg, Senftenberg, Germany","There is an ever-increasing number of applications, which use quantitative PCR (qPCR) or digital PCR (dPCR) to elicit fundamentals of biological processes. Moreover, quantitative isothermal amplification (qIA) methods have become more prominent in life sciences and point-of-carediagnostics. Additionally, the analysis of melting data is essential during many experiments. Several software packages have been developed for the analysis of such datasets. In most cases, the software is either distributed as closed source software or as monolithic block with little freedom to perform highly customized analysis procedures. We argue, among others, that R is an excellent foundation for reproducible and transparent data analysis in a highly customizable cross-platform environment. However, for novices it is often challenging to master R or learn capabilities of the vast number of packages available. In the paper, we describe exemplary workflows for the analysis of qPCR, qIA or dPCR experiments including the analysis of melting curve data. Our analysis relies entirely on R packages available from public repositories. Additionally, we provide information related to standardized and reproducible research.",,,Article,"Final",,Scopus,2-s2.0-84934754609
"Lahti L., Ilomäki N., Tolonen M.","8679063700;56996160700;35879720500;","A quantitative study of history in the english short-title catalogue (ESTC), 1470-1800",2015,"LIBER Quarterly","25","2",,"87","116",,4,"10.18352/lq.10112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949466572&doi=10.18352%2flq.10112&partnerID=40&md5=a3c0960e6ff6ab6cecdd40a022134b64","Laboratory of Microbiology, Wageningen University, Netherlands; Department of Computer Science, University of Helsinki, Finland; Department of Modern Languages, University of Helsinki, Finland","Lahti, L., Laboratory of Microbiology, Wageningen University, Netherlands; Ilomäki, N., Department of Computer Science, University of Helsinki, Finland; Tolonen, M., Department of Modern Languages, University of Helsinki, Finland","This article analyses publication trends in the field of history in early modern Britain and North America in 1470-1800, based on English Short-Title Catalogue (ESTC) data.2 Its major contribution is to demonstrate the potential of digitized library catalogues as an essential scholastic tool and part of reproducible research. We also introduce a novel way of quantitatively analysing a particular trend in book production, namely the publishing of works in the field of history. The study is also our first experimental analysis of paper consumption in early modern book production, and demonstrates in practice the importance of open-science principles for library and information science. Three main research questions are addressed: 1) who wrote history; 2) where history was published; and 3) how publishing changed over time in early modern Britain and North America. In terms of our main findings we demonstrate that the average book size of history publications decreased over time, and that the octavo-sized book was the rising star in the eighteenth century, which is a true indication of expanding audiences. The article also compares different aspects of the most popular writers on history, such as Edmund Burke and David Hume. Although focusing on history, these findings may reflect more widespread publishing trends in the early modern era. We show how some of the key questions in this field can be addressed through the quantitative analysis of large-scale bibliographic data collections.3 © 2015, Igitur, Utrecht Publishing and Archiving Services. All rights reserved.","History publishing; Short-title catalogue",,Article,"Final",Open Access,Scopus,2-s2.0-84949466572
"Bergmann F.T., Adams R., Moodie S., Cooper J., Glont M., Golebiewski M., Hucka M., Laibe C., Miller A.K., Nickerson D.P., Olivier B.G., Rodriguez N., Sauro H.M., Scharm M., Soiland-Reyes S., Waltemath D., Yvon F., Le Novère N.","57201570692;7403935962;56238715400;55243567700;55908468300;16229843100;6507020371;23969468200;25028160300;7005755956;7101797474;36794180200;6601968571;55626698400;24774024500;36471561200;56313361700;7003673076;","COMBINE archive and OMEX format: One file to share all information to reproduce a modeling project",2014,"BMC Bioinformatics","15","1", 326,"","",,27,"10.1186/s12859-014-0369-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923910740&doi=10.1186%2fs12859-014-0369-z&partnerID=40&md5=08361bbeab7b215d089b991ff645e12a","Modelling of Biological Processes, BioQUANT/COS, University of Heidelberg, INF 267, Heidelberg, 69120, Germany; ResearchSpace, 24 Fountainhall Road, Edinburgh, EH9 2LW, United Kingdom; European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD, United Kingdom; Eight Pillars Ltd, 19 Redford Walk, Edinburgh, EH13 0AG, United Kingdom; Department of Computer Science, University of Oxford, Wolfson Building, Parks Road, Oxford, OX1 3QD, United Kingdom; HITS gGmbH, Schloss-Wolfsbrunnenweg 35, Heidelberg, D-69118, Germany; Computing and Mathematical sciences, California Institute of Technology, Pasadena, CA  91125, United States; Auckland Bioengineering Institute, University of Auckland, Private Bag 92019, Auckland, 1142, New Zealand; VU University Amsterdam, Systems Bioinformatics, Amsterdam, 1081 HV, Netherlands; Babraham Research Campus, Babraham Institute, Cambridge, CB22 3AT, United Kingdom; University of Washington, Department of Bioengineering, Seattle, WA  98195, United States; University of Rostock, Systems Biology and Bioinformatics, Ulmenstrasse 69, Rostock, 18057, Germany; The University of Manchester, School of Computer Science, Oxford Road, Manchester, M13 9PL, United Kingdom","Bergmann, F.T., Modelling of Biological Processes, BioQUANT/COS, University of Heidelberg, INF 267, Heidelberg, 69120, Germany; Adams, R., ResearchSpace, 24 Fountainhall Road, Edinburgh, EH9 2LW, United Kingdom; Moodie, S., European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD, United Kingdom, Eight Pillars Ltd, 19 Redford Walk, Edinburgh, EH13 0AG, United Kingdom; Cooper, J., Department of Computer Science, University of Oxford, Wolfson Building, Parks Road, Oxford, OX1 3QD, United Kingdom; Glont, M., European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD, United Kingdom; Golebiewski, M., HITS gGmbH, Schloss-Wolfsbrunnenweg 35, Heidelberg, D-69118, Germany; Hucka, M., Computing and Mathematical sciences, California Institute of Technology, Pasadena, CA  91125, United States; Laibe, C., European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD, United Kingdom; Miller, A.K., Auckland Bioengineering Institute, University of Auckland, Private Bag 92019, Auckland, 1142, New Zealand; Nickerson, D.P., Auckland Bioengineering Institute, University of Auckland, Private Bag 92019, Auckland, 1142, New Zealand; Olivier, B.G., VU University Amsterdam, Systems Bioinformatics, Amsterdam, 1081 HV, Netherlands; Rodriguez, N., Babraham Research Campus, Babraham Institute, Cambridge, CB22 3AT, United Kingdom; Sauro, H.M., University of Washington, Department of Bioengineering, Seattle, WA  98195, United States; Scharm, M., University of Rostock, Systems Biology and Bioinformatics, Ulmenstrasse 69, Rostock, 18057, Germany; Soiland-Reyes, S., The University of Manchester, School of Computer Science, Oxford Road, Manchester, M13 9PL, United Kingdom; Waltemath, D., University of Rostock, Systems Biology and Bioinformatics, Ulmenstrasse 69, Rostock, 18057, Germany; Yvon, F., European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD, United Kingdom; Le Novère, N., European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD, United Kingdom, Babraham Research Campus, Babraham Institute, Cambridge, CB22 3AT, United Kingdom","Background: With the ever increasing use of computational models in the biosciences, the need to share models and reproduce the results of published studies efficiently and easily is becoming more important. To this end, various standards have been proposed that can be used to describe models, simulations, data or other essential information in a consistent fashion. These constitute various separate components required to reproduce a given published scientific result. Results: We describe the Open Modeling EXchange format (OMEX). Together with the use of other standard formats from the Computational Modeling in Biology Network (COMBINE), OMEX is the basis of the COMBINE Archive, a single file that supports the exchange of all the information necessary for a modeling and simulation experiment in biology. An OMEX file is a ZIP container that includes a manifest file, listing the content of the archive, an optional metadata file adding information about the archive and its content, and the files describing the model. The content of a COMBINE Archive consists of files encoded in COMBINE standards whenever possible, but may include additional files defined by an Internet Media Type. Several tools that support the COMBINE Archive are available, either as independent libraries or embedded in modeling software. Conclusions: The COMBINE Archive facilitates the reproduction of modeling and simulation experiments in biology by embedding all the relevant information in one file. Having all the information stored and exchanged at once also helps in building activity logs and audit trails. We anticipate that the COMBINE Archive will become a significant help for modellers, as the domain moves to larger, more complex experiments such as multi-scale models of organs, digital organisms, and bioengineering. © 2014 Bergmann et al.; licensee BioMed Central Ltd.","Archive; Computational modeling; Data format; Reproducible research; Reproducible science","Computation theory; Archive; Computational model; Data format; Reproducible research; Reproducible science; Biology; biology; computer program; computer simulation; human; information center; information retrieval; Internet; nucleic acid database; procedures; Archives; Computational Biology; Computer Simulation; Databases, Nucleic Acid; Humans; Information Storage and Retrieval; Internet; Software",Article,"Final",Open Access,Scopus,2-s2.0-84923910740
"Mccormick M., Liu X., Jomier J., Marion C., Ibanez L.","36573732900;56042161800;6507216580;35211283000;34879831500;","Itk: Enabling reproducible research and open science",2014,"Frontiers in Neuroinformatics","8","FEB", 13,"","",,26,"10.3389/fninf.2014.00013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894227409&doi=10.3389%2ffninf.2014.00013&partnerID=40&md5=66af407ebf70041521231c9b48fb4126","Medical Computing Group, Kitware Inc, Clifton Park, NY, United States; Medical Computing Group, Kitware Inc, Lyon, France","Mccormick, M., Medical Computing Group, Kitware Inc, Clifton Park, NY, United States; Liu, X., Medical Computing Group, Kitware Inc, Clifton Park, NY, United States; Jomier, J., Medical Computing Group, Kitware Inc, Lyon, France; Marion, C., Medical Computing Group, Kitware Inc, Lyon, France; Ibanez, L., Medical Computing Group, Kitware Inc, Clifton Park, NY, United States","Reproducibility verification is essential to the practice of the scientific method. Researchers report their findings, which are strengthened as other independent groups in the scientific community share similar outcomes. In the many scientific fields where software has become a fundamental tool for capturing and analyzing data, this requirement of reproducibility implies that reliable and comprehensive software platforms and tools should be made available to the scientific community. The tools will empower them and the public to verify, through practice, the reproducibility of observations that are reported in the scientific literature. Medical image analysis is one of the fields in which the use of computational resources, both software and hardware, are an essential platform for performing experimental work. In this arena, the introduction of the Insight Toolkit (ITK) in 1999 has transformed the field and facilitates its progress by accelerating the rate at which algorithmic implementations are developed, tested, disseminated and improved. By building on the efficiency and quality of open source methodologies, ITK has provided the medical image community with an effective platform on which to build a daily workflow that incorporates the true scientific practices of reproducibility verification. This article describes the multiple tools, methodologies, and practices that the ITK community has adopted, refined, and followed during the past decade, in order to become one of the research communities with the most modern reproducibility verification infrastructure. For example, 207 contributors have created over 2400 unit tests that provide over 84% code line test coverage. The Insight Journal, an open publication journal associated with the toolkit, has seen over 360,000 publication downloads. The median normalized closeness centrality, a measure of knowledge flow, resulting from the distributed peer code review system was high, 0.46. © 2014 McCormick, Liu, Jomier, Marion and Ibanez.","Code review; Insight journal; Insight toolkit; Itk; Open science; Reproducibility","algorithm; article; brain development; brain segmentation; community; computer network; computer program; gerrit; information processing; knowledge; modularization; nuclear magnetic resonance imaging; publication; quality control; reproducibility; scientific community; scientific literature; training",Article,"Final",Open Access,Scopus,2-s2.0-84894227409
"Hrynaszkiewicz I., Li P., Edmunds S.","25521908400;57199004880;36719422500;","Open science and the role of publishers in reproducible research",2014,"Implementing Reproducible Research",,,,"383","418",,3,"10.1201/b16868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010809481&doi=10.1201%2fb16868&partnerID=40&md5=a6203b649b6fbb406478c911f27e04c2","Faculty of 1000, London, United Kingdom; Beijing Genomics Institute, Beijing, China","Hrynaszkiewicz, I., Faculty of 1000, London, United Kingdom; Li, P., Beijing Genomics Institute, Beijing, China; Edmunds, S., Beijing Genomics Institute, Beijing, China","When we read about the claims made in scientific papers, we tend to believe that they have been written by their authors in good faith. The process of science therefore demands the highest ethics and quality in order for the content of a scientific paper to be taken at face value. However, the increasing number of retractions in the scientific literature suggests that peer review is not of sufficient rigor to assess whether the results reported in papers can in fact be reproduced.1 It is often only the results and conclusions of a study that are examined, while the methodology, raw data, and the source code used to generate the results of a paper are usually not fully evaluated. © 2014 by Taylor & Francis Group, LLC.",,,Book Chapter,"Final",,Scopus,2-s2.0-85010809481
"Stodden V.","15623425400;","The reproducible research movement in statistics",2014,"Statistical Journal of the IAOS","30","2",,"91","93",,3,"10.3233/SJI-140818","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909996951&doi=10.3233%2fSJI-140818&partnerID=40&md5=056f04d78f9688cd2c2a401975d0bae8","Department of Statistics, Columbia University, New York, NY, United States","Stodden, V., Department of Statistics, Columbia University, New York, NY, United States",[No abstract available],"open code; open data; open science; Reproducible research; science policy",,Article,"Final",,Scopus,2-s2.0-84909996951
"Stodden V., Leisch F., Peng R.D.","15623425400;7005468665;8297055600;","Implementing reproducible research",2014,"Implementing Reproducible Research",,,,"1","419",,108,"10.1201/b16868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055586929&doi=10.1201%2fb16868&partnerID=40&md5=424f84ae4da235dbc094b2d377659749","Columbia University, New York, NY, United States; University of Natural Resources and Life Sciences, Institute of Applied Statistics and Computing, Vienna, Austria; Johns Hopkins University, Baltimore, MD, United States","Stodden, V., Columbia University, New York, NY, United States; Leisch, F., University of Natural Resources and Life Sciences, Institute of Applied Statistics and Computing, Vienna, Austria; Peng, R.D., Johns Hopkins University, Baltimore, MD, United States","In computational science, reproducibility requires that researchers make code and data available to others so that the data can be analyzed in a similar manner as in the original publication. Code must be available to be distributed, data must be accessible in a readable format, and a platform must be available for widely distributing the data and code. In addition, both data and code need to be licensed permissively enough so that others can reproduce the work without a substantial legal burden. Implementing Reproducible Research covers many of the elements necessary for conducting and distributing reproducible research. It explains how to accurately reproduce a scientific result. Divided into three parts, the book discusses the tools, practices, and dissemination platforms for ensuring reproducibility in computational science. It describes: • Computational tools, such as Sweave, knitr, VisTrails, Sumatra, CDE, and the Declaratron system • Open source practices, good programming practices, trends in open science, and the role of cloud computing in reproducible research • Software and methodological platforms, including open source software packages, RunMyCode platform, and open access journals Each part presents contributions from leaders who have developed software and other products that have advanced the field. Supplementary material is available at www.ImplementingRR.org. © 2014 by Taylor & Francis Group, LLC.",,,Book,"Final",,Scopus,2-s2.0-85055586929
"Xie Y.","55661402000;","Knitr: A comprehensive tool for reproducible research in R",2014,"Implementing Reproducible Research",,,,"3","32",,85,"10.1201/b16868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055520225&doi=10.1201%2fb16868&partnerID=40&md5=abf1ae4e9688f06a533c8809cef6750a","Department of Statistics, Iowa State University, Ames, IA, United States","Xie, Y., Department of Statistics, Iowa State University, Ames, IA, United States","Reproducibility is the ultimate standard by which scientific findings are judged. From the computer science perspective, reproducible research is often related to literate programming [13], a paradigm conceived by Donald Knuth, and the basic idea is to combine computer code and software documentation in the same document; the code and documentation can be identified by different special markers. We can either compile the code and mix the results with documentation or extract the source code from the document. To some extent, this implies reproducibility because everything is generated automatically from computer code, and the code can reflect all the details about computing. © 2014 by Taylor & Francis Group, LLC.",,,Book Chapter,"Final",,Scopus,2-s2.0-85055520225
"Button K.S., Munafò M.R.","37107323800;7004859481;","Incentivising reproducible research",2014,"Cortex","51","1",,"107","108",,5,"10.1016/j.cortex.2013.09.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84895057330&doi=10.1016%2fj.cortex.2013.09.011&partnerID=40&md5=2882ecdc7b3ed8e2238819835019e61d","School of Social and Community Medicine, University of Bristol, United Kingdom; MRC Integrative Epidemiology Unit, UK Centre for Tobacco and Alcohol Studies, and School of Experimental Psychology, University of Bristol, United Kingdom","Button, K.S., School of Social and Community Medicine, University of Bristol, United Kingdom, MRC Integrative Epidemiology Unit, UK Centre for Tobacco and Alcohol Studies, and School of Experimental Psychology, University of Bristol, United Kingdom; Munafò, M.R., MRC Integrative Epidemiology Unit, UK Centre for Tobacco and Alcohol Studies, and School of Experimental Psychology, University of Bristol, United Kingdom",[No abstract available],,"human; medical research; note; null hypothesis; publishing; science; scientist; statistics; creativity; funding; leadership; Note; research; scientific literature; Humans; Motivation; Publishing; Reproducibility of Results",Note,"Final",,Scopus,2-s2.0-84895057330
"Davison A.P., Mattioni M., Samarkanov D., Teleńczuk B.","8940202300;54781523300;55350386000;15062161400;","Sumatra: A toolkit for reproducible research",2014,"Implementing Reproducible Research",,,,"57","78",,15,"10.1201/b16868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048153264&doi=10.1201%2fb16868&partnerID=40&md5=b056ef6e53dbdafcf8a0770ca4bdd040","Unité de Neurosciences, Information and Complexité, Centre National de la Recherche Scientifique, Gif sur Yvette, France; European Molecular Biology Laboratory, European Bioinformatics Institute, Hinxton, United Kingdom; Ecole Centrale de Lille, Lille University of Science and Technology, Villeneuve-d'Ascq, France","Davison, A.P., Unité de Neurosciences, Information and Complexité, Centre National de la Recherche Scientifique, Gif sur Yvette, France; Mattioni, M., European Molecular Biology Laboratory, European Bioinformatics Institute, Hinxton, United Kingdom; Samarkanov, D., Ecole Centrale de Lille, Lille University of Science and Technology, Villeneuve-d'Ascq, France; Teleńczuk, B., Unité de Neurosciences, Information and Complexité, Centre National de la Recherche Scientifique, Gif sur Yvette, France","Lack of replicability in computational studies is, at base, a problem of shortcomings in record keeping. In laboratory-based experimental science, the tradition is to write down all experimental details in a paper notebook. This approach is no longer viable for many computational studies as the number of details that could have an impact on the final result is so large. Automated or semiautomated tools for keeping track of all the experimental detailsthe scientist's own code, input and output data, supporting software, the computer hardware used, etc.-are therefore needed. © 2014 by Taylor & Francis Group, LLC.",,,Book Chapter,"Final",,Scopus,2-s2.0-85048153264
"Nikolayeva O., Robinson M.D.","56488302800;56433742400;","edgeR for differential RNA-seq and ChIP-seq analysis: An application to stem cell biology",2014,"Methods in Molecular Biology","1150",,,"45","79",,67,"10.1007/978-1-4939-0512-6_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921425131&doi=10.1007%2f978-1-4939-0512-6_3&partnerID=40&md5=67e9325fecaa565f1729804762a7f99b",,"Nikolayeva, O.; Robinson, M.D.","The edgeR package, an R-based tool within the Bioconductor project, offers a fl exible statistical framework for detection of changes in abundance based on counts. In this chapter, we illustrate the use of edgeR on a human embryonic stem cell dataset, in particular for RNA-seq and ChIP-seq data. We focus on a step-by-step statistical analysis of differential expression, going from raw data to a list of putative differentially expressed genes and give examples of integrative analysis using the ChIP-seq data. We emphasize data quality spot checks and the use of positive controls throughout the process and give practical recommendations for reproducible research. © Springer Science+Business Media New York 2014.","ChIP-seq; Differential count analysis; edgeR; Human embryonic stem cells; Integrative analysis; Reproducible research; RNA-seq","complementary DNA; genomic DNA; Article; chromosome; cytology; embryo; embryonic stem cell; exon; gene expression; genome; histone modification; human; human cell; priority journal; promoter region; RNA sequence; transcription initiation site; biology; biostatistics; chromatin immunoprecipitation; embryonic stem cell; metabolism; procedures; sequence analysis; Biostatistics; Chromatin Immunoprecipitation; Computational Biology; Embryonic Stem Cells; Humans; Sequence Analysis, RNA",Article,"Final",,Scopus,2-s2.0-84921425131
"Braun M.L., Ong C.S.","7402739780;56401499100;","Open science in machine learning",2014,"Implementing Reproducible Research",,,,"343","366",,3,"10.1201/b16868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018181072&doi=10.1201%2fb16868&partnerID=40&md5=e947537234662391edc6c32db13f8c01","Department of Computer Science, Technical University of Berlin, Berlin, Germany; Bioinformatics Group, National ICT Australia, University of Melbourne, Melbourne, VIC, Australia","Braun, M.L., Department of Computer Science, Technical University of Berlin, Berlin, Germany; Ong, C.S., Bioinformatics Group, National ICT Australia, University of Melbourne, Melbourne, VIC, Australia","The advent of Big Data has resulted in an urgent need for flexible analysis tools. Machine learning addresses part of this need, providing a stable of potential computational models for extracting knowledge from the flood of data. In contrast to many areas of the natural sciences, such as physics, chemistry, and biology, machine learning can be studied in an algorithmic and computational fashion. In principle, machine learning experiments can be precisely defined, leading to perfectly reproducible research. In fact, there have been several efforts in the past of frameworks for reproducible experiments [3,13,15,30]. Since machine learning is a data-driven approach, we need to have access to carefully structured data [25], that would enable direct comparison of the results of statistical estimation procedures. Some headway has been seen in the statistics and bioinformatics community. The success of R and Bioconductor [8,9] as well as projects such as Sweave [15] and Orgmode [29] have resulted in the possibility to embed the code that produces the results of the paper in the paper itself. The idea is to have a unified computation and presentation, with the hope that it results in reproducible research [14,24]. © 2014 by Taylor & Francis Group, LLC.",,,Book Chapter,"Final",,Scopus,2-s2.0-85018181072
"Ruiz C., Richard O., Emeras J.","55634445800;57193426641;55654858200;","Reproducible software appliances for experimentation",2014,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST","137",,,"33","42",,5,"10.1007/978-3-319-13326-3_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916243435&doi=10.1007%2f978-3-319-13326-3_4&partnerID=40&md5=38fa823ced75046488b9e434a4c49d19","INRIA Grenoble, Grenoble, France; INRIA Nancy, Nancy, France","Ruiz, C., INRIA Grenoble, Grenoble, France; Richard, O., INRIA Grenoble, Grenoble, France; Emeras, J., INRIA Nancy, Nancy, France","Experiment reproducibility is a milestone of the scientific method. Reproducibility of experiments in computer science would bring several advantages such as code re-usability and technology transfer. The reproducibility problem in computer science has been solved partially, addressing particular class of applications or single machine setups. In this paper we present our approach oriented to setup complex environments for experimentation, environments that require a lot of configuration and the installation of several software packages. The main objective of our approach is to enable the exact and independent reconstruction of a given software environment and the reuse of code. We present a simple and small software appliance generator that helps an experimenter to construct a specific software stack that can be deployed on different available testbeds. © Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2014.","Cloud Computing; Experiment Methodology; Reproducible Research; Testbed; Virtual Appliances","Cloud computing; Complex networks; Experiments; Scheduling algorithms; Technology transfer; Testbeds; Complex environments; Reproducibilities; Reproducible research; Scientific method; Single- machines; Software environments; Software stacks; Virtual appliance; Computer software reusability",Conference Paper,"Final",,Scopus,2-s2.0-84916243435
"Sundnes K.O.","6603027516;","19. Putting it together",2014,"Scandinavian Journal of Public Health","42",,,"173","177",,,"10.1177/1403494813515128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899820377&doi=10.1177%2f1403494813515128&partnerID=40&md5=5cf9be3fe3c9a06ebe6f3893ac8a3872",,"Sundnes, K.O.","The goal of these Guidelines is to benefit populations at risk through improving the quality of responses to the health aspects of disasters. This will be achieved through the development of methods that open disasters to structured, reproducible research, and thereby contributing to the science of health disaster management. Five major barriers were identified that impaired our ability to attain these goals: (1) lack of a endorsed terminology (2) lack of a standard descriptive system for society and its functions; (3) lack of structured description of disaster phases based on their properties; (4) widely distributed grey literature; and (5) no common structure to reports. In response to these findings, many commonly held processes have been deconstructed into a total of four frameworks, the use of which should help in meeting the goal. The use of the frameworks should provide further insight into the epidemiology of disasters in addition to the insight of the value of interventions provided for relief, recovery, and/or preparedness, once a disaster occurs or a hazard has been identified. The way forward should include the development of consensus on definitions used in the health aspects of disasters and for a repository of interventions applied in specific settings that include their respective effectiveness in attaining the goal for which they were selected. In addition, existing literature and future reports should be forced into the frameworks to facilitate our understanding and to develop the science of health disaster, evolution of standards, best practices, and competencies, but also to test and further improve these Guidelines. The frameworks should be augmented by standardised data collection instruments including templates for the gathering, organisation, and synthesis of data. © 2014, the Nordic Societies of Public Health. All rights reserved.","Best practices; capacity building; competencies; damage; database; deconstruction; definitions; disaster; evaluations; frameworks; functions; grey literature; hazards; indicators; interventions; repository; research; responses; science; standards; structure; typology","disaster planning; human; motivation; organization and management; practice guideline; public health; Disaster Planning; Disaster Planning; Disaster Planning; Goals; Goals; Goals; Guidelines as Topic; Guidelines as Topic; Guidelines as Topic; Humans; Humans; Humans; Public Health; Public Health; Public Health",Article,"Final",Open Access,Scopus,2-s2.0-84899820377
"Stodden V.","15623425400;","What computational scientists need to know about intellectual property law: A primer",2014,"Implementing Reproducible Research",,,,"325","340",,1,"10.1201/b16868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944349702&doi=10.1201%2fb16868&partnerID=40&md5=f3f7d421f0ea192a7136abe822f42fc2","Department of Statistics, Columbia University, New York City, NY, United States","Stodden, V., Department of Statistics, Columbia University, New York City, NY, United States","Data and code are becoming as important to research dissemination as the traditional manuscript. For computational science, the evidence is clear: it is typically impossible to verify scientific claims without access to the code and data that generated published findings. Gentleman and Lang [1] introduced the notion of the “research compendium” as the unit of scholarly communication, a triple including the explanatory narrative, the code, and the data used in deriving the results. One of the reasons for including the code and data is to facilitate the production of really reproducible research, a phrase coined by Jon Claerbout in 1991† to mean research results that can be regenerated from the available code and data. Claerbout's approach was paraphrased by Donoho and Buckheit [2] as follows: Enabling computational replication typically means supplying the data, software, and scripts, including all parameter settings, which produced the results [3,4]. This approach runs headlong and unavoidably into current intellectual property law, which creates a stumbling block rather than an impassable barrier to the dissemination of really reproducible research. In this chapter, I describe these intellectual property stumbling blocks to the open sharing of computational scientific knowledge and present solutions that coincide with long-standing scientific norms. In Section 12.2, I motivate scientific communication as a narrative with a twofold purpose: to communicate the importance of the findings within the larger scientific context and to provide sufficient information that the results may be verified by others in the field. Sections 12.3 and 12.4 then discuss intellectual property barriers and solutions that enable code and data sharing, respectively. Each of these three research outputs, the research article, the code, and the data, requires different legal analyses and action in the scientific context as described in the following. The final section discusses citation for digital scholarly output, focusing on code and data. © 2014 by Taylor & Francis Group, LLC.",,,Book Chapter,"Final",,Scopus,2-s2.0-84944349702
"Hinsen K.","6701852443;","Software development for reproducible research",2013,"Computing in Science and Engineering","15","4", 6664970,"60","63",,2,"10.1109/MCSE.2013.91","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888409504&doi=10.1109%2fMCSE.2013.91&partnerID=40&md5=87997c1c0df411597c167b17770c5c40","Centre de Biophysique Moléculaire, Orléans, France","Hinsen, K., Centre de Biophysique Moléculaire, Orléans, France","Reproducible research will change not only the way we run computations, but also the way we write scientific software. © 1999-2011 IEEE.","reproducible research; scientific computing; scientific programming","Reproducible research; Scientific programming; Scientific softwares; Computer science; Engineering; Natural sciences computing; Research",Article,"Final",,Scopus,2-s2.0-84888409504
"Page K.R., Fields B., Roure D.D., Crawford T., Downie J.S.","8104972900;35733701400;6701509117;15054056900;7102932568;","Capturing the workflows of music information retrieval for repeatability and reuse",2013,"Journal of Intelligent Information Systems","41","3",,"435","459",,14,"10.1007/s10844-013-0260-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888343387&doi=10.1007%2fs10844-013-0260-9&partnerID=40&md5=6d52bc70190b06fb9ce46e6dd308550e","Oxford E-Research Centre, University of Oxford, Oxford, United Kingdom; Musicmetric (Semetric Ltd.), London, United Kingdom; Department of Computing,Goldsmiths, University of London, London, United Kingdom; Graduate School of Library and Information Sciences, University of Illinois, Urbana-Champaign, United States","Page, K.R., Oxford E-Research Centre, University of Oxford, Oxford, United Kingdom; Fields, B., Musicmetric (Semetric Ltd.), London, United Kingdom; Roure, D.D., Oxford E-Research Centre, University of Oxford, Oxford, United Kingdom; Crawford, T., Department of Computing,Goldsmiths, University of London, London, United Kingdom; Downie, J.S., Graduate School of Library and Information Sciences, University of Illinois, Urbana-Champaign, United States","Many solutions for the reuse and re-purposing of Music Information Retrieval (MIR) methods, and the tools implementing those methods, have been introduced over recent years. Proposals for achieving interoperability between systems have ranged from shared software libraries and interfaces, through common frameworks and portals, to standardised file formats and metadata. Here we assess these solutions for their suitability to be reused and combined as repurposable components within assemblies (or workflows) that can be used in novel and possibly more ambitious ways. Reuse and repeatability also have great implications for the process of MIR research: the encapsulation of any algorithm and its operation - including inputs, parameters, and outputs - is fundamental to the repeatability and reproducibility of an experiment. This is desirable both for the open and reliable evaluation of algorithms and for the advancement of MIR by building more effectively upon prior research. At present there is no clear best practice widely adopted by the field. Based upon our analysis of contemporary systems and their adoption we reflect as to whether this should be considered a failure. Are there limits to interoperability unique to MIR, and how might they be overcome Beyond workflows how much research context can, and should, be captured We frame our assessment within the emerging notion of Research Objects for reproducible research in other domains, and describe how their adoption could serve as a route to reuse in MIR. © 2013 Springer Science+Business Media New York.","Music Information Retrieval (MIR); Reproducible research; Research Objects; Workflows","Best practices; File formats; Music information retrieval; Reproducibilities; Reproducible research; Research object; Software libraries; Work-flows; Algorithms; Information retrieval; Interoperability; Research",Article,"Final",,Scopus,2-s2.0-84888343387
"Palma R., Hołubowicz P., Page K., Corcho O., Pérez S., Mazurek C.","13404889300;55827790400;8104972900;14010357000;57197994484;14619722100;","Digital libraries for the preservation of research methods and associated artifacts",2013,"ACM International Conference Proceeding Series",,,,"8","15",,4,"10.1145/2499583.2499589","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882382288&doi=10.1145%2f2499583.2499589&partnerID=40&md5=1725660aa409a30fb43f82212df0ea06","Poznan Supercomputing and Networking Center, Poznań, Poland; University of Oxford, Oxford, United Kingdom; Universidad Politécnica de Madrid, Madrid, Spain","Palma, R., Poznan Supercomputing and Networking Center, Poznań, Poland; Hołubowicz, P., Poznan Supercomputing and Networking Center, Poznań, Poland; Page, K., University of Oxford, Oxford, United Kingdom; Corcho, O., Universidad Politécnica de Madrid, Madrid, Spain; Pérez, S., Universidad Politécnica de Madrid, Madrid, Spain; Mazurek, C., Poznan Supercomputing and Networking Center, Poznań, Poland","New digital artifacts are emerging in data-intensive science. For example, scientific workflows are executable descriptions of scientific procedures that define the sequence of computational steps in an automated data analysis, supporting reproducible research and the sharing and replication of best-practice and know-how through reuse. Workflows are specified at design time and interpreted through their execution in a variety of situations, environments, and domains. Hence it is essential to preserve both their static and dynamic aspects, along with the research context in which they are used. To achieve this, we propose the use of multidimensional digital objects (Research Objects) that aggregate the resources used and/or produced in scientific investigations, including workflow models, provenance of their executions, and links to the relevant associated resources, along with the provision of technological support for their preservation and efficient retrieval and reuse. In this direction, we specified a software architecture for the design and implementation of a Research Object preservation system, and realized this architecture with a set of services and clients, drawing together practices in digital libraries, preservation systems, workflow management, social networking and Semantic Web technologies. In this paper, we describe the backbone system of this realization, a digital library system built on top of dLibra.","Evolution; Libraries; Preservation; Semantic","Automated data analysis; Design and implementations; Digital library systems; Evolution; Reproducible research; Scientific investigation; Semantic Web technology; Technological supports; Digital libraries; Digital storage; Libraries; Semantics; Social sciences computing; Technology transfer; Wood preservation; Work simplification; Research",Conference Paper,"Final",,Scopus,2-s2.0-84882382288
"Walters W.P.","36018804500;","Modeling, informatics, and the quest for reproducibility",2013,"Journal of Chemical Information and Modeling","53","7",,"1529","1530",,13,"10.1021/ci400197w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880519482&doi=10.1021%2fci400197w&partnerID=40&md5=3f3afad0a7685cd301a1e9838a2d0652","Vertex Pharmaceuticals, Inc., 130 Waverly St., Cambridge, MA 02139, United States","Walters, W.P., Vertex Pharmaceuticals, Inc., 130 Waverly St., Cambridge, MA 02139, United States","There is no doubt that papers published in the Journal of Chemical Information and Modeling, and related journals, provide valuable scientific information. However, it is often difficult to reproduce the work described in molecular modeling and cheminformatics papers. In many cases the software described in the paper is not readily available, in other cases the supporting information is not provided in an accessible format. To date, the major journals in the fields of molecular modeling and cheminformatics have not established guidelines for reproducible research. This letter provides an overview of the reproducibility challenges facing our field and suggests some guidelines for improving the reproducibility of published work. © 2013 American Chemical Society.",,"Chemical information; Cheminformatics; Informatics; Reproducibilities; Reproducible research; Scientific information; Molecular modeling; Information science; chemical structure; computer; computer program; information science; reproducibility; letter; Computers; Informatics; Models, Molecular; Reproducibility of Results; Software; Computers; Informatics; Models, Molecular; Reproducibility of Results; Software",Article,"Final",Open Access,Scopus,2-s2.0-84880519482
"Ram K.","15751626600;","Git can facilitate greater reproducibility and increased transparency in science",2013,"Source Code for Biology and Medicine","8",, 7,"","",,71,"10.1186/1751-0473-8-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874350660&doi=10.1186%2f1751-0473-8-7&partnerID=40&md5=d7e24153f56ff31a40a05871d4f380bb","Environmental Science, Policy, and Management, University of California, Berkeley, Berkeley, CA 94720, United States","Ram, K., Environmental Science, Policy, and Management, University of California, Berkeley, Berkeley, CA 94720, United States","Background: Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.Findings: Version control systems (VCS), which have long been used to maintain code repositories in the software industry, are now finding new applications in science. One such open source VCS, Git, provides a lightweight yet robust framework that is ideal for managing the full suite of research outputs such as datasets, statistical code, figures, lab notes, and manuscripts. For individual researchers, Git provides a powerful way to track and compare versions, retrace errors, explore new approaches in a structured manner, while maintaining a full audit trail. For larger collaborative efforts, Git and Git hosting services make it possible for everyone to work asynchronously and merge their contributions at any time, all the while maintaining a complete authorship trail. In this paper I provide an overview of Git along with use-cases that highlight how this tool can be leveraged to make science more reproducible and transparent, foster new collaborations, and support novel uses. © 2013 Ram; licensee BioMed Central Ltd.","Open science; Reproducible research; Version control",,Article,"Final",Open Access,Scopus,2-s2.0-84874350660
"De Chaumont F., Dallongeville S., Provoost T., Lecomte T., Dufour A., Olivo-Marin J.-C.","9332814800;36843696700;36551522700;57209017641;54985870600;6601972315;","Icy: A user-friendly environment for algorithm development and deployment",2013,"European Signal Processing Conference",,, 6811738,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901355836&partnerID=40&md5=c03938c2a63f2c6651d336dbfdc04a4f","Institut Pasteur, Quantitative Image Analysis Unit, CNRS URA 2582, 25 rue du Dr Roux, 75015 Paris, France","De Chaumont, F., Institut Pasteur, Quantitative Image Analysis Unit, CNRS URA 2582, 25 rue du Dr Roux, 75015 Paris, France; Dallongeville, S., Institut Pasteur, Quantitative Image Analysis Unit, CNRS URA 2582, 25 rue du Dr Roux, 75015 Paris, France; Provoost, T., Institut Pasteur, Quantitative Image Analysis Unit, CNRS URA 2582, 25 rue du Dr Roux, 75015 Paris, France; Lecomte, T., Institut Pasteur, Quantitative Image Analysis Unit, CNRS URA 2582, 25 rue du Dr Roux, 75015 Paris, France; Dufour, A., Institut Pasteur, Quantitative Image Analysis Unit, CNRS URA 2582, 25 rue du Dr Roux, 75015 Paris, France; Olivo-Marin, J.-C., Institut Pasteur, Quantitative Image Analysis Unit, CNRS URA 2582, 25 rue du Dr Roux, 75015 Paris, France","Bioimage informatics has emerged as a new interdisciplinary research endeavor for bringing the power of computational and mathematical sciences into the biological imaging arena. We describe an open-source software platform, Icy, that proposes a comprehensive framework for easy algorithm development and deployment fostering community-oriented efforts. Icy offers a platform to share and publish collaborative algorithm developments, while promoting re-usability and code sharing to ease the development of new algorithms, and simplifying user's feedback and support through a community web site. © 2013 EURASIP.","automated image acquisition; Bioimage informatics; Java; open source; reproducible research; script; visual programming","Computer programming; Information science; Open source software; Signal processing; Bioimage informatics; Java; Open sources; Reproducible research; script; Visual programming; Algorithms",Conference Paper,"Final",,Scopus,2-s2.0-84901355836
"Goble C., De Roure D., Bechhofer S.","7004072716;6701509117;6603392974;","Accelerating Scientists' Knowledge Turns",2013,"Communications in Computer and Information Science","348",,,"3","25",,6,"10.1007/978-3-642-37186-8_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882241332&doi=10.1007%2f978-3-642-37186-8_1&partnerID=40&md5=ab9e0eee4923f3c18af1d6e09ba01ea9","School of Computer Science, The University of Manchester, Manchester, United Kingdom; Oxford e-Research Centre, University of Oxford, United Kingdom","Goble, C., School of Computer Science, The University of Manchester, Manchester, United Kingdom; De Roure, D., Oxford e-Research Centre, University of Oxford, United Kingdom; Bechhofer, S., School of Computer Science, The University of Manchester, Manchester, United Kingdom","A ""knowledge turn"" is a cycle of a process by a professional, including the learning generated by the experience, deriving more good and leading to advance. The majority of scientific advances in the public domain result from collective efforts that depend on rapid exchange and effective reuse of results. We have powerful computational instruments, such as scientific workflows, coupled with widespread online information dissemination to accelerate knowledge cycles. However, turns between researchers continue to lag. In particular method obfuscation obstructs reproducibility. The exchange of ""Research Objects"" rather than articles proposes a technical solution; however the obstacles are mainly social ones that require the scientific community to rethink its current value systems for scholarship, data, methods and software. © Springer-Verlag Berlin Heidelberg 2013.","Digital Scholarship; Open Science; Reproducible Research; Research Object; Scientific Workflow","Information dissemination; Knowledge management; Digital Scholarship; Open science; Reproducible research; Research object; Scientific workflows; Research",Conference Paper,"Final",,Scopus,2-s2.0-84882241332
"Welty L.J., Carter R.E., Finkelstein D.M., Harrell F.E., Lindsell C.J., MacAluso M., Mazumdar M., Nietert P.J., Oster R.A., Pollock B.H., Roberson P.K., Ware J.H.","6506336738;8916068500;7101757324;36786110100;7004138202;57208420158;35944668400;7003663592;35335185300;12794737900;57200950346;57202555597;","Strategies for developing biostatistics resources in an academic health center",2013,"Academic Medicine","88","4",,"454","460",,10,"10.1097/ACM.0b013e31828578ed","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875823226&doi=10.1097%2fACM.0b013e31828578ed&partnerID=40&md5=608f1b3ac40eec55c7b5029aed512395","Department of Preventive Medicine, Northwestern University Feinberg School of Medicine, 680 N. Lake Shore Dr., Chicago, IL 60611, United States; Department of Health Sciences Research, Biostatistics, Epidemiology, and Research Design Resource, Mayo Clinic, Rochester, MN, United States; Harvard Medical School, Department of Biostatistics, Massachusetts General Hospital, Boston, MA, United States; Department of Biostatistics, Vanderbilt University School of Medicine, Vanderbilt Institute for Clinical and Translational Research, Nashville, TN, United States; Department of Emergency Medicine, Biostatistics, Epidemiology, and Research Design, University of Cincinnati, Cincinnati, OH, United States; Division of Biostatistics and Epidemiology, Cincinnati Children's Hospital Medical Center, University of Cincinnati, Cincinnati, OH, United States; Division of Biostatistics and Epidemiology, Department of Public Health, Weill Cornell Medical College of Cornell University, New York, NY, United States; Department of Public Health Sciences, Medical University of South Carolina, South Carolina Clinical and Translational Sciences Institute, Charleston, SC, United States; Division of Preventive Medicine, Department of Medicine, University of Alabama at Birmingham School of Medicine, Birmingham, AB, United States; Department of Epidemiology and Biostatistics, Biostatistics, Epidemiology, and Research Design Core, University of Texas Health Science Center at San Antonio School of Medicine, San Antonio, TX, United States; Department of Biostatistics, Biostatistics and Research Design Component of the Translational Research Institute, University of Arkansas for Medical Sciences College of Medicine, Little Rock, AR, United States; Department of Biostatistics, Harvard School of Public Health, Boston, MA, United States","Welty, L.J., Department of Preventive Medicine, Northwestern University Feinberg School of Medicine, 680 N. Lake Shore Dr., Chicago, IL 60611, United States; Carter, R.E., Department of Health Sciences Research, Biostatistics, Epidemiology, and Research Design Resource, Mayo Clinic, Rochester, MN, United States; Finkelstein, D.M., Harvard Medical School, Department of Biostatistics, Massachusetts General Hospital, Boston, MA, United States; Harrell, F.E., Department of Biostatistics, Vanderbilt University School of Medicine, Vanderbilt Institute for Clinical and Translational Research, Nashville, TN, United States; Lindsell, C.J., Department of Emergency Medicine, Biostatistics, Epidemiology, and Research Design, University of Cincinnati, Cincinnati, OH, United States; MacAluso, M., Division of Biostatistics and Epidemiology, Cincinnati Children's Hospital Medical Center, University of Cincinnati, Cincinnati, OH, United States; Mazumdar, M., Division of Biostatistics and Epidemiology, Department of Public Health, Weill Cornell Medical College of Cornell University, New York, NY, United States; Nietert, P.J., Department of Public Health Sciences, Medical University of South Carolina, South Carolina Clinical and Translational Sciences Institute, Charleston, SC, United States; Oster, R.A., Division of Preventive Medicine, Department of Medicine, University of Alabama at Birmingham School of Medicine, Birmingham, AB, United States; Pollock, B.H., Department of Epidemiology and Biostatistics, Biostatistics, Epidemiology, and Research Design Core, University of Texas Health Science Center at San Antonio School of Medicine, San Antonio, TX, United States; Roberson, P.K., Department of Biostatistics, Biostatistics and Research Design Component of the Translational Research Institute, University of Arkansas for Medical Sciences College of Medicine, Little Rock, AR, United States; Ware, J.H., Department of Biostatistics, Harvard School of Public Health, Boston, MA, United States","Biostatistics - the application of statistics to understanding health and biology - provides powerful tools for developing research questions, designing studies, refining measurements, analyzing data, and interpreting findings. Biostatistics plays an important role in health-related research, yet biostatistics resources are often fragmented, ad hoc, or oversubscribed within academic health centers (AHCs). Given the increasing complexity and quantity of health-related data, the emphasis on accelerating clinical and translational science, and the importance of conducting reproducible research, the need for the thoughtful development of biostatistics resources within AHCs is growing.In this article, the authors identify strategies for developing biostatistics resources in three areas: (1) recruiting and retaining biostatisticians, (2) efficiently using biostatistics resources, and (3) improving biostatistical contributions to science. AHCs should consider these three domains in building strong biostatistics resources, which they can leverage to support a broad spectrum of research. For each of the three domains, the authors describe the advantages and disadvantages of AHCs creating centralized biostatistics units rather than dispersing such resources across clinical departments or other research units. They also address the challenges that biostatisticians face in contributing to research without sacrificing their individual professional growth or the trajectory of their research teams. The authors ultimately recommend that AHCs create centralized biostatistics units because this approach offers distinct advantages both to investigators who collaborate with biostatisticians as well as to the biostatisticians themselves, and it is better suited to accomplish the research and education missions of AHCs.",,,Review,"Final",,Scopus,2-s2.0-84875823226
"Ducke B.","26036232900;","Natives of a connected world: Free and open source software in archaeology",2012,"World Archaeology","44","4",,"571","579",,9,"10.1080/00438243.2012.743259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870925390&doi=10.1080%2f00438243.2012.743259&partnerID=40&md5=545130c04f4a58c0963ae05ef98027f8","Freie Universität, Berlin, Germany","Ducke, B., Freie Universität, Berlin, Germany","Archaeological research is increasingly based on computational methods and software. This development has profound economical and epistemological implications that must be critically reviewed and understood with respect to financial barriers to reproducible research and the 'black box' effect that proprietary software introduces into archaeological research. Free and open source software (FOSS) offers an alternative model of software development that is better aligned with both the economics of project-based research and the demands of good scientific practice. FOSS is not a new concept but reflects the original idea of software as part of the public research domain - an idea that is concordant with the nature of the internet and globally connected research. © 2012 Copyright Taylor and Francis Group, LLC.","Archaeology; knowledge; open source software; reproducible research; science","archaeology; research; software",Article,"Final",,Scopus,2-s2.0-84870925390
"Stodden V., Hurlin C., Pérignon C.","15623425400;16304259600;13612699200;","RunMyCode.org: A novel dissemination and collaboration platform for executing published computational results",2012,"2012 IEEE 8th International Conference on E-Science, e-Science 2012",,, 6404455,"","",,16,"10.1109/eScience.2012.6404455","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873636621&doi=10.1109%2feScience.2012.6404455&partnerID=40&md5=8004566aaee178b7fe317987a7987f6f","Department of Statistics, Columbia University, New York City, NY, United States; Department of Economics, University of Orléans, France; Finance Department, HEC Paris, France","Stodden, V., Department of Statistics, Columbia University, New York City, NY, United States; Hurlin, C., Department of Economics, University of Orléans, France; Pérignon, C., Finance Department, HEC Paris, France","We believe computational science as practiced today suffers from a growing credibility gap - it is impossible to replicate most of the computational results presented at conferences or published in papers today. We argue that this crisis can be addressed by the open availability of the code and data that generated the results, in other words practicing reproducible computational science. In this paper we present a new computational infrastructure called RunMyCode.org that is designed to support published articles by providing a dissemination platform for the code and data that generated the their results. Published articles are given a companion webpage on the RunMyCode.org website from which a visitor can both download the associated code and data, and execute the code in the cloud directly through the RunMyCode.org website. This permits results to be verified through the companion webpage or on a user's local system. RunMyCode.org also permits a user to upload their own data to the companion webpage to check the code by running it on novel datasets. Through the creation of ""coder pages"" for each contributor to RunMyCode.org, we seek to facilitate social network-like interaction. Descriptive information appears on each coder page, including demographic data and other companion pages to which they made contributions. In this paper we motivate the rationale and functionality of RunMyCode.org and outline a vision of its future. ©2012 IEEE.","Cloud computing; Code sharing; Collaborative networks; Data sharing; Dissemination platform; Executable papers; Open science; Reproducible computational science; Reproducible research","Code sharing; Collaborative network; Computational science; Data Sharing; Dissemination platform; Open science; Reproducible research; Cloud computing; Websites; Publishing",Conference Paper,"Final",,Scopus,2-s2.0-84873636621
"Pham Q., Malik T., Foster I., Di Lauro R., Montella R.","23091602300;7005177091;35572232000;55384177900;9235980600;","SOLE: Linking research papers with science objects",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","7525 LNCS",,,"203","208",,20,"10.1007/978-3-642-34222-6_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868273935&doi=10.1007%2f978-3-642-34222-6_16&partnerID=40&md5=08cf67f261ebe2fdda3368cf1e845153","Department of Computer Science, University of Chicago, Chicago, IL 60637, United States; Computation Institute, University of Chicago, Chicago, IL 60637, United States; Department of Applied Science, University of Napoli Parthenope, Napoli, 80143, Italy","Pham, Q., Department of Computer Science, University of Chicago, Chicago, IL 60637, United States; Malik, T., Computation Institute, University of Chicago, Chicago, IL 60637, United States; Foster, I., Department of Computer Science, University of Chicago, Chicago, IL 60637, United States, Computation Institute, University of Chicago, Chicago, IL 60637, United States; Di Lauro, R., Department of Applied Science, University of Napoli Parthenope, Napoli, 80143, Italy; Montella, R., Department of Applied Science, University of Napoli Parthenope, Napoli, 80143, Italy","We introduce Science Object Linking and Embedding (SOLE), a tool for linking research papers with associated science objects, such as source codes, datasets, annotations, workflows, packages, and virtual machine images. The objective of SOLE is to reduce the cost to an author of linking research papers with such science objects for the purpose of reproducible research. To this end, SOLE allows an author to use simple tags to delimit a science object to be associated with a research paper. It creates an adequate representation of the science object and manages a bibliography-like specification of science objects. Authors and readers can reference elements of this bibliography and associate them with phrases in the text of the research paper through a Web interface, in a similar manner to a traditional bibliography tool. © 2012 Springer-Verlag.",,"Data sets; Object linking and embedding; Reproducible research; Research papers; Source codes; Virtual machines; Web interface; Work-flows; Bibliographies; Data processing; Paper; Research; World Wide Web",Conference Paper,"Final",Open Access,Scopus,2-s2.0-84868273935
"Cannam C., Figueira L.A., Plumbley M.D.","36730835200;57196651227;6603774794;","Sound software: Towards software reuse in audio and music research",2012,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",,, 6288485,"2745","2748",,5,"10.1109/ICASSP.2012.6288485","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867610376&doi=10.1109%2fICASSP.2012.6288485&partnerID=40&md5=1cdfc9de091ab21420a84d700059a71b","Queen Mary University of London, Centre for Digital Music, United Kingdom","Cannam, C., Queen Mary University of London, Centre for Digital Music, United Kingdom; Figueira, L.A., Queen Mary University of London, Centre for Digital Music, United Kingdom; Plumbley, M.D., Queen Mary University of London, Centre for Digital Music, United Kingdom","Although researchers are increasingly aware of the need to publish and maintain software code alongside their results, practical barriers prevent this from happening in many cases. We examine these barriers, propose an incremental approach to overcoming some of them, and describe the Sound Software project, an effort to support software development practice in the UK audio and music research community. Finally we make some recommendations for research groups seeking to improve their own researchers' software practice. © 2012 IEEE.","Programming; Reproducible research; Scientific computing; Software reuse; Software tools","Incremental approach; Reproducible research; Research communities; Research groups; Software codes; Software development practices; Software practices; Software project; Computer aided software engineering; Computer software reusability; Mathematical programming; Natural sciences computing; Research; Signal processing; Software design; Audio acoustics",Conference Paper,"Final",,Scopus,2-s2.0-84867610376
"Hrynaszkiewicz I., Cockerill M.J.","25521908400;14063084200;","Open by default: A proposed copyright license and waiver agreement for open access research and data in peer-reviewed journals",2012,"BMC Research Notes","5",, 494,"","",,14,"10.1186/1756-0500-5-494","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865828359&doi=10.1186%2f1756-0500-5-494&partnerID=40&md5=c57044e1ea8b08f047fe1a3b19eee5f1","BioMed Central Ltd, 236 Grays Inn Road, London, WC1X 8HB, United Kingdom","Hrynaszkiewicz, I., BioMed Central Ltd, 236 Grays Inn Road, London, WC1X 8HB, United Kingdom; Cockerill, M.J., BioMed Central Ltd, 236 Grays Inn Road, London, WC1X 8HB, United Kingdom","Copyright and licensing of scientific data, internationally, are complex and present legal barriers to data sharing, integration and reuse, and therefore restrict the most efficient transfer and discovery of scientific knowledge. Much data are included within scientific journal articles, their published tables, additional files (supplementary material) and reference lists. However, these data are usually published under licenses which are not appropriate for data. Creative Commons CC0 is an appropriate and increasingly accepted method for dedicating data to the public domain, to enable data reuse with the minimum of restrictions. BioMed Central is committed to working towards implementation of open data-compliant licensing in its publications. Here we detail a protocol for implementing a combined Creative Commons Attribution license (for copyrightable material) and Creative Commons CC0 waiver (for data) agreement for content published in peer-reviewed open access journals. We explain the differences between legal requirements for attribution in copyright, and cultural requirements in scholarship for giving individuals credit for their work through citation. We argue that publishing data in scientific journals under CC0 will have numerous benefits for individuals and society, and yet will have minimal implications for authors and minimal impact on current publishing and research workflows. We provide practical examples and definitions of data types, such as XML and tabular data, and specific secondary use cases for published data, including text mining, reproducible research, and open bibliography. We believe this proposed change to the current copyright and licensing structure in science publishing will help clarify what users - people and machines - of the published literature can do, legally, with journal articles and make research using the published literature more efficient. We further believe this model could be adopted across multiple publishers, and invite comment on this article from all stakeholders in scientific research. © 2012 Hrynaszkiewicz and Cockerill; licensee BioMed Central Ltd.",,"access to information; animal; editorial; ethics; human; information dissemination; legal aspect; licensing; medical research; peer review; publishing; standard; Access to Information; Animals; Biomedical Research; Copyright; Humans; Information Dissemination; Licensure; Peer Review",Review,"Final",Open Access,Scopus,2-s2.0-84865828359
"Howe B.","57203255530;","Virtual appliances, cloud computing, and reproducible research",2012,"Computing in Science and Engineering","14","4", 6193081,"36","41",,48,"10.1109/MCSE.2012.62","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864249527&doi=10.1109%2fMCSE.2012.62&partnerID=40&md5=efb183fad39c04b4bcefac959f187280","University of Washington, EScience Institute, Computer Science and Engineering Department, United States","Howe, B., University of Washington, EScience Institute, Computer Science and Engineering Department, United States","As science becomes increasingly computational, reproducibility has become increasingly difficult, perhaps surprisingly. In many contexts, virtualization and cloud computing can mitigate the issues involved without significant overhead to the researcher, enabling the next generation of rigorous and reproducible computational science. © 2012 IEEE.","case studies in scientific applications; cloud computing; information storage and retrieval; reproducible results; scientific computing; services computing","Computational science; Information storage and retrieval; Reproducibilities; Reproducible research; reproducible results; Scientific applications; Services computing; Virtual appliance; Virtualizations; Natural sciences computing; Research; Cloud computing",Article,"Final",,Scopus,2-s2.0-84864249527
"Leveque R., Mitchell I., Stodden V.","7003657764;35986052900;15623425400;","Reproducible research for scientific computing: Tools and strategies for changing the culture",2012,"Computing in Science and Engineering","14","4", 6171147,"13","17",,47,"10.1109/MCSE.2012.38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864270397&doi=10.1109%2fMCSE.2012.38&partnerID=40&md5=bfaf31c10aa171f6bfecbcc8d33ac4fb","Department of Applied Mathematics, University of Washington, United States; Department of Computer Science, University of British Columbia, Canada; Department of Statistics, Columbia University, United States","Leveque, R., Department of Applied Mathematics, University of Washington, United States; Mitchell, I., Department of Computer Science, University of British Columbia, Canada; Stodden, V., Department of Statistics, Columbia University, United States","This article considers the obstacles involved in creating reproducible computational research as well as some efforts and approaches to overcome them. © 2012 IEEE.","computational science and engineering; data and code disclosure; reproducibility; reproducible research; scientific computing","Computational science and engineerings; data and code disclosure; Reproducibilities; Reproducible research; Computer science; Engineering; Natural sciences computing; Research",Article,"Final",,Scopus,2-s2.0-84864270397
"Stodden V.","15623425400;","Reproducible research: Tools and strategies for scientific computing",2012,"Computing in Science and Engineering","14","4", 6241363,"11","12",,13,"10.1109/MCSE.2012.82","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864234358&doi=10.1109%2fMCSE.2012.82&partnerID=40&md5=55f245b72c63ab7aed6a2d1b5ef986eb","Department of Statistics, Columbia University, United States","Stodden, V., Department of Statistics, Columbia University, United States",[No abstract available],"computational science and engineering; data and code disclosure; reproducibility; reproducible research; scientific computing",,Editorial,"Final",,Scopus,2-s2.0-84864234358
"Davison A.","8940202300;","Automated capture of experiment context for easier reproducibility in computational research",2012,"Computing in Science and Engineering","14","4", 6180156,"48","56",,59,"10.1109/MCSE.2012.41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864222718&doi=10.1109%2fMCSE.2012.41&partnerID=40&md5=5ccbd34ecc4d3be04104e554f04a8598","Unité de Neurosciences, Information and Complexité, Centre National de la Recherche Scientifique, France","Davison, A., Unité de Neurosciences, Information and Complexité, Centre National de la Recherche Scientifique, France","Published scientific research that relies on numerical computations is too often not reproducible. For computational research to become consistently and reliably reproducible, the process must become easier to achieve, as part of day-to-day research. A combination of best practices and automated tools can make it easier to create reproducible research. © 2012 IEEE.","reliability; reusable libraries; reusable software; scientific computing; software/program verification","Automated tools; Numerical computations; Reproducibilities; Reproducible research; Reusable library; Reusable softwares; Scientific researches; Software/program verification; Computer software reusability; Natural sciences computing; Reliability; Software reliability; Verification; Research",Article,"Final",,Scopus,2-s2.0-84864222718
"Gavish M., Donoho D.","36470111400;7006144847;","Three dream applications of verifiable computational results",2012,"Computing in Science and Engineering","14","4", 6200248,"26","31",,9,"10.1109/MCSE.2012.65","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864205790&doi=10.1109%2fMCSE.2012.65&partnerID=40&md5=5ee0e5cfd7879a538d5cba265019c4b3","Stanford University, United States","Gavish, M., Stanford University, United States; Donoho, D., Stanford University, United States","Verifiable Computational Results (VCR) is a disciplined approach to computer-based research that requires subtle adjustment to the work habits of scientists, and in return automatically converts their results into permanent Web services. This article describes how VCR makes computational results accessible to three specific Dream Applications, which allow researchers to search, reuse, and experiment upon published computational results. © 2012 IEEE.","dream applications; meta-analysis; repository; reproducible research; RESTful Web services; scientific computing; VCR; verifiable research; verifiable result identifier","Meta-analysis; repository; Reproducible research; RESTful Web services; verifiable result identifier; Natural sciences computing; Videocassette recorders; Web services; Websites; Research",Article,"Final",,Scopus,2-s2.0-84864205790
"Groves T., Godlee F.","7005100007;26643531000;","Open science and reproducible research",2012,"BMJ (Online)","344","7863", e4383,"","",,15,"10.1136/bmj.e4383","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863190431&doi=10.1136%2fbmj.e4383&partnerID=40&md5=cc9760e683580899271a33237c2fe7f2",,"Groves, T.; Godlee, F.",[No abstract available],,"access to information; clinical data repository; data analysis software; editorial; health care financing; health care organization; health care quality; health status; information dissemination; information processing; Internet; medical decision making; medical research; online system; peer review; priority journal; publication; publishing; quality control; risk benefit analysis; scientist; factual database; human; organization and management; United Kingdom; Access to Information; Biomedical Research; Databases, Factual; Great Britain; Humans",Editorial,"Final",Open Access,Scopus,2-s2.0-84863190431
"Majka P., Kublik E., Furga G., Wójcik D.K.","54882418300;6602229137;54883504100;7003319396;","Common atlas format and 3D brain atlas reconstructor: Infrastructure for Constructing 3D brain atlases",2012,"Neuroinformatics","10","2",,"181","197",,20,"10.1007/s12021-011-9138-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861202352&doi=10.1007%2fs12021-011-9138-6&partnerID=40&md5=6491ff1856dbbe0e2fae37b36d4c539a","Department of Neurophysiology, Nencki Institute of Experimental Biology, 3 Pasteur Street, 02-093 Warsaw, Poland; Department of Mathematics, Mechanics and Computer Science, University of Warsaw, Warsaw, Poland","Majka, P., Department of Neurophysiology, Nencki Institute of Experimental Biology, 3 Pasteur Street, 02-093 Warsaw, Poland; Kublik, E., Department of Neurophysiology, Nencki Institute of Experimental Biology, 3 Pasteur Street, 02-093 Warsaw, Poland; Furga, G., Department of Mathematics, Mechanics and Computer Science, University of Warsaw, Warsaw, Poland; Wójcik, D.K., Department of Neurophysiology, Nencki Institute of Experimental Biology, 3 Pasteur Street, 02-093 Warsaw, Poland","One of the challenges of modern neuroscience is integrating voluminous data of diferent modalities derived from a variety of specimens. This task requires a common spatial framework that can be provided by brain atlases. The first atlases were limited to two-dimentional presentation of structural data. Recently, attempts at creating 3D atlases have been made to offer navigation within non-standard anatomical planes and improve capability of localization of different types of data within the brain volume. The 3D atlases available so far have been created using frameworks which make it difficult for other researchers to replicate the results. To facilitate reproducible research and data sharing in the field we propose an SVGbased Common Atlas Format (CAF) to store 2D atlas delineations or other compatible data and 3D Brain Atlas Reconstructor (3dBAR), software dedicated to automated reconstruction of three-dimensional brain structures from 2D atlas data. The basic functionality is Electronic supplementary material The online version of this article (doi:10.1007/s12021-011-9138-6) contains supplementary material, which is available to authorized users. P. Majka (B) . E. Kublik . D. K. Wójcik Department of Neurophysiology, Nencki Institute of Experimental Biology, 3 Pasteur Street, 02-093 Warsaw, Poland e-mail: p.majka@nencki.gov.pl G. Furga Department of Mathematics, Mechanics and Computer Science, University of Warsaw, Warsaw, Poland provided by (1) a set of parsers which translate various atlases from a number of formats into the CAF, and (2) a module generating 3Dmodels from CAF datasets. The whole reconstruction process is reproducible and can easily be configured, tracked and reviewed, which facilitates fixing errors. Manual corrections can be made when automatic reconstruction is not sufficient. The software was designed to simplify interoperability with other neuroinformatics tools by using open file formats. The content can easily be exchanged at any stage of data processing. The framework allows for the addition of new public or proprietary content. © Springer Science+Business Media, LLC 2011.","3D reconstruction; 3D visualization; Brain atlas; Reproducible research; Tool interoperability; Visualization","animal; book; brain; C57BL mouse; computer program; factual database; histology; human; image processing; medical informatics; methodology; mouse; rat; reproducibility; review; three dimensional imaging; Animals; Atlases as Topic; Brain; Databases, Factual; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Medical Informatics; Mice; Mice, Inbred C57BL; Rats; Reproducibility of Results; Software",Review,"Final",Open Access,Scopus,2-s2.0-84861202352
"Li-Thiao-Té S.","16646203500;","Literate program execution for teaching computational science",2012,"Procedia Computer Science","9",,,"1723","1732",,1,"10.1016/j.procs.2012.04.190","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896966382&doi=10.1016%2fj.procs.2012.04.190&partnerID=40&md5=09419007e13ba9307573ee3637cf4579","Université Paris 13, CNRS, UMR 7539 LAGA, 99, avenue Jean-Baptiste Clément, F-93 430 Villetaneuse, France","Li-Thiao-Té, S., Université Paris 13, CNRS, UMR 7539 LAGA, 99, avenue Jean-Baptiste Clément, F-93 430 Villetaneuse, France","Class material for computer science courses often contains algorithms and code snippets, as well as the results of their execution. Usually, these are written and tested outside the source document then included via copy-and-paste. Making sure that the code compiles and that the results really correspond to the included code is the teacher's responsibility. Using techniques and ideas from literate programming, we propose to include source code and executable instructions inside the source document. To support this, we have implemented Lepton which is a tool for extracting source code, compiling, executing, and including the results of the documented programs. Consequently, copy-and-paste is eliminated and code output is guaranteed to be up-to-date with source code. This manuscript was written with Lepton. © 2012 Published by Elsevier Ltd.","Executable papers; Literate programming; Reproducible research; Tools to aid in teaching",,Conference Paper,"Final",Open Access,Scopus,2-s2.0-84896966382
"Bassingthwaighte J.B., Butterworth E., Jardine B., Raymond G.M.","7102946604;26655222600;55585385400;7203010895;","Compartmental modeling in the analysis of biological systems",2012,"Methods in Molecular Biology","929",,,"391","438",,3,"10.1007/978-1-62703-50-2_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934443273&doi=10.1007%2f978-1-62703-50-2_17&partnerID=40&md5=0f1876d96818f03cc5cee654c163c8c0","Department of Bioengineering, University of Washington, Seattle, WA, United States","Bassingthwaighte, J.B., Department of Bioengineering, University of Washington, Seattle, WA, United States; Butterworth, E., Department of Bioengineering, University of Washington, Seattle, WA, United States; Jardine, B., Department of Bioengineering, University of Washington, Seattle, WA, United States; Raymond, G.M., Department of Bioengineering, University of Washington, Seattle, WA, United States","Compartmental models are composed of sets of interconnected mixing chambers or stirred tanks. Each component of the system is considered to be homogeneous, instantly mixed, with uniform concentration. The state variables are concentrations or molar amounts of chemical species. Chemical reactions, transmembrane transport, and binding processes, determined in reality by electrochemical driving forces and constrained by thermodynamic laws, are generally treated using first-order rate equations. This fundamental simplicity makes them easy to compute since ordinary differential equations (ODEs) are readily solved numerically and often analytically. While compartmental systems have a reputation for being merely descriptive they can be developed to levels providing realistic mechanistic features through refining the kinetics. Generally, one is considering multi-compartmental systems for realistic modeling. Compartments can be used as ""black"" box operators without explicit internal structure, but in pharmacokinetics compartments are considered as homogeneous pools of particular solutes, with inputs and outputs defined as flows or solute fluxes, and transformations expressed as rate equations. Descriptive models providing no explanation of mechanism are nevertheless useful in modeling of many systems. In pharmacokinetics (PK), compartmental models are in widespread use for describing the concentration-time curves of a drug concentration following administration. This gives a description of how long it remains available in the body, and is a guide to defining dosage regimens, method of delivery, and expectations for its effects. Pharmacodynamics (PD) requires more depth since it focuses on the physiological response to the drug or toxin, and therefore stimulates a demand to understand how the drug works on the biological system; having to understand drug response mechanisms then folds back on the delivery mechanism (the PK part) since PK and PD are going on simultaneously (PKPD). Many systems have been developed over the years to aid in modeling PKPD systems. Almost all have solved only ODEs, while allowing considerable conceptual complexity in the descriptions of chemical transformations, methods of solving the equations, displaying results, and analyzing systems behavior. Systems for compartmental analysis include Simulation and Applied Mathematics, CoPasi (enzymatic reactions), Berkeley Madonna (physiological systems), XPPaut (dynamical system behavioral analysis), and a good many others. JSim, a system allowing the use of both ODEs and partial differential equations (that describe spatial distributions), is used here. It is an open source system, meaning that it is available for free and can be modified by users. It offers a set of features unique in breadth of capability that make model verification surer and easier, and produces models that can be shared on all standard computer platforms. © 2012 Springer Science+Business Media, LLC.","CellML; Compartmental systems; Confidence limits; JSim; Optimization; Ordinary and partial differential equations; Pharmacokinetics- pharmacodynamics; Physiological and pharmacologic modeling; Physiome; PKPD; Reproducible research; SBML; Systems biology; Unit checking; Validation; Verification","drug; article; biological model; compartment model; computer program; delivery; drug response; mathematics; pharmacodynamics; plasma concentration-time curve; priority journal; simulation",Article,"Final",,Scopus,2-s2.0-84934443273
"Peng R.D.","8297055600;","Reproducible research in computational science",2011,"Science","334","6060",,"1226","1227",,482,"10.1126/science.1213847","https://www.scopus.com/inward/record.uri?eid=2-s2.0-82755174123&doi=10.1126%2fscience.1213847&partnerID=40&md5=a818476504a1de27146bfa7e6f878558","Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, Baltimore MD 21205, United States","Peng, R.D., Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, Baltimore MD 21205, United States","Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.",,"numerical model; research work; biology; human; medical literature; medical research; priority journal; reproducibility; science; short survey",Short Survey,"Final",,Scopus,2-s2.0-82755174123
"Kraker P., Leony D., Reinhardt W., Beham G.","25655048000;36246250500;24341601100;24337312400;","The case for an open science in technology enhanced learning",2011,"International Journal of Technology Enhanced Learning","3","6",,"643","654",,19,"10.1504/IJTEL.2011.045454","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865512384&doi=10.1504%2fIJTEL.2011.045454&partnerID=40&md5=581a13f0dd344caddff1e43e61d565d8","Know-Center, Graz University of Technology, Inffeldgasse 21a, 8010 Graz, Austria; Department of Telematic Engineering, Carlos III University of Madrid, Av. Universidad, 30, Edif. Torres Quevedo, E-28911 Leganés, Madrid, Spain; Department of Computer Science, University of Paderborn, Fürstenallee 11, 3102 Paderborn, Germany; Graz University of Technology, Inffeldgasse 21a, 8010 Graz, Austria","Kraker, P., Know-Center, Graz University of Technology, Inffeldgasse 21a, 8010 Graz, Austria; Leony, D., Department of Telematic Engineering, Carlos III University of Madrid, Av. Universidad, 30, Edif. Torres Quevedo, E-28911 Leganés, Madrid, Spain; Reinhardt, W., Department of Computer Science, University of Paderborn, Fürstenallee 11, 3102 Paderborn, Germany; Beham, G., Graz University of Technology, Inffeldgasse 21a, 8010 Graz, Austria","In this paper, we make the case for an open science in technology enhanced learning (TEL). Open science means opening up the research process by making all of its outcomes, and the way in which these outcomes were achieved, publicly available on the World Wide Web. In our vision, the adoption of open science instruments provides a set of solid and sustainable ways to connect the disjoint communities in TEL. Furthermore, we envision that researchers in TEL would be able to reproduce the results from any paper using the instruments of open science. Therefore, we introduce the concept of open methodology, which stands for sharing the methodological details of the evaluation provided, and the tools used for data collection and analysis. We discuss the potential benefits, but also the issues of an open science, and conclude with a set of recommendations for implementing open science in TEL. Copyright © 2011 Inderscience Enterprises Ltd.","Barriers to open science; Comparability of research; Implementation of open science; Open access; Open data; Open methodology; Open science; Open source; Reproducible research; Technology enhanced learning; TEL; Vision paper",,Article,"Final",,Scopus,2-s2.0-84865512384
"Grubb A.M., Easterbrook S.M.","47561405700;6603689305;","On the lack of consensus over the meaning of openness: An empirical study",2011,"PLoS ONE","6","8", e23420,"","",,15,"10.1371/journal.pone.0023420","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051740010&doi=10.1371%2fjournal.pone.0023420&partnerID=40&md5=96fd0aee8c4e61bea6e33b2946d6533f","Department of Computer Science, University of Toronto, Toronto, Canada","Grubb, A.M., Department of Computer Science, University of Toronto, Toronto, Canada; Easterbrook, S.M., Department of Computer Science, University of Toronto, Toronto, Canada","This study set out to explore the views and motivations of those involved in a number of recent and current advocacy efforts (such as open science, computational provenance, and reproducible research) aimed at making science and scientific artifacts accessible to a wider audience. Using a exploratory approach, the study tested whether a consensus exists among advocates of these initiatives about the key concepts, exploring the meanings that scientists attach to the various mechanisms for sharing their work, and the social context in which this takes place. The study used a purposive sampling strategy to target scientists who have been active participants in these advocacy efforts, and an open-ended questionnaire to collect detailed opinions on the topics of reproducibility, credibility, scooping, data sharing, results sharing, and the effectiveness of the peer review process. We found evidence of a lack of agreement on the meaning of key terminology, and a lack of consensus on some of the broader goals of these advocacy efforts. These results can be explained through a closer examination of the divergent goals and approaches adopted by different advocacy efforts. We suggest that the scientific community could benefit from a broader discussion of what it means to make scientific research more accessible and how this might best be achieved. © 2011 Grubb, Easterbrook.",,"access to information; awareness; consensus development; controlled study; empirical research; human; information processing; nomenclature; open ended questionnaire; peer review; perception; public opinion; publication; qualitative analysis; reproducibility; review; social interaction; strategic planning; article; consensus; information dissemination; medical research; methodology; questionnaire; social environment; standard; Biomedical Research; Consensus; Humans; Information Dissemination; Peer Review; Questionnaires; Reproducibility of Results; Research Design; Social Environment",Review,"Final",Open Access,Scopus,2-s2.0-80051740010
"Kapfhammer G.M.","12752631400;","Empirically evaluating regression testing techniques: Challenges, solutions, and a potential way forward",2011,"Proceedings - 4th IEEE International Conference on Software Testing, Verification, and Validation Workshops, ICSTW 2011",,, 5954396,"99","102",,9,"10.1109/ICSTW.2011.88","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051616641&doi=10.1109%2fICSTW.2011.88&partnerID=40&md5=2c3781ffc94117ea896761abaac3925a","Department of Computer Science, Allegheny College, United States","Kapfhammer, G.M., Department of Computer Science, Allegheny College, United States","The published studies of regression testing methods often contain many of the hallmarks of high quality empirical research. Beyond features like clear descriptions of the methodology and the visualization and statistical analysis of the data sets, certain papers in this field also provide some of the artifacts used in and/or produced by the experiments. Yet, the limited industrial adoption of regression testing techniques is due in part to a lack of comprehensive empirical evaluations. Moreover, the regression testing community has not achieved a level of experimental reproducibility that would fully establish it as a science. After identifying the challenges associated with evaluating regression testing methods, this paper advocates a way forward involving a mutually beneficial increased sharing of the inputs, outputs, and procedures used in experiments. © 2011 IEEE.","Regression testing; Reproducible research","Data sets; Empirical evaluations; Empirical research; High quality; Industrial adoption; Regression testing; Regression testing techniques; Reproducibilities; Reproducible research; Computer software selection and evaluation; Data visualization; Experiments; Regression analysis; Testing; Verification; Visualization; Software testing",Conference Paper,"Final",,Scopus,2-s2.0-80051616641
"Limare N., Morel J.-M.","39762262400;57203072257;","The IPOL initiative: Publishing and testing algorithms on line for reproducible research in image processing",2011,"Procedia Computer Science","4",,,"716","725",,9,"10.1016/j.procs.2011.04.075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958258849&doi=10.1016%2fj.procs.2011.04.075&partnerID=40&md5=c8705af6ad5ac84915b85a54a2105ceb","CMLA, ENS Cachan, CNRS, 61 Avenue du Président Wilson, F-94230 Cachan, France","Limare, N., CMLA, ENS Cachan, CNRS, 61 Avenue du Président Wilson, F-94230 Cachan, France; Morel, J.-M., CMLA, ENS Cachan, CNRS, 61 Avenue du Président Wilson, F-94230 Cachan, France","Image Processing On Line (IPOL) publishes image processing and image analysis algorithms, described in accurate literary form, coupled with code. It allows scientists to check directly the published algorithms on line by providing a web execution interface on any uploaded image. This installation acts the universality of image science. It permits to transcend the artificial segmentation of the research community in groups using this or that image software, or working on dedicated incompatible image formats. It promotes reproducible research, and the establishment of a state of the art verifiable by all, and on any image. This paper describes the technical challenges raised by the foundation of this new kind of journal and its scientific evaluation issues. It finally analyzes the first publications, to demonstrate its potential impact on the development of image science. © 2011 Published by Elsevier Ltd.","Image processing; Implementation; Reproducible research; Web interface","Execution interface; Image analysis algorithms; Image format; Image science; Image software; Implementation; Potential impacts; Reproducible research; Research communities; State of the art; Technical challenges; Testing algorithm; Web interface; Algorithms; Digital image storage; Imaging systems; Research; User interfaces; World Wide Web; Image segmentation",Conference Paper,"Final",Open Access,Scopus,2-s2.0-79958258849
"Le Borgne Y.-A., Campo A.","15065575500;57196586423;","Open Review in computer science : Elsevier grand challenge on executable papers",2011,"Procedia Computer Science","4",,,"778","780",,1,"10.1016/j.procs.2011.04.082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958259630&doi=10.1016%2fj.procs.2011.04.082&partnerID=40&md5=1e7a5b9e50bf8eede9391581921b0f10","Computational Modeling Laboratory and Electronics and Informatics Dpt., Vrije Universiteit Brussel, Pleinlaan, 2, 1050, Brussels, Belgium; Computer Science Department, Machine Learning Group, Université Libre de Bruxelles, Bd. Triomphe, 1050, Brussels, Belgium; Artificial Intelligence Laboratory, IRIDIA, Université Libre de Bruxelles, 50, Av. F. Roosevelt, 1050 - Brussels, Belgium","Le Borgne, Y.-A., Computational Modeling Laboratory and Electronics and Informatics Dpt., Vrije Universiteit Brussel, Pleinlaan, 2, 1050, Brussels, Belgium, Computer Science Department, Machine Learning Group, Université Libre de Bruxelles, Bd. Triomphe, 1050, Brussels, Belgium; Campo, A., Artificial Intelligence Laboratory, IRIDIA, Université Libre de Bruxelles, 50, Av. F. Roosevelt, 1050 - Brussels, Belgium","We present Open Review, a web-based platform aimed at stimulating executable papers by means of post-publication peer-review. Its goal is to bring computer science researchers to collaboratively build their work upon previous research results, in such a way that transparency, reproducibility and sustainability of research results are greatly improved. The main design goals of the platform are clarity, conciseness, and reproducibility. Its main features are to: (i) provide incentives for making research communities to participate, (ii) make papers executable by means of boards' annotations, without necessarily involving the authors of an article, and (iii) give snapshots of the current research state on any given article. © 2011 Published by Elsevier Ltd.","Collaborative research; Elsevier grand challenge; Executable papers; Peer-review; Reproducible research","Collaborative research; Elsevier; Executable papers; Peer-review; Reproducible research; Computer science; Engineering research; User interfaces; Paper",Conference Paper,"Final",Open Access,Scopus,2-s2.0-79958259630
"Carey V.J., Stodden V.","7006779984;15623425400;","Reproducible research concepts and tools for cancer bioinformatics",2010,"Biomedical Informatics for Cancer Research",,,,"149","175",,6,"10.1007/978-1-4419-5714-6_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955763421&doi=10.1007%2f978-1-4419-5714-6_8&partnerID=40&md5=363deae4fa13022041376f036579bf52","Channing Laboratory, Brigham and Women's Hospital, Harvard Medical School, 181 Longwood Avenue, Boston, MA 02115, United States; Yale Law School, 127 Wall St, New Haven, CT 06511, United States","Carey, V.J., Channing Laboratory, Brigham and Women's Hospital, Harvard Medical School, 181 Longwood Avenue, Boston, MA 02115, United States; Stodden, V., Yale Law School, 127 Wall St, New Haven, CT 06511, United States","""Reproducible research"" refers to a publishing discipline, originating in the geosciences, in which journal articles are accompanied by publication of data resources and software sufficient to allow independent reproduction of all tables and figures presented in articles. This paper reviews concepts of reproducible research in connection with cancer bioinformatics. The importance of reproducible discipline in the face of analytic complexity of microarray studies is documented with two case studies, and the role of portable self-documenting data and software archives in securing reproducibility is described. Legal protections for those engaged in reproducible research are discussed in the context of current US copyright law; a reproducible research standard that formalizes rights and obligations of those engaged in reproducible research is detailed. There is every indication that reproducible discipline is feasible for microarray studies, and reliability of inferences in cancer bioinformatics will be enhanced if commitments to concrete reproducibility are broadly accepted in the research community. © Springer Science+Business Media, LLC 2010.",,,Book Chapter,"Final",,Scopus,2-s2.0-79955763421
"Nolan D., Peng R.D., Lang D.T.","7103352085;8297055600;7202377375;","Enhanced dynamic documents for reproducible research",2010,"Biomedical Informatics for Cancer Research",,,,"335","345",,,"10.1007/978-1-4419-5714-6_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885749523&doi=10.1007%2f978-1-4419-5714-6_20&partnerID=40&md5=48c87af8cca54c613d2187f609518015","Department of Statistics, University of California, Davis, 4210 Math. Sci. Bldg. One Shield Avenue, Davis, CA 95616, United States; Department of Statistics, University of California, 367 Evans Hall, Berkeley, CA 94720, United States; Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, 615 North Wolfe Street, Baltimore, MD 21205, United States","Nolan, D., Department of Statistics, University of California, 367 Evans Hall, Berkeley, CA 94720, United States; Peng, R.D., Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, 615 North Wolfe Street, Baltimore, MD 21205, United States; Lang, D.T., Department of Statistics, University of California, Davis, 4210 Math. Sci. Bldg. One Shield Avenue, Davis, CA 95616, United States","Dynamic documents that combine text and code, which is evaluated to dynamically create content when the document is rendered, for example, Sweave, are a large step forward in reproducible data analysis and computation. However, to capture the research process, we need richer paradigms and infrastructure. The process includes all the investigations and computations, and not just the final reported ones, and the entirety represents reproducible research. In addition to richer paradigms for reproducability, we want to be able to capture more complex aspects of the computational process, such as the use of multiple languages, and also engage different communities using other programming languages so that reproducible computations and research become more widespread. We also need to integrate existing and future approaches with commonly used tools such as Microsoft Word and make the resulting documents richer for authors and readers. We present two approaches to structured, dynamic documents that use modern, ubiquitous standard technologies (XML) and provide extensible infrastructure for richer documents. The first integrates R and Microsoft Word for use by a broader audience and provides some innovations in this interface, and the second uses eXtensible Stylesheet Language (XSL) and R to provide a flexible and extensible infrastructure for richer, more accessible dynamic documents. © 2010 Springer Science+Business Media, LLC.",,,Book Chapter,"Final",,Scopus,2-s2.0-84885749523
"Peng R.D., Lang D.T.","8297055600;7202377375;","Caching and visualizing statistical analyses",2010,"Biomedical Informatics for Cancer Research",,,,"291","300",,,"10.1007/978-1-4419-5714-6_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885768558&doi=10.1007%2f978-1-4419-5714-6_17&partnerID=40&md5=d2415e559ebeee369447643c5a28b569","Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, 615 North Wolfe Street, Baltimore, MD 21205, United States; Department of Statistics, University of California at Davis, 4210 Math. Sci. Bldg. One Shield Avenue, Davis, CA 95616, United States","Peng, R.D., Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, 615 North Wolfe Street, Baltimore, MD 21205, United States; Lang, D.T., Department of Statistics, University of California at Davis, 4210 Math. Sci. Bldg. One Shield Avenue, Davis, CA 95616, United States","We present the cacher and CodeDepends packages for R, which provide tools for (1) caching and analyzing the code for statistical analyses and (2) distributing these analyses to others in an efficient manner over the Web. The cacher package takes objects created by evaluating R expressions and stores them in key-value databases. These databases of cached objects can subsequently be assembled into cache packages for distribution over the Web. The cacher package also provides tools to help readers examine the data and code in a statistical analysis and reproduce, modify, or improve upon the results. In addition, readers can easily conduct alternate analyses of the data. The CodeDepends package provides complementary tools for analyzing and visualizing the code for a statistical analysis and this functionality has been integrated into the cacher package. In this chapter, we describe the cacher and CodeDepends packages and provide examples of how they can be used for reproducible research. © 2010 Springer Science+Business Media, LLC.",,,Book Chapter,"Final",,Scopus,2-s2.0-84885768558
"Stodden V.","15623425400;","Open science: Policy implications for the evolving phenomenon of user-led scientific innovation",2010,"Journal of Science Communication","9","1",,"1","8",,19,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955910701&partnerID=40&md5=04f1e51e940fa0164d1422000f12ca5b","Stanford University, Berkman Center at Harvard Law School, United States","Stodden, V., Stanford University, Berkman Center at Harvard Law School, United States","From contributions of astronomy data and DNA sequences to disease treatment research, scientific activity by non-scientists is a real and emergent phenomenon, and raising policy questions. This involvement in science can be understood as an issue of access to publications, code, and data that facilitates public engagement in the research process, thus appropriate policy to support the associated welfare enhancing benefits is essential. Current legal barriers to citizen participation can be alleviated by scientists' use of the ""Reproducible Research Standard,"" thus making the literature, data, and code associated with scientific results accessible. The enterprise of science is undergoing deep and fundamental changes, particularly in how scientists obtain results and share their work: the promise of open research dissemination held by the Internet is gradually being fulfilled by scientists. Contributions to science from beyond the ivory tower are forcing a rethinking of traditional models of knowledge generation, evaluation, and communication. The notion of a scientific ""peer"" is blurred with the advent of lay contributions to science raising questions regarding the concepts of peer-review and recognition. New collaborative models are emerging around both open scientific software and the generation of scientific discoveries that bear a similarity to open innovation models in other settings. Public engagement in science can be understood as an issue of access to knowledge for public involvement in the research process, facilitated by appropriate policy to support the welfare enhancing benefits deriving from citizen-science.",,,Article,"Final",,Scopus,2-s2.0-77955910701
"Mesirov J.P.","6701828765;","Accessible reproducible research",2010,"Science","327","5964",,"415","416",,166,"10.1126/science.1179653","https://www.scopus.com/inward/record.uri?eid=2-s2.0-75649122581&doi=10.1126%2fscience.1179653&partnerID=40&md5=7895cde4a2f11e5ebe2b37fcdf4c4ab8","Broad Institute of Massachusetts, Institute of Technology, Harvard University, Cambridge, MA 02142, United States","Mesirov, J.P., Broad Institute of Massachusetts, Institute of Technology, Harvard University, Cambridge, MA 02142, United States","As use of computation in research grows, new tools are needed to expand recording, reporting, and reproduction of methods and data.",,"computer simulation; data interpretation; DNA; genomics; genotype; paradigm shift; publishing; research work; RNA; software; algorithm; computer; computer model; computer program; data analysis; information technology; knowledge; learning; priority journal; publication; reproducibility; research; scientific literature; short survey; simulation; access to information; article; biology; computer analysis; computer program; genomics; information science; Internet; methodology; publishing; research; Access to Information; Computational Biology; Computing Methodologies; Genomics; Informatics; Internet; Publishing; Reproducibility of Results; Research; Software",Short Survey,"Final",,Scopus,2-s2.0-75649122581
"Fadili J.M., Starck J.-L., Elad M., Donoho D.L.","6602661154;7005106453;7003845289;7006144847;","MCALab: Reproducible research in signal and image decomposition and inpainting",2010,"Computing in Science and Engineering","12","1", 5372180,"44","63",,53,"10.1109/MCSE.2010.14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-75449083431&doi=10.1109%2fMCSE.2010.14&partnerID=40&md5=b7d29c3e1f13307842cd129908cd78ec","National Graduate School of Engineering and Research, Caen, France; Commission for Atomic Energy (CEA), France; Department of Computer Science at the Technion, Israel Institute of Technology, Haifa, Israel; Stanford University, United States","Fadili, J.M., National Graduate School of Engineering and Research, Caen, France; Starck, J.-L., Commission for Atomic Energy (CEA), France; Elad, M., Department of Computer Science at the Technion, Israel Institute of Technology, Haifa, Israel; Donoho, D.L., Stanford University, United States","Morphological component analysis of signals and images has far-reaching applications in science and technology, but some consider it problematic and even intractable. Reproducible research is essential to give MCA a firm scientific foundation. Researchers developed MCALab to demonstrate key MCA concepts and make them available to interested researchers. © 2006 IEEE.","Inpainting; Morphological component analysis; Reproducible research; Signal and image decomposition; Sparse representations","Component analysis; Image decomposition; Inpainting; Reproducible research; Sparse representation; Magnetic logic devices; Research; Signal processing",Article,"Final",,Scopus,2-s2.0-75449083431
"Hofer S.M., Piccinin A.M.","7004934589;6603598774;","Toward an integrative science of life-span development and aging",2010,"Journals of Gerontology - Series B Psychological Sciences and Social Sciences","65 B","3",,"269","278",,34,"10.1093/geronb/gbq017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951226360&doi=10.1093%2fgeronb%2fgbq017&partnerID=40&md5=f38a0797fb43e0b7d53cf88720198c17","Department of Psychology, University of Victoria, STN CSC, PO Box 3050, Victoria, BC, Canada","Hofer, S.M., Department of Psychology, University of Victoria, STN CSC, PO Box 3050, Victoria, BC, Canada; Piccinin, A.M., Department of Psychology, University of Victoria, STN CSC, PO Box 3050, Victoria, BC, Canada","The study of aging demands an integrative life-span developmental framework, involving interdisciplinary collaborations and multiple methodological approaches for understanding how and why individuals change, in both normative and idiosyncratic ways. We highlight and summarize some of the issues encountered when conducting integrative research for understanding aging-related change, including, the integration of results across different levels of analysis; the integration of theory, design, and analysis; and the synthesis of results across studies of aging. We emphasize the necessity of longitudinal designs for understanding development and aging and discuss methodological issues that should be considered for achieving reproducible research on within-person processes. It will be important that current and future studies permit opportunities for quantitative comparison across populations given the extent to which historical shifts and cultural differences influence life-span processes and aging-related outcomes. © The Author 2010. Published by Oxford University Press on behalf of The Gerontological Society of America. All rights reserved.","Cross-cultural differences; Developmental methods; Life course and developmental change; Longitudinal change; Measurement; Quantitative methods; Research Methods and Issues","adult; aged; aging; article; cognition; cohort analysis; cultural factor; ego development; health status; human; individuality; longitudinal study; methodology; middle aged; psychological aspect; psychological theory; research; social environment; social status; Adult; Aged; Aging; Cognition; Cohort Studies; Cross-Cultural Comparison; Health Status; Humans; Individuality; Longitudinal Studies; Middle Aged; Personality Development; Psychological Theory; Research; Social Conditions; Social Environment",Article,"Final",Open Access,Scopus,2-s2.0-77951226360
"Donoho D.L., Maleki A., Shahram M., Rahman I.U., Stodden V.","7006144847;16550098400;6602933076;15623580100;15623425400;","Reproducible research in computational harmonic analysis",2009,"Computing in Science and Engineering","11","1", 4720218,"8","18",,136,"10.1109/MCSE.2009.15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-58149133580&doi=10.1109%2fMCSE.2009.15&partnerID=40&md5=640aa1fa2f025c982f012aed9857337a","Stanford University; Apple Computer; Harvard University","Donoho, D.L., Stanford University; Maleki, A., Stanford University; Shahram, M., Stanford University; Rahman, I.U., Apple Computer; Stodden, V., Harvard University","Wavelab, based on the Matlab quantitative computing environment, is the first effort to provide a toolbox specifically designed to reproduce results in a series of computational science papers. The toolboxes in Wavelab framework include Atomizer for sparse representation of signals, Beamlab for multiscale geometric analysis, and Sparselab for multiscale analysis of manifold valued data. Various researchers have compared their own novel algorithms with the algorithms first published in the Sparselab package, which allows them to reproduce papers in Sparselab. The Symmlab package, which includes core algorithms and generates synthetic data, disseminates new problems and illustrates new data types. The arguments raised by researchers against reproducibility include reproducibility undermining the creation of intellectual capita; and reproducibility destroying time-honored motivations for collaboration.",,"Computational sciences; Computing environments; Core algorithms; Multiscale analyses; Multiscale geometric analyses; Novel algorithms; Reproducibility; Reproducible researches; Sparse representations; Synthetic datums; Fourier series; Harmonic analysis; MATLAB",Article,"Final",,Scopus,2-s2.0-58149133580
"Mitchell I.M.","35986052900;","The flexible, extensible and efficient toolbox of level set methods",2008,"Journal of Scientific Computing","35","2-3",,"300","329",,130,"10.1007/s10915-007-9174-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-49749109557&doi=10.1007%2fs10915-007-9174-4&partnerID=40&md5=f9fdbd8093d3c8b69c523ed8da360628","Department of Computer Science, University of British Columbia, 2366 Main Mall, Vancouver, BC V6T 1Z4, Canada","Mitchell, I.M., Department of Computer Science, University of British Columbia, 2366 Main Mall, Vancouver, BC V6T 1Z4, Canada","Level set methods are a popular and powerful class of numerical algorithms for dynamic implicit surfaces and solution of Hamilton-Jacobi PDEs. While the advanced level set schemes combine both efficiency and accuracy, their implementation complexity makes it difficult for the community to reproduce new results and make quantitative comparisons between methods. This paper describes the Toolbox of Level Set Methods, a collection of Matlab routines implementing the basic level set algorithms on fixed Cartesian grids for rectangular domains in arbitrary dimension. The Toolbox's code and interface are designed to permit flexible combinations of different schemes and PDE forms, allow easy extension through the addition of new algorithms, and achieve efficient execution despite the fact that the code is entirely written as m-files. The current contents of the Toolbox and some coding patterns important to achieving its flexibility, extensibility and efficiency are briefly explained, as is the process of adding two new algorithms. Code for both the Toolbox and the new algorithms is available from the Web. © 2007 Springer Science+Business Media, LLC.","Dynamic implicit surfaces; Hamilton-Jacobi equations; Level set methods; Numerical software; Reproducible research","Arbitrary dimension; Cartesian grids; Coding patterns; Dynamic implicit; Dynamic implicit surfaces; Hamilton-Jacobi; Hamilton-Jacobi equations; Implementation complexity; Level set methods; Level Sets; Level-set algorithms; MATLAB routines; New results; Numerical algorithms; Numerical software; Rectangular domains; Reproducible research; Aircraft engines; Algorithms; Chlorine compounds; Codes (standards); Codes (symbols); Drop breakup; Level measurement; MATLAB; Partial differential equations; Programming theory; Set theory",Article,"Final",,Scopus,2-s2.0-49749109557
"Ramage D., Oliner A.J.","23135978500;15923659900;","RA: Research assistant for the computational sciences",2007,"Proceedings of the 2007 Workshop on Experimental Computer Science",,, 19,"","",,1,"10.1145/1281700.1281719","https://www.scopus.com/inward/record.uri?eid=2-s2.0-37849027509&doi=10.1145%2f1281700.1281719&partnerID=40&md5=4b616e81f734c6c3362bfcdfb7f74e37","Stanford University, Stanford, CA 94305-9025, United States","Ramage, D., Stanford University, Stanford, CA 94305-9025, United States; Oliner, A.J., Stanford University, Stanford, CA 94305-9025, United States","Computational experiments often discard large amounts of valuable data, such as invocation parameters and the lineage of output. Our goal is to identify, manage, capture, and organize this information. These data can be used to make the scientific process simpler and more efficient, and to increase the value of the research by making it more rigorous and reproducible. Research Assistant (RA) is an open source Java programming tool that helps to plug this information leak. RA ensures that all console output is valid XML; saves invocation parameters, the random seed, and code version information; automatically checkpoints intermediate results; creates runnable experiment packages; and keeps meticulous notes. This paper presents the design and implementation of RA, and shows how RA easily scales to make complex experiments repeatable. Copyright 2007 ACM.","Java; Programming tool; Reproducibility; Reproducible research; XML","Computer aided software engineering; Data privacy; Java programming language; Parameter estimation; XML; Computational sciences; Programming tool; Research Assistant (RA); Computer science",Article,"Final",,Scopus,2-s2.0-37849027509
"Kovačević J.","7005353935;","How to encourage and publish reproducible research",2007,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","4",, 4218340,"IV1273","IV1276",,26,"10.1109/ICASSP.2007.367309","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547537521&doi=10.1109%2fICASSP.2007.367309&partnerID=40&md5=8b2865567ad2bd60ce11f8ca947ac460","Depts. of Biomedical Engineering and Electrical and Computer Engineering, Carnegie Mellon University, United States","Kovačević, J., Depts. of Biomedical Engineering and Electrical and Computer Engineering, Carnegie Mellon University, United States","I discuss the ""what"", ""why"" and ""how"" or reproducible research, a concept that emerged recently in computational sciences. It refers to the idea that the ultimate product is not a published paper only, but the data, software and everything else needed to produce that paper. In signal processing, the discussion just started, and this paper attempts to add to the current efforts of bringing the issue to the forefront and looking for solutions to make it happen. © 2007 IEEE.","Literate programming; Reproducible research","Computational sciences; Literate programming; Reproducible research; Computational methods; Computer programming; Computer software; Data reduction; Signal processing",Conference Paper,"Final",,Scopus,2-s2.0-34547537521
"Baiocchi G.","16644723000;","Reproducible research in computational economics: Guidelines, integrated approaches, and open source software",2007,"Computational Economics","30","1",,"19","40",,9,"10.1007/s10614-007-9084-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250882204&doi=10.1007%2fs10614-007-9084-4&partnerID=40&md5=449124303f902b133f2541156dc8a528","Department of Economics and Finance, University of Durham, Durham DH1 3HY, United Kingdom","Baiocchi, G., Department of Economics and Finance, University of Durham, Durham DH1 3HY, United Kingdom","Traditionally, computer and software applications have been used by economists to off-load otherwise complex or tedious tasks onto technology, freeing up time and intellect to address other, intellectually more rewarding, aspects of research. On the negative side, this increasing dependence on computers has resulted in research that has become increasingly difficult to replicate. In this paper, we propose some basic standards to improve the production and reporting of computational results in economics for the purpose of accuracy and reproducibility. In particular, we make recommendations on four aspects of the process: computational practice, published reporting, supporting documentation, and visualization. Also, we reflect on current developments in the practice of computing and visualization, such as integrated dynamic electronic documents, distributed computing systems, open source software, and their potential usefulness in making computational and empirical research in economics more easily reproducible. © Springer Science+Business Media, LLC 2007.","Econometric software; Economic methodology; Other computer software",,Article,"Final",,Scopus,2-s2.0-34250882204
"Laine C., Goodman S.N., Griswold M.E., Sox H.C.","57204303041;35404606500;7102709853;7005145392;","Reproducible research: Moving toward research the public can really trust",2007,"Annals of Internal Medicine","146","6",,"450","453",,118,"10.7326/0003-4819-146-6-200703200-00154","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33947715604&doi=10.7326%2f0003-4819-146-6-200703200-00154&partnerID=40&md5=12e53bf466dacb3a42df73df27a0581f","Customer Service, American College of Physicians, 190 N. Independence Mall West, Philadelphia, PA 19106, United States; Department of Oncology, Division of Biostatistics, Johns Hopkins University, 550 North Broadway, Baltimore, MD 21209, United States; Welch Center, Johns Hopkins University, 2024 E. Monument Street, Baltimore, MD 21205, United States","Laine, C., Customer Service, American College of Physicians, 190 N. Independence Mall West, Philadelphia, PA 19106, United States; Goodman, S.N., Department of Oncology, Division of Biostatistics, Johns Hopkins University, 550 North Broadway, Baltimore, MD 21209, United States; Griswold, M.E., Welch Center, Johns Hopkins University, 2024 E. Monument Street, Baltimore, MD 21205, United States; Sox, H.C., Customer Service, American College of Physicians, 190 N. Independence Mall West, Philadelphia, PA 19106, United States","A community of scientists arrives at the truth by independently verifying new observations. In this time-honored process, journals serve 2 principal functions: evaluative and editorial. In their evaluative function, they winnow out research that is unlikely to stand up to independent verification; this task is accomplished by peer review. In their editorial function, they try to ensure transparent (by which we mean clear, complete, and unambiguous) and objective descriptions of the research. Both the evaluative and editorial functions go largely unnoticed by the public - the former only draws public attention when a journal publishes fraudulent research. However, both play a critical role in the progress of science. This paper is about both functions. We describe the evaluative processes we use and announce a new policy to help the scientific community evaluate, and build upon, the research findings that we publish. © 2007 American College of Physicians.",,"evaluation; medical literature; medical research; peer review; policy; priority journal; publishing; reproducibility; review; scientist; trust; article; conflict of interest; publication; publishing; research ethics; scientific misconduct; standard; Biomedical Research; Conflict of Interest; Editorial Policies; Ethics, Research; Peer Review, Research; Periodicals; Publishing; Reproducibility of Results; Scientific Misconduct",Review,"Final",,Scopus,2-s2.0-33947715604
"Duke C.","9040973700;","Beyond data: Reproducible research in ecology and environmental sciences - The author replies [3]",2007,"Frontiers in Ecology and the Environment","5","2",,"67","",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847676429&partnerID=40&md5=25066e99faf17c702a990ff9a195f969","Ecological Society of America, Washington, DC, United States","Duke, C., Ecological Society of America, Washington, DC, United States",[No abstract available],,,Letter,"Final",,Scopus,2-s2.0-33847676429
"Hollister J.W., Walker H.A.","7003746590;7202541589;","Beyond data: Reproducible research in ecology and environmental sciences [6]",2007,"Frontiers in Ecology and the Environment","5","1",,"11","12",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847001604&partnerID=40&md5=ecab73ec96dd9a56af8507cdab5ab81d","US Environmental Protection Agency, Atlantic Ecology Division, Narragansett, RI, United States","Hollister, J.W., US Environmental Protection Agency, Atlantic Ecology Division, Narragansett, RI, United States; Walker, H.A., US Environmental Protection Agency, Atlantic Ecology Division, Narragansett, RI, United States",[No abstract available],,,Letter,"Final",,Scopus,2-s2.0-33847001604
"LeVeque R.J.","7003657764;","Wave propagation software, computational science, and reproducible research",2006,"International Congress of Mathematicians, ICM 2006","3",,,"1227","1253",,11,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878071118&partnerID=40&md5=c65eb4f5c5950d0476f3d54637d5ee7e","Department of Applied Mathematics, University of Washington, Box 352420, Seattle, WA 98195-2420, United States","LeVeque, R.J., Department of Applied Mathematics, University of Washington, Box 352420, Seattle, WA 98195-2420, United States","Wave propagation algorithms are a class of high-resolution finite volume methods for solving hyperbolic partial differential equations arising in diverse applications. The development and use of the clawpack software implementing these methods serves as a case study for a more general discussion of mathematical aspects of software development and the need for more reproducibility in computational research. Sample applications discussed include medical applications of shock waves and geophysical fluid dynamics modeling volcanoes and tsunamis. © 2006 European Mathematical Society.","Clawpack; Hyperbolic partial differential equations; Numerical analysis; Reproducible research; Scientific computing; Software","Clawpack; Computational researches; Computational science; Diverse applications; Geophysical fluid dynamics; Hyperbolic partial differential equation; Reproducible research; Wave propagation algorithm; Computer software; Finite volume method; Medical applications; Natural sciences computing; Numerical analysis; Partial differential equations; Wave propagation; Research",Conference Paper,"Final",,Scopus,2-s2.0-84878071118
"Peng R.D., Dominici F., Zeger S.L.","8297055600;7003921473;7006338489;","Reproducible epidemiologic research",2006,"American Journal of Epidemiology","163","9",,"783","789",,141,"10.1093/aje/kwj093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646228403&doi=10.1093%2faje%2fkwj093&partnerID=40&md5=b636139c26df37d9d627df5f411bea87","Biostatistics Department, Johns Hopkins Bloomberg School of Public Health, Baltimore, MD, United States; Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, 615 North Wolfe Street, E3535, Baltimore, MD 21205, United States","Peng, R.D., Biostatistics Department, Johns Hopkins Bloomberg School of Public Health, Baltimore, MD, United States, Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, 615 North Wolfe Street, E3535, Baltimore, MD 21205, United States; Dominici, F., Biostatistics Department, Johns Hopkins Bloomberg School of Public Health, Baltimore, MD, United States; Zeger, S.L., Biostatistics Department, Johns Hopkins Bloomberg School of Public Health, Baltimore, MD, United States","The replication of important findings by multiple independent investigators is fundamental to the accumulation of scientific evidence. Researchers in the biologic and physical sciences expect results to be replicated by independent data, analytical methods, laboratories, and instruments. Epidemiologic studies are commonly used to quantify small health effects of important, but subtle, risk factors, and replication is of critical importance where results can inform substantial policy decisions. However, because of the time, expense, and opportunism of many current epidemiologic studies, it is often impossible to fully replicate their findings. An attainable minimum standard is ""reproducibility,"" which calls for data sets and software to be made available for verifying published findings and conducting alternative analyses. The authors outline a standard for reproducibility and evaluate the reproducibility of current epidemiologic research. They also propose methods for reproducible research and implement them by use of a case study in air pollution and health. Copyright © 2006 by the Johns Hopkins Bloomberg School of Public Health All rights reserved.","Air pollution; Information dissemination; Models, statistical","data set; decision making; epidemiology; health risk; policy making; risk factor; air pollution; analytic method; data analysis; epidemiology; health care policy; information dissemination; medical research; quantitative analysis; reproducibility; review; risk factor; Air Pollution; Environmental Illness; Epidemiologic Research Design; Humans; Models, Statistical; Reproducibility of Results",Review,"Final",,Scopus,2-s2.0-33646228403
"Gentleman R.","6701841330;","Reproducible research: A bioinformatics case study",2005,"Statistical Applications in Genetics and Molecular Biology","4","1",,"","",23,84,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-18544387899&partnerID=40&md5=fc1f04f277db2bd5e9b7ffecece235a6","Harvard University, United States","Gentleman, R., Harvard University, United States","While scientific research and the methodologies involved have gone through substantial technological evolution the technology involved in the publication of the results of these endeavors has remained relatively stagnant. Publication is largely done in the same manner today as it was fifty years ago. Many journals have adopted electronic formats, however, their orientation and style is little different from a printed document. The documents tend to be static and take little advantage of computational resources that might be available. Recent work, Gentleman and Temple Lang (2003), suggests a methodology and basic infrastructure that can be used to publish documents in a substantially different way. Their approach is suitable for the publication of papers whose message relies on computation. Stated quite simply, Gentleman and Temple Lang (2003) propose a paradigm where documents are mixtures of code and text. Such documents may be self-contained or they may be a component of a compendium which provides the infrastructure needed to provide access to data and supporting software. These documents, or compendiums, can be processed in a number of different ways. One transformation will be to replace the code with its output - thereby providing the familiar, but limited, static document. In this paper we apply these concepts to a seminal paper in bioinformatics, namely The Molecular Classification of Cancer, Golub et al (1999). The authors of that paper have generously provided data and other information that have allowed us to largely reproduce their results. Rather than reproduce this paper exactly we demonstrate that such a reproduction is possible and instead concentrate on demonstrating the usefulness of the compendium concept itself.","Computational science; Literate programming; Reproducibility","article; bioinformatics; electronics; medical literature; methodology; molecular evolution; cancer classification; computer program; disease classification; publication; research",Article,"Final",,Scopus,2-s2.0-18544387899
"Pennock D.J., Corre M.D.","7005052158;6701346260;","Development and application of landform segmentation procedures",2001,"Soil and Tillage Research","58","3-4",,"151","162",,78,"10.1016/S0167-1987(00)00165-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035089451&doi=10.1016%2fS0167-1987%2800%2900165-3&partnerID=40&md5=29785146c3d9b3aaec7e9d913c5e3116","Department of Soil Science, University of Saskatchewan, 51 Campus Drive, Saskatoon, Sask. S7N 5A8, Canada; Institute of Soil Science and Forest Nutrition, University of Goettingen, Buesgenweg 2, 37077 Goettingen, Germany","Pennock, D.J., Department of Soil Science, University of Saskatchewan, 51 Campus Drive, Saskatoon, Sask. S7N 5A8, Canada; Corre, M.D., Institute of Soil Science and Forest Nutrition, University of Goettingen, Buesgenweg 2, 37077 Goettingen, Germany","Landscape-scale approaches to research in soil science are explicitly focused on transfers of components within and between landscapes. Despite wide-spread recognition of the importance of these transfers, the application of landscape-scale approaches has been hindered by the lack of clear, reproducible research designs. Landform segmentation is used to divide natural and human-influenced landscapes into functionally distinct units. A specific type of landform segmentation, landform element classification, was used in a comparative mensurative design to compare the effects of cultivation on soil distribution and soil organic carbon (SOC) storage and in a manipulative design to determine the relationship between N2O emissions and fertilizer rate in a hummocky till geomorphic surface in southern Saskatchewan. Significant transfers of SOC and surface soil from convex shoulder units to lower slope positions occurred over the past 90 years, resulting in a change in the type of soils that occupy these positions at two research sites. The observed pattern is consistent with a tillage translocation dominated surface. The dominant control on N2O emissions in the landscape are spatial differences in water-filled pore space (WFPS) that are strongly controlled by water redistribution. Emissions from drier, shoulder landform element complexes are consistently low throughout the year, whereas a strong positive relationship between N fertilizer rate and N2O emissions occur in the wettest, level depressional elements. © 2001 Elsevier Science B.V.","Digital elevation models; Terrain modeling",,Article,"Final",,Scopus,2-s2.0-0035089451
"Carr T.R., Buchanan R.C., Adkins-Heljeson D., Mettille T.D., Sorensen J.","7103305358;7202408933;6505811105;6507042414;7403200434;","The future of scientific communication in the earth sciences: The impact of the internet",1997,"Computers and Geosciences","23","5",,"503","512",,3,"10.1016/S0098-3004(97)00032-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031436619&doi=10.1016%2fS0098-3004%2897%2900032-0&partnerID=40&md5=aa2e922478ba83407b7b9a36c1657ba6","Kansas Geological Survey, University of Kansas, Lawrence, KS 66047, United States","Carr, T.R., Kansas Geological Survey, University of Kansas, Lawrence, KS 66047, United States; Buchanan, R.C., Kansas Geological Survey, University of Kansas, Lawrence, KS 66047, United States; Adkins-Heljeson, D., Kansas Geological Survey, University of Kansas, Lawrence, KS 66047, United States; Mettille, T.D., Kansas Geological Survey, University of Kansas, Lawrence, KS 66047, United States; Sorensen, J., Kansas Geological Survey, University of Kansas, Lawrence, KS 66047, United States","Publication on paper of research results following peer-review and editing has been the accepted means of scientific communication for several centuries. Today, the continued growth in the volume of scientific literature, the increased unit costs of archiving paper publications, and the rapidly increasing power and availability of electronic technology are creating tremendous pressures on traditional scientific communication. The earth sciences are not immune from these pressures, and the role of the traditional publication as the primary means of communication is rapidly changing. Electronic publications and network technology are radically altering the relationship between interpretative result and the underlying data. Earth science research institutions, including the Kansas Geological Survey, are experimenting with new forms of on-line publication that assure broad access to research and data and improve application of research results to societal problems. © 1997 Elsevier Science Ltd.","Reproducible research; Scientific electronic publishing; Technology transfer","Earth sciences; electronic publishing; Internet; scientific communication; World Wide Web",Article,"Final",,Scopus,2-s2.0-0031436619
"Claerbout J.F., Karrenbach M.","7003857400;6506961656;","Electronic documents give reproducible research a new meaning",1992,"1992 SEG Annual Meeting",,,,"601","604",,62,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053483930&partnerID=40&md5=576e4c9dd4b9ac0d65a6951836e99e40","Stanford Univ., United States","Claerbout, J.F., Stanford Univ., United States; Karrenbach, M., Stanford Univ., United States","A revolution in education and technology transfer follows from the marriage of word processing and software command scripts, In this marriage an author attaches to every figure caption a pushbutton or a name tag usable to recalculate the figure from all its data, parameters, and programs. This provides a concrete definition of reproducibility in computationally oriented research. Experience at the Stanford Exploration Project shows that preparing such electronic documents is little effort beyond our customary report writing; mainly, we need to file everything in a systematic way. In 1990 we began experimenting with electronic documents that merge our scientific software with our word-processing software. A year later we manufactured a CD-ROM containing a new textbook, Joe Dellinger's doctoral dissertation, and two progress reports of the Stanford Exploration Project. We distributed these CD-ROMs1 to sponsors and many friends at the 1991 SEG meeting. In 1990, we set this sequence of goals: • Learn how to merge a publication with its underlying computational analysis. • Teach researchers how to prepare a document in a form where they themselves can reproduce their own research results a year or more later by ""pressing a single button"". • Learn how to leave finished work in a condition where coworkers can reproduce the calculation including the final illustration by pressing a button in its caption. • Prepare a complete copy of our local software environment so that graduating students can take their work away with them to other sites, press a button, and reproduce their Stanford work. • Merge electronic documents written by multiple authors (SEP reports). • Export electronic documents to numerous other sites (sponsors) so they can readily reproduce a substantial portion of our Stanford research. We met all these goals and set new ones: • produce all new documents in this form, including lab reports in formal classes and ""lab notebooks"" of research progress. • make incremental improvements in electronic-document software • seek partners for broadening standards (and making incremental improvements), Our basic goal is reproducible research. The electronic document is our means to this end. In principle, reproducibility in research can be achieved without electronic documents and that is how we started. Our first nonelectronic reproducible document was a textbook in which the paper document contained the name of a program script in every figure caption. The program scripts were organized by book chapter and section so they could be correlated to an accompanying magnetic tape dump of the file system. The magnetic tape also contained all the necessary data to feed the program script. Now that we have begun using CD-ROM publication, we can go much further. Every figure caption contains a pushbutton that jumps to the appropriate science directory (folder) and initiates a figure rebuild command and then displays the figure, possibly as a movie or interactive program. We normally display seismic images of the earth's interior. but to reach wider audiences, Figure 1 shows a satellite weather picture which the pushbutton will animate as seen on commerical television. We include all our plot software as well as freely available software from many sources, including compilers and the &amp; TgX word processing system. Naturally we cannot include licensed software, but with the exception of Fortran and C compilers and the UNIX system itself, our publication includes source code for everything needed. The CD-ROM, at 680 megabytes, is so large we have had room for many executable programs on popular brands of workstations. The presence of these exścutables gives our readers a fast start. Nearly everyone would rather read a paper book than the bitmapped page images on a screen that you see with an electronic document. But the illustrations in the electronic book are mostly in color, many are movies, and some are interactive. So the electronic book gives the reader a better understanding of the results. We typically use an interactive movie program to compare seismic sections where successive frames include processing with various parameters. The movie medium is much more informative than comparing seismic sections side by side. 3-D volumes are much better exhibited by movies than static paper illustrations. We are delivering a volume of software that is accessed like a book. © 1992 SEG Annual Meeting. All rights reserved.",,"CD-ROM; Electronic publishing; Facsimile; Magnetic tape; Motion pictures; Program compilers; Seismology; Technology transfer; Textbooks; Word processing; Computational analysis; Doctoral dissertations; Electronic document software; Freely available software; Incremental improvements; Reproducible research; Software environments; Word-processing systems; C (programming language)",Conference Paper,"Final",,Scopus,2-s2.0-85053483930
